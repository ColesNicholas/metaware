---
title: Process data
author: "Nicholas A. Coles (checked by Anjie Cao)"
editor_options: 
  chunk_output_type: console
---
This code processes and merges:
1. metaware_ESData_raw.xlsx: contains information about each study in the meta-analysis (as well as statistics needed to calculate Cohen's d)

2. metaware_SurvData_raw.csv: contains ratings of vignettes describing studies in the meta-analysis. Also contains ratings from a replication of Coles et al. 2022.

# Prep environment
```{r setup and load packages, include = FALSE}
# load libraries
library("tidyverse")
library("readxl")
```

# Open and clean metaware_ESData_raw.xlsx
```{r open/clean data, message = FALSE, warning = FALSE}
# import data
DF <- read_xlsx(path = "data/metaware_EsData_raw.xlsx",
                sheet = "coding",
                na = c("NA"))

# change ref.type pvc to cvp (for aesthetics)
DF[DF$ref.type == "pvc", ]$ref.type = "cvp"

DF <- DF %>% 
  
  # remove reference columns (these are for documentation purposes only)
  select(-ends_with("ref")) %>% 
  
  # remove variables we won't include in any analyses
  select(-c(dv, note, outcome)) %>% 
  
  # create ref.r var that indicates whether there were one or two demand conditions
  ## if the ref.type variable included a "c", it means that
  ## there was one demand condition compared to a control group 
  mutate(ref.r = 
           if_else(condition = ref.type == "cvp" |
                     ref.type == "nvc" |
                     ref.type == "cvz",
                   true = "single",
                   false = "double")) %>% 
  
  # create study and es_id columns
  rename(id.study = id) %>% 
  mutate(id.es = 1 : nrow(DF)) %>% 
  
  # where appropriate, convert variables to factors
  mutate(across(.cols = c(id.study, id.es, published, student,
                          paid, online, ref.type,
                          ref.r),
                .fns = as.factor)
         )

# create blank columns for effect size and effect size variance
# Note: these pre-existing columns are necessary for the 
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
```

## Calculate Cohen's *d* and variance
### For between-subjects data
#### Functions for calculating *d* 
##### When *M*'s and *SD*'s are provided
```{r define function EsBetwMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1, 
                       n.2, m.2, sd.2){
    sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
                       ((n.2 - 1) * (sd.2^2))) /
                        (n.1 + n.2 - 2));
    
    es <- (m.1 - m.2) / sd.within;
    return(es)
}
```

##### When t-values are provided
```{r define function EsBetwTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
    es <- tval * sqrt((n.1 + n.2) / 
                      (n.1 * n.2));
    return(es)
}
```

##### When F-values are provided
```{r define function EsBetwFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
  es <- sqrt((fval * (n.1 + n.2)) / 
             (n.1 * n.2)); 
    return(es)
  }
```

##### When p-values are provided
```{r define function EsBetwPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval){
  # calculate the inverse of the cumulative distribution function of t
  t.inv <- qt(p = (pval / 2), 
              df = (n.1 + n.2 - 2),
              lower.tail = FALSE);
  
  es <- t.inv * sqrt((n.1 + n.2) /
                     (n.1 * n.2));
  return(es)
}
```

#### Function for calculating variance of *d* with continuous data
```{r define function EsVarBetw}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){       
   es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
             ((es^2) / (2 * (n.1 + n.2)));
   return(es.var)
}
```

#### Functions for calculating *d* and variance of *d* with count data
```{r define functions EsBetwCount and EsVarBetwCount}
# cohen's d
EsBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.8
  or <- (count.1 * (n.2 - count.2)) / 
        ((n.1 - count.1) * count.2);
  
  # calculate log odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.9
  log.or = log(or);
  
  # convert log odds ratio to Cohen's d
  # formula: Borenstein et al. 2011; p . 47 Equation 7.1
  es <- log.or * (sqrt(3) / pi);
  return(es)
}

# variance of cohen's d
EsVarBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate log odds ratio variance
  # formula: Borenstein et al. 2011; p. 36; Equation 5.10
  log.or.var = (1 / count.1) +
               (1 / (n.2 - count.2)) +
               (1 / (n.1 - count.1)) +
               (1 / count.2);
  
  # convert log odds ratio variance to variance of Cohen's d
  # formula: Borenstein et al. 2011; p. 47 Equation 7.2
  es.var = log.or.var * (3 / pi^2);
  return(es.var)
}
```

#### Call functions to calculate *d* and variance of *d*
```{r b: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "between"){
    
    # call EsBetwMean on cases with between-subject designs and *means*
    if (DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsBetwMean(n.1 = DF$n.1[i],
                             m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             n.2 = DF$n.2[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i]) 
      } 
    # call EsBetwTval on cases with between-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsBetwTval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             tval = DF$tval[i])
      }
    
    # call EsBetwFval on cases with between-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsBetwFval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             fval = DF$fval[i])
    }
    
    # call EsBetwPval on cases with between-subject designs and *p-values*
    if (DF$es.calc[i] == "p") {
      DF$es[i] <- EsBetwPval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             pval = DF$pval[i])
    }
    
    # call EsBetwCount and EsVarBetwCount on cases with between-subject designs and *count data*
    if (DF$es.calc[i] == "or") {
      DF$es[i] <- EsBetwCount(n.1 = DF$n.1[i],
                              n.2 = DF$n.2[i],
                              count.1 = DF$count.1[i],
                              count.2 = DF$count.2[i])
      
      DF$es.var[i] <- EsVarBetwCount(n.1 = DF$n.1[i],
                                     n.2 = DF$n.2[i],
                                     count.1 = DF$count.1[i],
                                     count.2 = DF$count.2[i])
    }
    
    # call EsVarBetw on cases with continuous data and a between subject designs
    if (DF$es.calc[i] != "or"){
      DF$es.var[i] <- EsVarBetw(n.1 = DF$n.1[i],
                                n.2 = DF$n.2[i],
                                es = DF$es[i])
    }
    }
}
```

### For within-subjects data
```{r assumed correlation}
# if no correlation is defined, set it at .5
# Note: there is sensitivity analysis code that will set a correlation and then re-execute this script (metaware_DataProcessingSens.Rmd)
if(!exists("corr")){
  corr <- .5
}
```

#### Functions for calculating d
##### When M's and SD's are provided 
```{r EsWitnMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
# formula for imputing sd.diff:
# http://handbook.cochrane.org/chapter_16/16_4_6_1_mean_differences.htm
EsWitnMean <- function(m.1, sd.1, m.2, sd.2, corr){
  sd.diff <- sqrt((sd.1^2) + (sd.2^2) -
                  (2 * corr * sd.1 * sd.2));
        
  es <- ((m.1 - m.2) / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

##### When t-values are provided
```{r EsWitnTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnTval <- function(n.1, tval, corr){
  es <- tval * sqrt((2 * (1 - corr)) / n.1);
  return(es)
}
```

##### When F-values are provided
```{r EsWitnFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnFval <- function(n.1, fval, corr){
  es <- sqrt((2 * fval * (1- corr)) / n.1);
  return(es)
}
```

#### Function for calculating variance of d
```{r EsVarWitn}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsVarWitn <- function(n.1, es){
  es.var <- ((1 / n.1) + 
             ((es^2) / (2 * n.1))) *
            2 * (1 - corr);
  return(es.var)
}
```

#### Call functions to calculate d and variance of d
```{r w: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "within"){
    
    # call EsWitnMean on cases with within-subject designs and *means*
    if(DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsWitnMean(m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i],
                             corr = corr)
    }
    
    # call EsWitnTval on cases with within-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsWitnTval(n.1 = DF$n.1[i],
                             tval = DF$tval[i],
                             corr = corr)
  }  
    
    # call EsWitnFval on cases with within-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsWitnFval(n.1 = DF$n.1[i],
                             fval = DF$fval[i],
                             corr = corr)
    }
    
    # call EsVarWitn on cases with within subject designs
    DF$es.var[i] <- EsVarWitn(n.1 = DF$n.1[i],
                              es = DF$es[i])
    }
  }
  
```

```{r del var}
# delete objects we no longer need
rm(corr, i,
   EsBetwFval, EsBetwMean, EsBetwTval,
   EsBetwPval, EsVarBetw, EsVarWitn,
   EsWitnFval, EsWitnMean, EsWitnTval,
   EsBetwCount, EsVarBetwCount)
```

## Specify direction
This direction of the effect was coded for in the raw database, and this code ensures that all effects are in the correct direction.
```{r specify es direction}
DF <- DF %>% 
  # specify direction of the effect size
  rowwise() %>% 
  mutate(es = if_else(condition = direction == "positive",
                      true = abs(es),
                      false = abs(es) * -1)
         ) %>% 
  ungroup()
```

## Remove objects we no longer need
```{r}
DF <- DF %>% 
  select(-c(es.calc : pval))
```

# Open and clean vignette rating data
metaware_SurvData_raw.csv contains vignette rating data (as well as data from a replication of Coles et al., 2022)

This part of the code focuses only on the vignette rating data. This part of the dataset is structured awkwardly, so it warrants its own data processing code.

By the end of the code chunk, we will have one row for each participants' rating of each vignette (i.e., very long data)
```{r}
# import data
DF.surv <- read_csv(file = "data/metaware_SurvData_raw.csv") %>%
  
  # remove unnecessary variables
  select(-c(StartDate : UserLanguage),
         -c(hap1_bl1_hap : survey_order),
         -contains("Click"),
         -contains("Submit"),
         -contains("Count")) %>% 
  
  # remove row containing ImportId
  filter(!grepl("ImportId", `1_awr`)) %>% 
  
  # assign participant ids
  mutate(ss = 1 : nrow(.),
         ss = as.character(ss)) %>%  
  
  # select columns containing information from the vignettes
  select(`1_awr` : `119_opp`, ss) %>% 
  
  # extract vignette identifier from the first row of data
  # note: I warned you the data structure is awkward
  mutate_all(~if_else(condition = grepl("#", .),
                      true = substr(x = .,
                                    start = 2,
                                    stop = 9),
                      false = .))

# append first row (containing vignette identifiers) to the column name
## append name
colnames(DF.surv) <- paste(sep = "##",
                           colnames(DF.surv),
                           as.character(unlist(DF.surv[1, ]))
                           )

## remove the first row
### now that the vignette identifier has been added to the column name, we don't need this row anymore
DF.surv <- DF.surv[-1, ]

## fix ss (subject identifier) variable naming
DF.surv <- DF.surv %>% 
  rename("ss" = "ss##1")

# pivot data so that there is one row for each participants' rating of each vignette
DF.surv <- DF.surv %>% 
  # pivot longer
  pivot_longer(cols = contains("##"),
               names_to = c("var", "vig"),
               names_sep = "##") %>% 
  
  # extract variable name
  mutate(var = substr(x = var,
                      start = nchar(var) - 2,
                      stop = nchar(var))) %>% 
  
  # pivot wider
  pivot_wider(names_from = var,
              values_from = value) %>% 
  
  # convert columns to correct class
  mutate_at(c("awr", "mot", "opp", "bel", "pre"),
            as.numeric)
```

## Process attention checks
Specify whether participants correctly identified the communicated hypothesis

Note: participants either read about a positive (pos), negative (neg), or nil (nil) researcher hypothesis. If they correctly understood the communicated hypothesis, their awr rating should be 1, 2, and 3 for pos, neg, and nil respectively
```{r}
DF.surv <- DF.surv %>% 
  
  # identify whether the researcher hypothesis was pos, neg, or nil
  mutate(dem = substr(x = vig,
                      start = 4,
                      stop = 4))
  
## set att.chk to 0 (failed attention check) by default
DF.surv$att.chk = 0

## set att.chk to 1 when hypothesis is correctly identified
### positive hypothesis (dem == p)
DF.surv[DF.surv$dem == "p" & 
          !is.na(DF.surv$awr) &
          DF.surv$awr == 1, ]$att.chk = 1

### negative hypothesis (dem == n)
DF.surv[DF.surv$dem == "n" & 
          !is.na(DF.surv$awr) &
          DF.surv$awr == 2, ]$att.chk = 1

### nil hypothesis (dem == z)
DF.surv[DF.surv$dem == "z" & 
          !is.na(DF.surv$awr) &
          DF.surv$awr == 3, ]$att.chk = 1

## if participants did not respond to the attention check item, set the att.chk variable to NA
DF.surv[is.na(DF.surv$awr), ]$att.chk = NA

## manually fix 28_p_dis vignette attention check
## there were some oddities in how we created this vignette--but the correct hypothesis would be 2 (not 1)
DF.surv[DF.surv$vig == "28_p_dis" &
          !is.na(DF.surv$awr) &
          DF.surv$awr == 2, ]$att.chk = 1
```

[optional] if you would like to examine the attention check data, the code below is useful
```{r eval = F}
# proportion of participants who passed the attention check
DF.surv %>%
  summarise(m = mean(att.chk,
                     na.rm = T))

# proportion of participants who passed the attention check (split by type of hypothesis communicated)
## Note: although they did far better than chance, raters struggled the most to correctly understand nil hypotheses
DF.surv %>%
  group_by(dem) %>%
  summarise(m = mean(att.chk,
                     na.rm = T))

# proportion of participants who passed the attention check (split by vignette)
## Note: participants had the most trouble understanding the 36_n_won vignette.
DF.surv %>% 
  group_by(vig) %>% 
  filter(!is.na(att.chk)) %>% 
  summarise(n = n(),
            m = mean(att.chk)) %>% 
  arrange(m)
```

Limit to observations where attention check was passed
```{r}
DF.surv <- DF.surv %>% 
  filter(att.chk == 1)
```

## Calculate survey summary statistics
For each vignette, we want the average of participants ratings of the extent to which they would:
1. Be motivated to adjust their responses to fit the communicated hypothesis (m.mot)
2. Have the opportunity to adjust their responses (m.opp)
3. Believe the communicated hypothesis (m.bel)
4. Predict that others will adjust their responses to fit the hypothesis (m.pre)
```{r}
surv.sum <- DF.surv %>% 
  group_by(vig) %>% 
  summarise(m.mot = mean(mot, na.rm = T),
            m.opp = mean(opp, na.rm = T),
            m.bel = mean(bel, na.rm = T),
            m.pre = mean(pre, na.rm = T)
            ) %>% 
   ungroup()

# remove old survey dataframe (not needed anymore)
rm(DF.surv)
```

# Join the summary statistics (surv.sum) to the effect size dataframe (DF)
Note: some effect sizes involved a comparison between two demand characteristic manipulations. In these scenarios, the first demand characteristic condition is "vig.1" and the second is "vig.2". In these scenarios, we sum the summary statistics scores, for reasons we describe in the paper.
```{r}
# connect summary data to effect size dataframe
DF <- DF %>% 
  # join vig.1 data
  ## rename vig.1 to vig to enable join
  rename(vig = vig.1) %>% 
  
  ## connect summary data to vig.1
  left_join(x = ., 
            y = surv.sum,
            by = "vig") %>% 
  
  ## rename vig.1 summary columns
  rename(v1.mot = m.mot, 
         v1.opp = m.opp, 
         v1.bel = m.bel, 
         v1.pre = m.pre) %>% 
  
  
  # join vig.2 data
  ## rename vig.2 to vig to prep for join
  rename(vig.1 = vig,
         vig = vig.2) %>% 
  
  ## connect summary data to vig.2
  left_join(x = .,
            y = surv.sum,
            by = "vig") %>% 
  
  ## rename vig.2 summary columns
  rename(v2.mot = m.mot, 
         v2.opp = m.opp, 
         v2.bel = m.bel, 
         v2.pre = m.pre) %>% 
  
  # sum motivation, opportunity, belief, and prediction scores
  rowwise() %>% 
  mutate(mot = sum(c(v1.mot, v2.mot), 
                   na.rm = T),
         opp = sum(c(v1.opp, v2.opp), 
                   na.rm = T),
         bel = sum(c(v1.bel, v2.bel), 
                   na.rm = T),
         pre = sum(c(v1.pre, v2.pre), 
                   na.rm = T)) %>% 
  ungroup()

# set motivation, opportunity, belief, and prediction scores blank for id 18
# we did not create vignettes for id 18 because it was a *massive* outlier that we removed from all analyses 
DF[DF$id.study == 18, ]$mot = NA
DF[DF$id.study == 18, ]$opp = NA
DF[DF$id.study == 18, ]$bel = NA
DF[DF$id.study == 18, ]$pre = NA

# organize ordering of variables
DF <- DF %>% 
  select(id.study, id.es, 
         citation : ref.r, 
         es, es.var,
         mot : pre)
```

# Prep dataset for replication of Coles et al. 2022
```{r}
# import data
DF.surv2 <- 
  read_csv(file = "data/metaware_SurvData_raw.csv")

# remove rows containing unnecessary variable details
DF.surv2 <- DF.surv2[-(1 : 2), ]

# hand recode gender
## list as unknown if they did not answer (or said they'd prefer not to answer)
DF.surv2[is.na(DF.surv2$indiv_gend_var), ]$indiv_gend_var = "unknown"
DF.surv2[DF.surv2$indiv_gend_var == "7", ]$indiv_gend_var = "unknown"

## recode rest
DF.surv2[DF.surv2$indiv_gend_var == "1", ]$indiv_gend_var = "female"
DF.surv2[DF.surv2$indiv_gend_var == "2", ]$indiv_gend_var = "male"
DF.surv2[DF.surv2$indiv_gend_var == "3", ]$indiv_gend_var = "trans_female"
DF.surv2[DF.surv2$indiv_gend_var == "4", ]$indiv_gend_var = "trans_male"
DF.surv2[DF.surv2$indiv_gend_var == "5", ]$indiv_gend_var = "gender_nonconforming"

# hand recode ethnicity
DF.surv2[is.na(DF.surv2$ethnicity), ]$ethnicity = "unknown"
DF.surv2[DF.surv2$ethnicity == "1", ]$ethnicity = "white_caucasian"
DF.surv2[DF.surv2$ethnicity == "2", ]$ethnicity = "black_african_american"
DF.surv2[DF.surv2$ethnicity == "3", ]$ethnicity = "american_indian"
DF.surv2[DF.surv2$ethnicity == "4", ]$ethnicity = "asian"
DF.surv2[DF.surv2$ethnicity == "5", ]$ethnicity = "native_pacific_islander"
DF.surv2[DF.surv2$ethnicity == "6", ]$ethnicity = "native_pacific_islander"
DF.surv2[DF.surv2$ethnicity == "6" | 
           DF.surv2$ethnicity == "1,6" |
           DF.surv2$ethnicity == "1,2" |
           DF.surv2$ethnicity == "1,4" |
           DF.surv2$ethnicity == "2,6" |
           DF.surv2$ethnicity == "7" |
           DF.surv2$ethnicity == "1,3", ]$ethnicity = "other"

# process data
DF.surv2 <- DF.surv2 %>%
  
  # identify relevant variables
  select(
    # block 1 happy pose emotion reports
    hap1_bl1_hap : hap1_bl1_enj,
    
    # block 1 neutral pose emotion reports
    neu1_bl1_hap : neu1_bl1_enj,
    
    # block 2 happy pose emotion reports
    hap2_bl2_hap : hap2_bl2_enj,
    
    # block 2 neutral pose emotion reports
    neu2_bl2_hap : neu2_bl2_enj,
    
    # motivation, prediction, belief, and opportunity scores
    mot : opp, mot_gen,
    
    # manipulation check items (awareness and attention checks)
    hap1_bl1_att, hap2_bl2_att, neu1_bl1_att, neu2_bl2_att,
    awr,
    
    # condition and individual difference items
    demand,
    indiv_gend_var, indiv_agee_var, ethnicity,
    
    # relevant vignette data
    `46_awr` : `46_opp`,
    `47_awr` : `47_opp`) %>% 
  
  # rename vignette variables
  rename(pos_awr = `46_awr`,
         pos_mot = `46_mot`,
         pos_pre = `46_pre`,	
         pos_bel = `46_bel`,
         pos_opp = `46_opp`,
         
         nil_awr = `47_awr`,
         nil_mot = `47_mot`,
         nil_pre = `47_pre`,	
         nil_bel = `47_bel`,
         nil_opp = `47_opp`) %>% 
  
  # add subid variable
  mutate(sub = factor(1 : nrow(.))) %>% 
  
  # identify whether attention checks were all passed
  mutate(att.chk = 
           if_else(condition = 
                     hap1_bl1_att == "5" &
                     neu1_bl1_att == "5" &
                     hap2_bl2_att == "5" &
                     neu2_bl2_att == "5",
                   true = 1,
                   false = 0)
         ) %>% 
  
  # identify whether participants correctly identified the hypothesis
  mutate(manip.chk =
           if_else(condition =
                     demand == "pos" & awr == 1,
                   true = 1,
                   false = 
                     if_else(condition = 
                               demand == "nil" & awr == 2,
                             true = 1,
                             false = 0))) %>% 
  
  # create separate rows for each trial 
    # 1. Gather emotion reports into a single column
    gather(key = "dv", 
           value = "value",
           hap1_bl1_hap : neu2_bl2_enj) %>% 
  
    # 2. Create separate variables that identify the trial and outcome using "_..._ naming convention separator
    separate(col = "dv", 
             into = c("trial", "outcome"),
             sep = "_..._") %>%
    
    # 3. Spread outcomes into individual rows
    pivot_wider(names_from = "outcome",
                values_from = "value") %>% 
  
  # fix variable types
  mutate_at(.vars = c("mot", "pre", "bel", "opp",
                      "mot_gen", "indiv_agee_var", 
                      
                      "hap", "sat", "enj",
                      
                      "pos_awr", "pos_mot",
                      "pos_pre", "pos_bel",
                      "pos_opp",
                      
                      "nil_awr", "nil_mot",
                      "nil_pre", "nil_bel",
                      "nil_opp"),
            .funs = as.numeric) %>%
  
  mutate_at(.vars = c("demand", "indiv_gend_var",
                      "ethnicity", "sub"),
            .funs = as.factor) %>% 
  
  # Calculate self-reported happiness scores
  rowwise() %>%
  mutate(happy = mean(c(hap, sat, enj))) %>% 
  ungroup() %>% 
  
  # identify block number
  mutate(block.num = if_else(condition = trial == "hap1" |
                                         trial == "neu1",
                             true = 1,
                             false = 2),
         block.num = factor(block.num)) %>% 
  
  # create new trial variable that remove redundant information about block
  mutate(trial = substr(x = trial, 
                        start = 1, 
                        stop = 3),
         trial = factor(trial)) %>% 
  
  # organize dataframe
  arrange(sub, block.num, trial) %>% 
  select(sub, demand, trial, block.num, happy, 
         att.chk, manip.chk,
         mot : mot_gen,
         indiv_gend_var : ethnicity) %>% 
  
  # recode (flip) motivation for the nil hypothesis condition
  rowwise() %>% 
  mutate(mot = if_else(demand == "nil",
                       mot * (-1),
                       mot)) %>% 
  ungroup()

# center motivation, opportunity, and belief scores
DF.surv2$mot.c = scale(DF.surv2$mot,
                       scale = F) %>% as.numeric()
DF.surv2$opp.c = scale(DF.surv2$opp,
                       scale = F) %>% as.numeric()
DF.surv2$bel.c = scale(DF.surv2$bel,
                       scale = F) %>% as.numeric()
```

# Export
When sensitivity analyses are performed, there will be a token variable created called "sens". If this variable does not exist (i.e., it isn't a sensitivity analysis) export the main data as the official clean version.
```{r}
if(!exists("sens")){
  write.csv(DF, 
            "data/metaware_meta_clean.csv", 
            row.names = F)
}
```

Export replication study dataset
```{r}
write.csv(DF.surv2,
          "data/metaware_replication_clean.csv",
          row.names = F)
```
