---
title: Data analysis for "A meta-analysis of the effects of demand characteristics in non-clinical research"
author: "Nicholas A. Coles and Morgan Wyatt"
editor_options: 
  chunk_output_type: console
---
The code was written in `r R.version$version.string` using R Markdown (http://rmarkdown.rstudio.com/).

# Section 1: Data Prep
```{r setup and load packages, include = FALSE}
# clean environment
rm(list = ls())

# load packages
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    
    sapply(pkg, require, character.only = TRUE)
}

# call package function
packages <- c('metafor', 'tidyverse', 'PublicationBias',
              'readxl', 'robumeta', 'MAd')
ipak(packages)
rm(packages, ipak)

# turn scientific notation off
options(scipen = 999)

# do we need Type 3 SS?
```

## Open and clean data
```{r open/clean data, message = FALSE, warning = FALSE}
# import data
DF <- read_xlsx(path = "metaware_data_raw.xlsx",
                sheet = "coding",
                na = c("NA"))

# delete unnecessary variables
DF <- DF %>% 
  
  # remove reference columns
  select(-ends_with("ref")) %>% 
  
  # remove variables we won't include in any analyses
  select(-c(prop.woman, age, dv, note)) %>% 
  
  # convert factors to factors
  mutate(id = as.factor(id),
         published = as.factor(published),
         student = as.factor(student),
         paid = as.factor(paid),
         online = as.factor(online),
         ref.type = as.factor(ref.type))

# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the 
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA

# record by year
tmp <- DF %>% 
  distinct(id,
           .keep_all = T)

tmp$year %>% 
  hist(breaks = seq(from = 1960, 
                  to = 2022,
                  by = 2))

rm(tmp)
```

# Calculate Cohen's *d* and variance
## For between-subjects data
### Functions for calculating *d* 
#### When *M*'s and *SD*'s are provided
```{r define function EsBetwMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1, 
                       n.2, m.2, sd.2){
    sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
                       ((n.2 - 1) * (sd.2^2))) /
                        (n.1 + n.2 - 2));
    
    es <- (m.1 - m.2) / sd.within;
    return(es)
}
```

#### When t-values are provided
```{r define function EsBetwTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
    es <- tval * sqrt((n.1 + n.2) / 
                      (n.1 * n.2));
    return(es)
}
```

#### When F-values are provided
```{r define function EsBetwFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
  es <- sqrt((fval * (n.1 + n.2)) / 
             (n.1 * n.2)); 
    return(es)
  }
```

#### When p-values are provided
```{r define function EsBetwPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval){
  # calculate the inverse of the cumulative distribution function of t
  t.inv <- qt(p = (pval / 2), 
              df = (n.1 + n.2 - 2),
              lower.tail = FALSE);
  
  es <- t.inv * sqrt((n.1 + n.2) /
                     (n.1 * n.2));
  return(es)
}
```

### Function for calculating variance of *d* with continuous data
```{r define function EsVarBetw}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){       
   es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
             ((es^2) / (2 * (n.1 + n.2)));
   return(es.var)
}
```

### Functions for calculating *d* and variance of *d* with count data
```{r define functions EsBetwCount and EsVarBetwCount}
# cohen's d
EsBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.8
  or <- (count.1 * (n.2 - count.2)) / 
        ((n.1 - count.1) * count.2);
  
  # calculate log odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.9
  log.or = log(or);
  
  # convert log odds ratio to Cohen's d
  # formula: Borenstein et al. 2011; p . 47 Equation 7.1
  es <- log.or * (sqrt(3) / pi);
  return(es)
}

# variance of cohen's d
EsVarBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate log odds ratio variance
  # formula: Borenstein et al. 2011; p. 36; Equation 5.10
  log.or.var = (1 / count.1) +
               (1 / (n.2 - count.2)) +
               (1 / (n.1 - count.1)) +
               (1 / count.2);
  
  # convert log odds ratio variance to variance of Cohen's d
  # formula: Borenstein et al. 2011; p. 47 Equation 7.2
  es.var = log.or.var * (3 / pi^2);
  return(es.var)
}
```

### Call functions to calculate d and variance of *d*
```{r b: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "between"){
    
    # call EsBetwMean on cases with between-subject designs and *means*
    if (DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsBetwMean(n.1 = DF$n.1[i],
                             m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             n.2 = DF$n.2[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i]) 
      } 
    # call EsBetwTval on cases with between-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsBetwTval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             tval = DF$tval[i])
      }
    
    # call EsBetwFval on cases with between-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsBetwFval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             fval = DF$fval[i])
    }
    
    # call EsBetwPval on cases with between-subject designs and *p-values*
    if (DF$es.calc[i] == "p") {
      DF$es[i] <- EsBetwPval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             pval = DF$pval[i])
    }
    
    # call EsBetwCount and EsVarBetwCount on cases with between-subject designs and *count data*
    if (DF$es.calc[i] == "or") {
      DF$es[i] <- EsBetwCount(n.1 = DF$n.1[i],
                              n.2 = DF$n.2[i],
                              count.1 = DF$count.1[i],
                              count.2 = DF$count.2[i])
      
      DF$es.var[i] <- EsVarBetwCount(n.1 = DF$n.1[i],
                                     n.2 = DF$n.2[i],
                                     count.1 = DF$count.1[i],
                                     count.2 = DF$count.2[i])
    }
    
    # call EsVarBetw on cases with continuous data and a between subject designs
    if (DF$es.calc[i] != "or"){
      DF$es.var[i] <- EsVarBetw(n.1 = DF$n.1[i],
                                n.2 = DF$n.2[i],
                                es = DF$es[i])
    }
    }
}
```

## For within-subjects data
```{r assumed correlation}
# define assumed correlation (sensitivity analyses performed later)
corr <- .5
```

### Functions for calculating d
#### When M's and SD's are provided 
```{r EsWitnMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
# formula for imputing sd.diff:
# http://handbook.cochrane.org/chapter_16/16_4_6_1_mean_differences.htm
EsWitnMean <- function(m.1, sd.1, m.2, sd.2, corr){
  sd.diff <- sqrt((sd.1^2) + (sd.2^2) -
                  (2 * corr * sd.1 * sd.2));
        
  es <- ((m.1 - m.2) / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

#### When t-values are provided
```{r EsWitnTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnTval <- function(n.1, tval, corr){
  es <- tval * sqrt((2 * (1 - corr)) / n.1);
  return(es)
}
```

#### When F-values are provided
```{r EsWitnFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnFval <- function(n.1, fval, corr){
  es <- sqrt((2 * fval * (1- corr)) / n.1);
  return(es)
}
```

### Function for calculating variance of d
```{r EsVarWitn}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsVarWitn <- function(n.1, es){
  es.var <- ((1 / n.1) + 
             ((es^2) / (2 * n.1))) *
            2 * (1 - corr);
  return(es.var)
}
```

### Call functions to calculate d and variance of d
```{r w: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "within"){
    
    # call EsWitnMean on cases with within-subject designs and *means*
    if(DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsWitnMean(m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i],
                             corr = corr)
    }
    
    # call EsWitnTval on cases with within-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsWitnTval(n.1 = DF$n.1[i],
                             tval = DF$tval[i],
                             corr = corr)
  }  
    
    # call EsWitnFval on cases with within-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsWitnFval(n.1 = DF$n.1[i],
                             fval = DF$fval[i],
                             corr = corr)
    }
    
    # call EsVarWitn on cases with within subject designs
    DF$es.var[i] <- EsVarWitn(n.1 = DF$n.1[i],
                              es = DF$es[i])
    }
  }
  
```

```{r del var}
# delete unnecessary variables
rm(corr, i,
   EsBetwFval, EsBetwMean, EsBetwTval,
   EsBetwPval, EsVarBetw, EsVarWitn,
   EsWitnFval, EsWitnMean, EsWitnTval,
   EsBetwCount, EsVarBetwCount)
```

## Delete id 18 because it's a MASSIVE outlier
```{r}
DF <- DF %>% 
  filter(id != 18)
```

## Specify direction
This direction of the effect was coded for in the raw database, and this code ensures that all effects are in the correct direction.
```{r specify es direction}
DF <- DF %>% 
  # specify direction of the effect size
  rowwise() %>% 
  mutate(es = if_else(condition = direction == "positive",
                      true = abs(es),
                      false = abs(es) * -1)
         ) %>% 
  ungroup()
```

# Export
```{r}
write.csv(DF %>% 
            filter(!is.na(es)), 
          'metaware.data_clean.csv', 
          row.names = FALSE)
```

# Data analysis
## Overall effect
```{r}
overall <- 
  robu(formula = es ~ 1,
       data = DF, 
       studynum = id,
       var.eff.size = es.var,
       modelweights = "HIER",
       small = FALSE)
```

## Moderator analyses
Prep analyses
```{r}
# create blank dataframe
mod.r <- data.frame(mod = character(),
                    level = character(),
                    s = integer(),
                    k = integer(),
                    d = integer(),
                    f = integer(),
                    CI95 = character(),
                    p = integer())

# create list of moderators
mod.l <- c("student", "paid", "online", 
           "design", "ref.type", "published")
```

Create function for moderator analysis
```{r}
ModAnalysis <- function(mod){
  # fit model
  m <- rma.uni(yi = es,
               vi = es.var,
               data = DF,
               mods = as.formula(paste0("~ ", mod)),
               method = "REML") %>%
    robust(cluster = DF$id)
  
  # append to moderator analysis results dataframe
  mod.r <<- 
    rbind(mod.r,
          cbind(mod = mod,
                level = NA,
                s = m$n,
                k = m$k,
                d = NA,
                f = round(m$QM, 
                          2),
                CI95 = NA,
                p = round(m$QMp,
                          4))
          )
}
```

Create subgroup analysis function
```{r}
SubAnalysis <- function(df, level, mod){
  # fit subgroup model
  m <- rma.uni(yi = es,
               vi = es.var,
               data = df,
               method = "REML")
  
  # run cluster-robust analysis if there are enough observations
   if(nrow(df) > 1){ 
     m <- robust(m, cluster = df$id)
     }
  
  # append to moderator analysis results dataframe
  mod.r <<- 
    rbind(mod.r,
          cbind(mod = mod,
                level = level,
                s = ifelse(nrow(df) > 1,
                           m$n,
                           NA),
                k = m$k,
                d = round(m$b[1],
                          2),
                f = NA,
                CI95 = paste0("[", 
                              round(m$ci.lb,
                                    2),
                              ", ",
                              round(m$ci.ub, 
                                    2),
                              "]"),
                p = round(m$pval,
                          4))
          )
}
```

Run moderator and subgroup analyses
```{r}
# DF <- DF %>% 
#   filter(name != "Demand effects in survey experiments: An empirical assessment")

for (mod in mod.l){
  ModAnalysis(mod = mod)
  
  mapply(FUN = SubAnalysis,
         df = split(DF, DF[, mod]),
         level = names(split(DF, DF[, mod])),
         mod = mod)
}
```

## Publication bias analyses
Funnel plot
```{r}
rma.uni(yi = es,
        vi = es.var,
        data = DF,
        method = "REML") %>% 
  robust(cluster = DF$id) %>% 
  funnel()
```

PET-PEESE and 3PSM
```{r}
# aggregate dependent effect sizes
DF.AGG <- agg(id = id,
              es = es,
              var = es.var,
              method = "BHHR",
              cor = .5, 
              data = DF)
  
# PET-PEESE models
## syntax provided by Carter & McCullough, 2014
##  first compute standard error of es
DF.AGG$se <- sqrt(DF.AGG$var)

### create models
pet <-   lm(DF.AGG$es ~ DF.AGG$se, 
             weights = 1 / DF.AGG$var) %>% summary()
peese <- lm(DF.AGG$es ~ DF.AGG$var, 
             weights = 1 / DF.AGG$var) %>% summary()
  
# Vevea and Hedges (1995) Weight-Function Model
weight.funct <- weightfunct(effect = DF.AGG$es,
                            v = DF.AGG$var,
                            mods = NULL,
                            weights= NULL,
                            fe = FALSE,
                            table = TRUE,
                            pval = NULL)

# Mathur and VanderWeele 2020 sensitivity analyses
corrected_meta(yi = DF$es,
               vi = DF$es.var,
               eta = 13,
               clustervar = DF$id,
               model = "robust",
               favor.positive = T,
               )

significance_funnel(yi = DF$es,
                    vi = DF$es.var,
                    favor.positive = T)
```
