---
title: Check progress on vignettes
author: "Anonymous for peer review; NAC"
editor_options: 
  chunk_output_type: console
---
On May 29, 2024, we began preparing to collect additional data using our vignette paradigm.

The main goal of this follow-up data collection effort is to increase and equalize the number of participants who viewed each vignette. As shown below, our first batch of data collection revealed that the ratings are not highly reliable across participants. This first batch also revealed that the Qualtrics randomization function did not force equal cell counts, leading to large discrepancies in the number of participants who viewed each vignette.

# Prep environment
```{r}
# clean environment
rm(list = ls())

# load packages
library("tidyverse")
library("here")
library("lme4")
library("presize")

# specify directory structure
i_am("admin/vig/metaware_AssessVigProgress.Rmd")
```

# Open and clean vignette rating data
```{r}
DF.surv <- read_csv(file = here("data/metaware_SurvData_raw.csv")) %>%
  
  # remove unnecessary variables
  select(-c(StartDate : UserLanguage),
         -c(hap1_bl1_hap : survey_order),
         -contains("Click"),
         -contains("Submit"),
         -contains("Count")) %>% 
  
  # remove row containing ImportId
  filter(!grepl("ImportId", `1_awr`)) %>% 
  
  # assign participant ids
  mutate(ss = 1 : nrow(.),
         ss = as.character(ss)) %>%  
  
  # select columns containing information from the vignettes
  select(`1_awr` : `119_opp`, ss) %>% 
  
  # extract vignette identifier from the first row of data
  # note: I warned you the data structure is awkward
  mutate_all(~if_else(condition = grepl("#", .),
                      true = substr(x = .,
                                    start = 2,
                                    stop = 9),
                      false = .))

# append first row (containing vignette identifiers) to the column name
## append name
colnames(DF.surv) <- paste(sep = "##",
                           colnames(DF.surv),
                           as.character(unlist(DF.surv[1, ]))
                           )

## remove the first row
### now that the vignette identifier has been added to the column name, we don't need this row anymore
DF.surv <- DF.surv[-1, ]

## fix ss (subject identifier) variable naming
DF.surv <- DF.surv %>% 
  rename("ss" = "ss##1")

# pivot data so that there is one row for each participants' rating of each vignette
DF.surv <- DF.surv %>% 
  # pivot longer
  pivot_longer(cols = contains("##"),
               names_to = c("var", "vig"),
               names_sep = "##") %>% 
  
  # extract variable name
  mutate(var = substr(x = var,
                      start = nchar(var) - 2,
                      stop = nchar(var))) %>% 
  
  # pivot wider
  pivot_wider(names_from = var,
              values_from = value) %>% 
  
  # convert columns to correct class
  mutate_at(c("awr", "mot", "opp", "bel", "pre"),
            as.numeric)
```


## Examine reliability of ratings
### Nicholas' approach (calculate ICC via mixed-effect model)
```{r}
# mot icc: .24
lmer(mot ~ 1 + (1 | ss) + (1 | vig),
     data = DF.surv) %>% 
  performance::icc(by_group = T)

# opp icc: .21
lmer(opp ~ 1 + (1 | ss) + (1 | vig),
     data = DF.surv) %>% 
  performance::icc(by_group = T)

# bel icc: .15
lmer(bel ~ 1 + (1 | ss) + (1 | vig),
     data = DF.surv)  %>% 
  performance::icc(by_group = T)
```

### Mike's approach (split-half)
```{r eval = F}
even <- DF.surv |>
  sample_frac(.5, replace = FALSE)

odd <- anti_join(DF.surv, even)

even <- even |>
  group_by(vig) |>
  summarise(mot_even = mean(mot, na.rm = TRUE), 
            bel_even = mean(bel, na.rm = TRUE))

odd <- odd |>
  group_by(vig) |>
  summarise(mot_odd = mean(mot, na.rm=TRUE), 
            bel_odd = mean(bel, na.rm = TRUE)) 

even_odd <- full_join(even, odd)

r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
```

### Alterantive approach: traditional ICC approach
```{r eval = F}
# structure dataframe for traditional icc approach
tmp <- DF.surv %>% 
  select(-c(dem, att.chk)) %>% 
  mutate(ss = as.numeric(ss)) %>% 
  arrange(vig) %>% 
  group_by(vig) %>% 
  mutate(ss = 1 : n()) %>% 
  ungroup() %>% 
  pivot_wider(names_from = ss,
              values_from = awr : opp)
  
library('irr')

# this gives NA, possibly there are too many NA's in those later cols
tmp %>% 
  select(mot_1 : mot_25) %>% 
  irr::icc(model="twoway", 
           type="agreement")

icc(anxiety, model  = "twoway", type = "agreement")

# here's how it looks when we remove columns until it fits
## mot: .13
tmp %>% 
  select(mot_1 : mot_22) %>% 
  irr::icc(model="twoway", 
           type="agreement")

## opp: .31
tmp %>% 
  select(opp_1 : opp_22) %>% 
  irr::icc(model="twoway", 
           type="agreement")

## bel: .18
tmp %>% 
  select(bel_1 : bel_22) %>% 
  irr::icc(model="twoway", 
           type="agreement")
```

## Evaluate how many observations are needed to increase precision
```{r}
# number of current participants (n = 222)
DF.surv$ss %>% unique %>% length

# number of vignettes (n = 119)
DF.surv$vig %>% unique %>% length

# number of ratings varies across vignettes (min = 8, max = 30)
DF.surv %>% 
  filter(!is.na(awr)) %>% 
  group_by(vig) %>% 
  summarise(n = n()) %>% 
  summarise(n.min = min(n),
            n.max = max(n),
            n.mean = mean(n))

# precision of estimates (overall: 1.24)
prec <- sapply(
  X = c("mot", "opp", "bel", "pre"),
  USE.NAMES = T,
  FUN = function(x){
    DF.surv %>% 
      filter(!is.na(get(x))) %>%
      group_by(vig) %>%
      summarise(n.est = n(),
                sd.est = sd(get(x)),
                se.est = sd.est / sqrt(n.est),
                imp = 2 * (1.96 * se.est)) %>% 
      summarise(m.imp = mean(imp)) %>% 
      return()
       }
  )

bind_rows(prec) %>% rowMeans() # overall precision

# estimate of sample needed to make precision = 1 (need 34 vignettes to get average precision to 1 for all measures)
prec <- sapply(
  X = c("mot", "opp", "bel", "pre"),
  USE.NAMES = T,
  FUN = function(x){
    
    # get M and SD
    desc <- DF.surv %>% 
      filter(!is.na(get(x))) %>%
      group_by(vig) %>%
      summarise(m.est = mean(get(x)),
                sd.est = sd(get(x))
                )
    
    # precision sample planning
    prec_mean(mean = desc$m.est,
              sd = desc$sd.est,
              conf.width = 1)$n %>% 
      mean() %>% 
      return()
       }
  )

bind_rows(prec) %>% max()

rm(prec)
```

## Compile information on how many vignette ratings we have
For the follow-up survey, we will adjust the sampling technique so that the number of ratings evens out
```{r}
sample <- DF.surv %>% 
  
  # see how many ratings per vignette we currently have
  filter(!is.na(mot)) %>% 
  group_by(vig) %>% 
  summarise(current_n = n()) %>% 
  
  # calculate how many observations we need to get sample to 35
  rowwise() %>% 
  mutate(needed_n = 35- current_n)

# total number of participants we need to recruit in follow up study: 220
sum(sample$needed_n) / 10  #  divide by 10 because each subject views 10 vignettes
```

## Export information
```{r}
# to maintain ordering, connect sample with DF. surv
sample.planning <- DF.surv %>% 
  # get one row per vignette
  distinct(vig) %>% 
  
  # join with sample
  full_join(x = .,
            y = sample,
            by = "vig")

write.csv(sample.planning,
          "metaware_VigSuppSamplePlanning.csv",
          row.names = F)
```

