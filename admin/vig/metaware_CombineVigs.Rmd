---
title: Combine vignettes into single data file
author: "Nicholas A. Coles (checked by Morgan H. Wyatt)"
editor_options: 
  chunk_output_type: console
---
For each study in the meta-analysis, we created vignettes for each demand characteristic condition and dependent variable combination. (E.g., if there were two demand characteristic conditions and two dependent variables, we created four vignettes.) These vignettes are stored in study-specific text files.

Each vignette contains three blocks of text that describe (1) the study context, (2) the researcher's stated hypothesis, and (3) the study procedures. To check whether [a future set of] raters understand the researcher's stated hypothesis, the vignette also contains a list of real and fake hypotheses.

This code compiles the vignettes into a single .csv file (metaware_VigCombined.csv), which was later imported into Qualtrics so that it could be reviewed and rated by a separate set of participants. This .csv file contains:
1. A unique vignette identifier, 
2. 3 columns containing 3 extracted blocks of text for each vignette,
3. 3 columns containing estimated reading times for each block of text, 
4. 4 columns containing real and fake hypotheses for each vignette.

# Prep environment
```{r}
# clean environment
rm(list = ls())

# load packages
library("tidyverse")
```

# Extract vignette blocks of text and estimate reading time
Get list of all vignette text files
```{r}
f.list <- list.files(path = "./vignettes",
                     pattern = ".txt")
```

Create blank dataframe to paste vignette info into
```{r}
v.DF <- data.frame()
```

Open each vignette file:
1. Extract vignette blocks of information
2. Compute reading time
3. Append to vignette info dataframe (v.DF)

If you want to follow this code, it helps to open a vignette text file to see how they were structured. id36_Demand2007.txt is a relatively simple one to reference.
```{r}
for (f in f.list){
 # open and process vignette file
  v <- 
    # open data
    read.delim(file = paste0("./vignettes/", f),
               col.names = "V1",
               encoding = "UTF-8") %>% 
    
    # remove non-vignette rows via slicing
    slice(
      # start at row after Vignette
      (which(. == "Vignette") + 1) : 
        
      # stop at end of file
      nrow(.)
      ) %>% 
    
    # identify vignette number
    mutate(V1 = if_else(grepl("#", .$V1),
                        substr(V1, 1, 9),
                        V1)
           ) %>% 
    
    # split at every new vignette
    split(cumsum(grepl("#", .$V1))
          ) %>% 
    
    # create separate column for each vignette
    map(c) %>% 
    bind_cols() %>% 
    
    # move first row to column names
    set_names(as.character(slice(., 1))) %>%
    slice(-1) %>% 
    
    # add sentence number column
    mutate(sent = seq.int(nrow(.))) %>% 
    
    # pivot longer
    pivot_longer(cols = -sent) %>% 
    
    # estimate reading time in milliseconds (400 words per minute)
    mutate(
      # estimate # of words
      word.num = str_count(value, "\\w+"),
      
      # estimate reading time 
      rt = (word.num / 400) * 60 * 1000
      ) %>% 
    
    select(-word.num) %>% 
    
    # pivot wider
    pivot_wider(names_from = sent,
                values_from = c(value, rt)) 
  
  # append results to v.DF
  v.DF <<- rbind(v.DF, v)
}

rm(f, v)
```

# Extract list of hypotheses
Create blank dataframe to paste results in
```{r}
h.DF <- data.frame()
```

Open each vignette file, extract hypotheses and append to h.DF
```{r}
for (f in f.list){
  h <- 
    # open data
    read.delim(file = paste0("./vignettes/", f),
               col.names = "V1",
               encoding = "UTF-8") %>% 
      
    # identify hypotheses using the ~ identifier
    filter(grepl("~", V1)) %>% 
    
    # separate hypothesis from key
    separate(V1,
             into = c("name", "hypothesis"),
             sep = 7)
  
  # append results to h.DF
  h.DF <<- rbind(h.DF, h)
}

rm(f, f.list, h)
```

# Merge dataframes containing hypotheses (h.DF) and vignette text/reading times (v.DF)
```{r}
# prep h.DF for merge (needs to be formatted similarly to v.DF)
h.DF <- h.DF %>% 
  mutate(id = substr(x = name,
                     start = 2,
                     stop = 3),
         dir = substr(x = name,
                      start = 5,
                      stop = 5)) %>% 
  select(-name) %>% 
  pivot_wider(names_from = dir,
              values_from = hypothesis)

# prep v.DF for merge (needs to be formatted similarly to h.DF)
v.DF <- v.DF %>% 
  mutate(id = substr(x = name,
                     start = 2,
                     stop = 3))

# merge
DF <- full_join(v.DF, h.DF,
                by = "id") %>%
    select(-id)

rm(h.DF, v.DF)
```

# Export data
```{r}
write.csv(DF, 'metaware_VigCombined.csv',
          row.names = F)
```
