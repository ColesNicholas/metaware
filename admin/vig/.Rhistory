(14 / 400) * 60
# specify directory structure
i_am("admin/vig/metaware_AssessVigProgress.Rmd")
library("here")
# clean environment
rm(list = ls())
# load packages
library("tidyverse")
library("here")
# specify directory structure
i_am("admin/vig/metaware_AssessVigProgress.Rmd")
read_csv(file = here("data/metaware_SurvData_test.csv"))
read_csv(file = here("data/metaware_SurvData.csv"))
read_csv(file = here("data/metaware_SurvData_raw.csv"))
DF.surv <- read_csv(file = here("data/metaware_SurvData_raw.csv")) %>%
# remove unnecessary variables
select(-c(StartDate : UserLanguage),
-c(hap1_bl1_hap : survey_order),
-contains("Click"),
-contains("Submit"),
-contains("Count")) %>%
# remove row containing ImportId
filter(!grepl("ImportId", `1_awr`)) %>%
# assign participant ids
mutate(ss = 1 : nrow(.),
ss = as.character(ss)) %>%
# select columns containing information from the vignettes
select(`1_awr` : `119_opp`, ss) %>%
# extract vignette identifier from the first row of data
# note: I warned you the data structure is awkward
mutate_all(~if_else(condition = grepl("#", .),
true = substr(x = .,
start = 2,
stop = 9),
false = .))
# append first row (containing vignette identifiers) to the column name
## append name
colnames(DF.surv) <- paste(sep = "##",
colnames(DF.surv),
as.character(unlist(DF.surv[1, ]))
)
## remove the first row
### now that the vignette identifier has been added to the column name, we don't need this row anymore
DF.surv <- DF.surv[-1, ]
## fix ss (subject identifier) variable naming
DF.surv <- DF.surv %>%
rename("ss" = "ss##1")
View(DF.surv)
# pivot data so that there is one row for each participants' rating of each vignette
DF.surv <- DF.surv %>%
# pivot longer
pivot_longer(cols = contains("##"),
names_to = c("var", "vig"),
names_sep = "##") %>%
# extract variable name
mutate(var = substr(x = var,
start = nchar(var) - 2,
stop = nchar(var))) %>%
# pivot wider
pivot_wider(names_from = var,
values_from = value) %>%
# convert columns to correct class
mutate_at(c("awr", "mot", "opp", "bel", "pre"),
as.numeric)
View(DF.surv)
lmer(mot ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
performance::icc(by_group = T)
library("lmer")
library("lme4")
lmer(mot ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
performance::icc(by_group = T)
lmer(opp ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
icc(by_group = T)
lmer(opp ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
performance::icc(by_group = T)
lmer(bel ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv)  %>%
performance::icc(by_group = T)
# number of participants (n = 222)
DF.surv$ss %>% unique %>% length
DF.surv$vig %>% unique %>% length
DF.surv %>%
filter(!is.na(awr)) %>%
group_by(vig) %>%
summarise(n = n()) %>%
summarise(n.min = min(n),
n.max = max(n),
n.mean = mean(n))
# precision of estimates
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
DF.surv %>%
filter(!is.na(get(x)),
att.chk == 1) %>%
group_by(vig) %>%
summarise(n.est = n(),
sd.est = sd(get(x)),
se.est = sd.est / sqrt(n.est),
imp = 2 * (1.96 * se.est)) %>%
summarise(m.imp = mean(imp)) %>%
return()
}
)
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(n.est = n(),
sd.est = sd(get(x)),
se.est = sd.est / sqrt(n.est),
imp = 2 * (1.96 * se.est)) %>%
summarise(m.imp = mean(imp)) %>%
return()
}
)
prec
bind_rows(prec) %>% rowMeans() # overall precision
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
# get M and SD
desc <- DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(m.est = mean(get(x)),
sd.est = sd(get(x))
)
# precision sample planning
prec_mean(mean = desc$m.est,
sd = desc$sd.est,
conf.width = 1)$n %>%
mean() %>%
return()
}
)
x = 'mot'
desc <- DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(m.est = mean(get(x)),
sd.est = sd(get(x))
)
desc
prec_mean(mean = desc$m.est,
sd = desc$sd.est,
conf.width = 1)
library("presize")
prec_mean(mean = desc$m.est,
sd = desc$sd.est,
conf.width = 1)$n %>%
mean()
rm(x)
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
# get M and SD
desc <- DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(m.est = mean(get(x)),
sd.est = sd(get(x))
)
# precision sample planning
prec_mean(mean = desc$m.est,
sd = desc$sd.est,
conf.width = 1)$n %>%
mean() %>%
return()
}
)
prec
bind_rows(prec) %>% max() # overall need
rm(prec)
rm(desc)
sample <- DF.surv %>%
# see how many ratings per vignette we currently have
filter(!is.na(mot)) %>%
group_by(vig) %>%
summarise(current_n = n()) %>%
# calculate how many observations we need to get sample to 35
rowwise() %>%
mutate(needed_n = 35- current_n) %>%
```
sample <- DF.surv %>%
# see how many ratings per vignette we currently have
filter(!is.na(mot)) %>%
group_by(vig) %>%
summarise(current_n = n()) %>%
# calculate how many observations we need to get sample to 35
rowwise() %>%
mutate(needed_n = 35- current_n)
View(sample)
sum(sample$needed_n) / 10  #  divide by 10 because each subject views 10 vignettes
?distinct
DF.surv <- DF.surv %>%
distinct(vig)
# Chunk 1
# clean environment
rm(list = ls())
# load packages
library("tidyverse")
library("here")
library("lme4")
library("presize")
# specify directory structure
i_am("admin/vig/metaware_AssessVigProgress.Rmd")
# Chunk 2
DF.surv <- read_csv(file = here("data/metaware_SurvData_raw.csv")) %>%
# remove unnecessary variables
select(-c(StartDate : UserLanguage),
-c(hap1_bl1_hap : survey_order),
-contains("Click"),
-contains("Submit"),
-contains("Count")) %>%
# remove row containing ImportId
filter(!grepl("ImportId", `1_awr`)) %>%
# assign participant ids
mutate(ss = 1 : nrow(.),
ss = as.character(ss)) %>%
# select columns containing information from the vignettes
select(`1_awr` : `119_opp`, ss) %>%
# extract vignette identifier from the first row of data
# note: I warned you the data structure is awkward
mutate_all(~if_else(condition = grepl("#", .),
true = substr(x = .,
start = 2,
stop = 9),
false = .))
# append first row (containing vignette identifiers) to the column name
## append name
colnames(DF.surv) <- paste(sep = "##",
colnames(DF.surv),
as.character(unlist(DF.surv[1, ]))
)
## remove the first row
### now that the vignette identifier has been added to the column name, we don't need this row anymore
DF.surv <- DF.surv[-1, ]
## fix ss (subject identifier) variable naming
DF.surv <- DF.surv %>%
rename("ss" = "ss##1")
# pivot data so that there is one row for each participants' rating of each vignette
DF.surv <- DF.surv %>%
# pivot longer
pivot_longer(cols = contains("##"),
names_to = c("var", "vig"),
names_sep = "##") %>%
# extract variable name
mutate(var = substr(x = var,
start = nchar(var) - 2,
stop = nchar(var))) %>%
# pivot wider
pivot_wider(names_from = var,
values_from = value) %>%
# convert columns to correct class
mutate_at(c("awr", "mot", "opp", "bel", "pre"),
as.numeric)
# Chunk 3
# mot icc: .24
lmer(mot ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
performance::icc(by_group = T)
# opp icc: .21
lmer(opp ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv) %>%
performance::icc(by_group = T)
# bel icc: .15
lmer(bel ~ 1 + (1 | ss) + (1 | vig),
data = DF.surv)  %>%
performance::icc(by_group = T)
# Chunk 6
# number of current participants (n = 222)
DF.surv$ss %>% unique %>% length
# number of vignettes (n = 119)
DF.surv$vig %>% unique %>% length
# number of ratings varies across vignettes (min = 8, max = 30)
DF.surv %>%
filter(!is.na(awr)) %>%
group_by(vig) %>%
summarise(n = n()) %>%
summarise(n.min = min(n),
n.max = max(n),
n.mean = mean(n))
# precision of estimates (overall: 1.24)
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(n.est = n(),
sd.est = sd(get(x)),
se.est = sd.est / sqrt(n.est),
imp = 2 * (1.96 * se.est)) %>%
summarise(m.imp = mean(imp)) %>%
return()
}
)
bind_rows(prec) %>% rowMeans() # overall precision
# estimate of sample needed to make precision = 1 (need 34 vignettes to get average precision to 1 for all measures)
prec <- sapply(
X = c("mot", "opp", "bel", "pre"),
USE.NAMES = T,
FUN = function(x){
# get M and SD
desc <- DF.surv %>%
filter(!is.na(get(x))) %>%
group_by(vig) %>%
summarise(m.est = mean(get(x)),
sd.est = sd(get(x))
)
# precision sample planning
prec_mean(mean = desc$m.est,
sd = desc$sd.est,
conf.width = 1)$n %>%
mean() %>%
return()
}
)
bind_rows(prec) %>% max()
rm(prec)
# Chunk 7
sample <- DF.surv %>%
# see how many ratings per vignette we currently have
filter(!is.na(mot)) %>%
group_by(vig) %>%
summarise(current_n = n()) %>%
# calculate how many observations we need to get sample to 35
rowwise() %>%
mutate(needed_n = 35- current_n)
# total number of participants we need to recruit in follow up study: 220
sum(sample$needed_n) / 10  #  divide by 10 because each subject views 10 vignettes
sample.planning <- DF.surv %>%
# get one row per vignette
distinct(vig)
?full_join
sample.planning <- DF.surv %>%
# get one row per vignette
distinct(vig) %>%
# join with sample
full_join(x = .,
y = sample,
by = "vig")
View(sample.planning)
write.csv(sample.planning,
"metaware_VigSuppSamplePlanning.csv",
row.names = F)
sample <- DF.surv %>%
# see how many ratings per vignette we currently have
filter(!is.na(mot)) %>%
group_by(vig) %>%
summarise(current_n = n()) %>%
# calculate how many observations we need to get sample to 35
rowwise() %>%
mutate(needed_n = 35- current_n)
# total number of participants we need to recruit in follow up study: 220
sum(sample$needed_n) / 10  #  divide by 10 because each subject views 10 vignettes
