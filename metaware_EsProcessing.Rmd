---
title: Process effect size data
author: "Nicholas A. Coles and Morgan Wyatt"
editor_options: 
  chunk_output_type: console
---
This code processes and merges the raw data contained in "metaware_ESData_raw.xlsx" and "metaware_SurvData_raw.csv"

# Prep environment
```{r setup and load packages, include = FALSE}
# load libraries
library("tidyverse")
library("readxl")
```

# Open and clean ES data
```{r open/clean data, message = FALSE, warning = FALSE}
# import data
DF <- read_xlsx(path = "data/metaware_EsData_raw.xlsx",
                sheet = "coding",
                na = c("NA"))

# change ref.type pvc to cvp (for aesthetics)
DF[DF$ref.type == "pvc", ]$ref.type = "cvp"

DF <- DF %>% 
  
  # remove reference columns
  select(-ends_with("ref")) %>% 
  
  # remove variables we won't include in any analyses
  select(-c(dv, note, outcome)) %>% 
  
  # create ref.r var that indicates whether there were one or two demand conditions
  mutate(ref.r = 
           if_else(ref.type == "cvp" |
                     ref.type == "nvc" |
                     ref.type == "cvz",
                   true = "single",
                   false = "double")) %>% 
  
  # create study and es_id columns
  rename(id.study = id) %>% 
  mutate(id.es = 1 : nrow(DF)) %>% 
  
  # convert factors to factors
  mutate(across(.cols = c(id.study, id.es, published, student,
                          paid, online, ref.type,
                          ref.r),
                .fns = as.factor)
         )

# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the 
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
```

## Calculate Cohen's *d* and variance
### For between-subjects data
#### Functions for calculating *d* 
##### When *M*'s and *SD*'s are provided
```{r define function EsBetwMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1, 
                       n.2, m.2, sd.2){
    sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
                       ((n.2 - 1) * (sd.2^2))) /
                        (n.1 + n.2 - 2));
    
    es <- (m.1 - m.2) / sd.within;
    return(es)
}
```

##### When t-values are provided
```{r define function EsBetwTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
    es <- tval * sqrt((n.1 + n.2) / 
                      (n.1 * n.2));
    return(es)
}
```

##### When F-values are provided
```{r define function EsBetwFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
  es <- sqrt((fval * (n.1 + n.2)) / 
             (n.1 * n.2)); 
    return(es)
  }
```

##### When p-values are provided
```{r define function EsBetwPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval){
  # calculate the inverse of the cumulative distribution function of t
  t.inv <- qt(p = (pval / 2), 
              df = (n.1 + n.2 - 2),
              lower.tail = FALSE);
  
  es <- t.inv * sqrt((n.1 + n.2) /
                     (n.1 * n.2));
  return(es)
}
```

#### Function for calculating variance of *d* with continuous data
```{r define function EsVarBetw}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){       
   es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
             ((es^2) / (2 * (n.1 + n.2)));
   return(es.var)
}
```

#### Functions for calculating *d* and variance of *d* with count data
```{r define functions EsBetwCount and EsVarBetwCount}
# cohen's d
EsBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.8
  or <- (count.1 * (n.2 - count.2)) / 
        ((n.1 - count.1) * count.2);
  
  # calculate log odds ratio
  # formula: Borenstein et al. 2011; p. 36; Equation 5.9
  log.or = log(or);
  
  # convert log odds ratio to Cohen's d
  # formula: Borenstein et al. 2011; p . 47 Equation 7.1
  es <- log.or * (sqrt(3) / pi);
  return(es)
}

# variance of cohen's d
EsVarBetwCount <- function(n.1, n.2, count.1, count.2){
  # calculate log odds ratio variance
  # formula: Borenstein et al. 2011; p. 36; Equation 5.10
  log.or.var = (1 / count.1) +
               (1 / (n.2 - count.2)) +
               (1 / (n.1 - count.1)) +
               (1 / count.2);
  
  # convert log odds ratio variance to variance of Cohen's d
  # formula: Borenstein et al. 2011; p. 47 Equation 7.2
  es.var = log.or.var * (3 / pi^2);
  return(es.var)
}
```

#### Call functions to calculate d and variance of *d*
```{r b: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "between"){
    
    # call EsBetwMean on cases with between-subject designs and *means*
    if (DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsBetwMean(n.1 = DF$n.1[i],
                             m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             n.2 = DF$n.2[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i]) 
      } 
    # call EsBetwTval on cases with between-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsBetwTval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             tval = DF$tval[i])
      }
    
    # call EsBetwFval on cases with between-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsBetwFval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             fval = DF$fval[i])
    }
    
    # call EsBetwPval on cases with between-subject designs and *p-values*
    if (DF$es.calc[i] == "p") {
      DF$es[i] <- EsBetwPval(n.1 = DF$n.1[i],
                             n.2 = DF$n.2[i],
                             pval = DF$pval[i])
    }
    
    # call EsBetwCount and EsVarBetwCount on cases with between-subject designs and *count data*
    if (DF$es.calc[i] == "or") {
      DF$es[i] <- EsBetwCount(n.1 = DF$n.1[i],
                              n.2 = DF$n.2[i],
                              count.1 = DF$count.1[i],
                              count.2 = DF$count.2[i])
      
      DF$es.var[i] <- EsVarBetwCount(n.1 = DF$n.1[i],
                                     n.2 = DF$n.2[i],
                                     count.1 = DF$count.1[i],
                                     count.2 = DF$count.2[i])
    }
    
    # call EsVarBetw on cases with continuous data and a between subject designs
    if (DF$es.calc[i] != "or"){
      DF$es.var[i] <- EsVarBetw(n.1 = DF$n.1[i],
                                n.2 = DF$n.2[i],
                                es = DF$es[i])
    }
    }
}
```

### For within-subjects data
```{r assumed correlation}
# if no correlation is defined, set it at .5
if(!exists("corr")){
  corr <- .5
}
```

#### Functions for calculating d
##### When M's and SD's are provided 
```{r EsWitnMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
# formula for imputing sd.diff:
# http://handbook.cochrane.org/chapter_16/16_4_6_1_mean_differences.htm
EsWitnMean <- function(m.1, sd.1, m.2, sd.2, corr){
  sd.diff <- sqrt((sd.1^2) + (sd.2^2) -
                  (2 * corr * sd.1 * sd.2));
        
  es <- ((m.1 - m.2) / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

##### When t-values are provided
```{r EsWitnTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnTval <- function(n.1, tval, corr){
  es <- tval * sqrt((2 * (1 - corr)) / n.1);
  return(es)
}
```

##### When F-values are provided
```{r EsWitnFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnFval <- function(n.1, fval, corr){
  es <- sqrt((2 * fval * (1- corr)) / n.1);
  return(es)
}
```

#### Function for calculating variance of d
```{r EsVarWitn}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsVarWitn <- function(n.1, es){
  es.var <- ((1 / n.1) + 
             ((es^2) / (2 * n.1))) *
            2 * (1 - corr);
  return(es.var)
}
```

#### Call functions to calculate d and variance of d
```{r w: call functions to calculate d}
for (i in 1:nrow(DF)) {
  if (DF$design[i] == "within"){
    
    # call EsWitnMean on cases with within-subject designs and *means*
    if(DF$es.calc[i] == "m_sd") {
      DF$es[i] <- EsWitnMean(m.1 = DF$m.1[i],
                             sd.1 = DF$sd.1[i],
                             m.2 = DF$m.2[i],
                             sd.2 = DF$sd.2[i],
                             corr = corr)
    }
    
    # call EsWitnTval on cases with within-subject designs and *t-values*
    if (DF$es.calc[i] == "t") {
      DF$es[i] <- EsWitnTval(n.1 = DF$n.1[i],
                             tval = DF$tval[i],
                             corr = corr)
  }  
    
    # call EsWitnFval on cases with within-subject designs and *F-values*
    if (DF$es.calc[i] == "f") {
      DF$es[i] <- EsWitnFval(n.1 = DF$n.1[i],
                             fval = DF$fval[i],
                             corr = corr)
    }
    
    # call EsVarWitn on cases with within subject designs
    DF$es.var[i] <- EsVarWitn(n.1 = DF$n.1[i],
                              es = DF$es[i])
    }
  }
  
```

```{r del var}
# delete unnecessary variables
rm(corr, i,
   EsBetwFval, EsBetwMean, EsBetwTval,
   EsBetwPval, EsVarBetw, EsVarWitn,
   EsWitnFval, EsWitnMean, EsWitnTval,
   EsBetwCount, EsVarBetwCount)
```

## Specify direction
This direction of the effect was coded for in the raw database, and this code ensures that all effects are in the correct direction.
```{r specify es direction}
DF <- DF %>% 
  # specify direction of the effect size
  rowwise() %>% 
  mutate(es = if_else(condition = direction == "positive",
                      true = abs(es),
                      false = abs(es) * -1)
         ) %>% 
  ungroup()
```

## Remove unnecessary variables
```{r}
DF <- DF %>% 
  select(-c(es.calc : pval))
```

# Open and clean survey data
```{r}
# import data
DF.surv <- read_csv(file = "data/metaware_SurvData_raw.csv") %>%
  
  # remove unnecessary variables
  select(-c(StartDate : UserLanguage),
         -c(hap1_bl1_hap : survey_order),
         -contains("Click"),
         -contains("Submit"),
         -contains("Count")) %>% 
  
  # remove row containing ImportId
  filter(!grepl("ImportId", `1_awr`)) %>% 
  
  # assign participant ids
  mutate(ss = 1 : nrow(.),
         ss = as.character(ss)) %>%  
  
  # select vignettes columns
  select(`1_awr` : `119_opp`, ss) %>% 
  
  # extract key from first row
  mutate_all(~if_else(condition = grepl("#", .),
                      true = substr(x = .,
                                    start = 2,
                                    stop = 9),
                      false = .))

# append first row to column name
## append name
colnames(DF.surv) <- paste(sep = "##",
                           colnames(DF.surv),
                           as.character(unlist(DF.surv[1, ]))
                           )

## remove first row
DF.surv <- DF.surv[-1, ]

## fix ss variable naming
DF.surv <- DF.surv %>% 
  rename("ss" = "ss##1")

# prep dataframe for summary statistics calculation
DF.surv <- DF.surv %>% 
  # pivot longer
  pivot_longer(cols = contains("##"),
               names_to = c("var", "vig"),
               names_sep = "##") %>% 
  
  # extract variable name
  mutate(var = substr(x = var,
                      start = nchar(var) - 2,
                      stop = nchar(var))) %>% 
  
  # pivot wider
  pivot_wider(names_from = var,
              values_from = value) %>% 
  
  # convert columns to correct class
  mutate_at(c("awr", "mot", "opp", "bel", "pre"),
            as.numeric)
```

## Process attention checks
Specify whether participants correctly identified the communicated hypothesis
Note: awr should be 1, 2, and 3 for pos, neg, and nil respectively
```{r}
DF.surv <- DF.surv %>% 
  
  # identify whether the demand condition was pos, neg, or nil
  mutate(dem = substr(x = vig,
                      start = 4,
                      stop = 4))
  
## set att.chk to 0 (false) by default
DF.surv$att.chk = 0

## set att.chk to 1 when hypothesis is correctly identified
DF.surv[DF.surv$dem == "p" & 
      !is.na(DF.surv$awr) &
      DF.surv$awr == 1, ]$att.chk = 1

DF.surv[DF.surv$dem == "n" & 
      !is.na(DF.surv$awr) &
      DF.surv$awr == 2, ]$att.chk = 1

DF.surv[DF.surv$dem == "z" & 
      !is.na(DF.surv$awr) &
      DF.surv$awr == 3, ]$att.chk = 1

## if participants did not specify a  hypothesis, set att.chk to NA
DF.surv[is.na(DF.surv$awr), ]$att.chk = NA

## manually fix 28_p_dis
## there were some oddities in how we created this vignette--but the correct hypothesis would be 2 (not 1)
DF.surv[DF.surv$vig == "28_p_dis" &
          !is.na(DF.surv$awr) &
          DF.surv$awr == 2, ]$att.chk = 1

## re-examination of 36_n_won suggested it was poorly worded (we meant to convey that it would hinder performance, but many people thought we meant it would improve performance)
```

Examine attention check data
```{r}
# overall
DF.surv %>%
  summarise(m = mean(att.chk,
                     na.rm = T))

# split by demand type
DF.surv %>%
  group_by(dem) %>%
  summarise(m = mean(att.chk,
                     na.rm = T))

# split by vignette
DF.surv %>% 
  group_by(vig) %>% 
  filter(!is.na(att.chk)) %>% 
  summarise(n = n(),
            m = mean(att.chk)) %>% 
  arrange(m) %>% 
  View()
```

Limit to observations where attention check was passed
```{r}
DF.surv <- DF.surv %>% 
  filter(att.chk == 1)
```

## Calculate summary statistics
```{r}
surv.sum <- DF.surv %>% 
  group_by(vig) %>% 
  summarise(m.mot = mean(mot, na.rm = T),
            m.opp = mean(opp, na.rm = T),
            m.bel = mean(bel, na.rm = T),
            m.pre = mean(pre, na.rm = T)
            ) %>% 
  ungroup()

rm(DF.surv)
```

# Combine ES and survey data
```{r}
# connect summary data to ES dataframe
DF <- DF %>% 
  # rename vig.1 to vig to enable join
  rename(vig = vig.1) %>% 
  
  # connect summary data to vig.1
  left_join(x = ., 
            y = surv.sum,
            by = "vig") %>% 
  
  # rename vig.1 summary columns
  rename(v1.mot = m.mot, 
         v1.opp = m.opp, 
         v1.bel = m.bel, 
         v1.pre = m.pre) %>% 
  
  # rename vig.2 to vig to prep for join
  rename(vig.1 = vig,
         vig = vig.2) %>% 
  
  # connect summary data to vig.2
  left_join(x = .,
            y = surv.sum,
            by = "vig") %>% 
  
  # rename vig.2 summary columns
  rename(v2.mot = m.mot, 
         v2.opp = m.opp, 
         v2.bel = m.bel, 
         v2.pre = m.pre) %>% 
  
  # sum motivation, opportunity, belief, and prediction scores
  rowwise() %>% 
  mutate(mot = sum(c(v1.mot, v2.mot), 
                   na.rm = T),
         opp = sum(c(v1.opp, v2.opp), 
                   na.rm = T),
         bel = sum(c(v1.bel, v2.bel), 
                   na.rm = T),
         pre = sum(c(v1.pre, v2.pre), 
                   na.rm = T)) %>% 
  ungroup()

rm(surv.sum)

# tmp code: if  no vignette ratings exist, leave mot to pre blank
DF[is.na(DF$v1.mot), ]$mot = NA
DF[is.na(DF$v1.mot), ]$opp = NA
DF[is.na(DF$v1.mot), ]$bel = NA
DF[is.na(DF$v1.mot), ]$pre = NA

# arrange variables
DF <- DF %>% 
  select(id.study, id.es, 
         name : ref.r, 
         es, es.var,
         mot : pre)
```

# Prep dataset for second part of survey
```{r}
# import data
DF.surv2 <- 
  read_csv(file = "data/metaware_SurvData_raw.csv")

# remove rows containing unnecessary variable details
DF.surv2 <- DF.surv2[-(1 : 2), ]

# process data
DF.surv2 <- DF.surv2 %>%
  
  # identify relevant variables
  select(
    # block 1 happy pose emotion reports
    hap1_bl1_hap : hap1_bl1_enj,
    
    # block 1 neutral pose emotion reports
    neu1_bl1_hap : neu1_bl1_enj,
    
    # block 2 happy pose emotion reports
    hap2_bl2_hap : hap2_bl2_enj,
    
    # block 2 neutral pose emotion reports
    neu2_bl2_hap : neu2_bl2_enj,
    
    # motivation, prediction, belief, and opportunity scores
    mot : opp, mot_gen,
    
    # manipulation check items (awareness and attention checks)
    hap1_bl1_att, hap2_bl2_att, neu1_bl1_att, neu2_bl2_att,
    awr,
    
    # condition and individual difference items
    demand,
    indiv_gend_var, indiv_agee_var, ethnicity,
    
    # relevant vignette data
    `46_awr` : `46_opp`,
    `47_awr` : `47_opp`) %>% 
  
  # rename vignette variables
  rename(pos_awr = `46_awr`,
         pos_mot = `46_mot`,
         pos_pre = `46_pre`,	
         pos_bel = `46_bel`,
         pos_opp = `46_opp`,
         
         nil_awr = `47_awr`,
         nil_mot = `47_mot`,
         nil_pre = `47_pre`,	
         nil_bel = `47_bel`,
         nil_opp = `47_opp`) %>% 
  
  # add subid variable
  mutate(sub = factor(1 : nrow(.))) %>% 
  
  # identify whether attention checks were all passed
  mutate(att.chk = 
           if_else(condition = 
                     hap1_bl1_att == "5" &
                     neu1_bl1_att == "5" &
                     hap2_bl2_att == "5" &
                     neu2_bl2_att == "5",
                   true = 1,
                   false = 1)
         ) %>% 
  
  # create separate rows for each trial 
    # 1. Gather emotion reports into a single column
    gather(key = "dv", 
           value = "value",
           hap1_bl1_hap : neu2_bl2_enj) %>% 
  
    # 2. Create separate variables that identify the trial and outcome using "_..._ naming convention separator
    separate(col = "dv", 
             into = c("trial", "outcome"),
             sep = "_..._") %>%
    
    # 3. Spread outcomes into individual rows
    pivot_wider(names_from = "outcome",
                values_from = "value") %>% 
  
  # fix variable types
  mutate_at(.vars = c("mot", "pre", "bel", "opp",
                      "mot_gen", "indiv_agee_var", 
                      
                      "hap", "sat", "enj",
                      
                      "pos_awr", "pos_mot",
                      "pos_pre", "pos_bel",
                      "pos_opp",
                      
                      "nil_awr", "nil_mot",
                      "nil_pre", "nil_bel",
                      "nil_opp"),
            .funs = as.numeric) %>%
  
  mutate_at(.vars = c("demand", "indiv_gend_var",
                      "ethnicity", "sub"),
            .funs = as.factor) %>% 
  
  # Calculate self-reported happiness scores
  rowwise() %>%
  mutate(happy = mean(c(hap, sat, enj))) %>% 
  ungroup() %>% 
  
  # identify block number
  mutate(block.num = if_else(condition = trial == "hap1" |
                                         trial == "neu1",
                             true = 1,
                             false = 2),
         block.num = factor(block.num)) %>% 
  
  # create new trial variable that remove redundant information about block
  mutate(trial = substr(x = trial, 
                        start = 1, 
                        stop = 3),
         trial = factor(trial)) %>% 
  
  # organize dataframe
  arrange(sub, block.num, trial) %>% 
  select(sub, demand, trial, block.num, happy, 
         att.chk, awr,
         mot : mot_gen,
         indiv_gend_var : ethnicity,
         pos_awr : nil_opp)
```

# Export
When sensitivity analyses are performed, there will be a token variable created called "sens". If this variable does not exist (i.e., it isn't a sensitivity analysis) export the main data as the official clean version.
```{r}
if(!exists("sens")){
  write.csv(DF, 
            "data/metaware_data_clean.csv", 
            row.names = F)
}
```

Export second survey dataset
```{r}
write.csv(DF.surv2,
          "data/metaware_survey2_clean.csv",
          row.names = F)
```

# prelimin analyses
Note that your belief question is a bit hard to interpret for this study.

In the nil-hypothesis condition, what exactly does it mean to think tha tthey hypothesized effect is true/untrue? Is the hypothesized effect the nil or non-nil effect?

The convergent validity analyses have very few n. Not sure if we're going to learn anything there.
```{r}
library(lme4)
library(lmerTest)
library(emmeans)

# convergent validity analyses
DF.pos <- DF.surv2 %>% 
  filter(demand == "pos")

DF.nil <- DF.surv2 %>% 
  filter(demand == "nil")

cor(DF.pos$pos_mot, DF.pos$mot,
    use = "pairwise.complete.obs")

cor(DF.nil$nil_mot, DF.nil$mot,
    use = "pairwise.complete.obs")

rm(DF.pos, DF.nil)

# test facial feedback by demand interaction
m <- lmer(happy ~ trial * block.num * demand + 
            (1 | sub),
          data = DF.surv2)

anova(m)

emmeans(m, 
        pairwise ~ trial)

joint_tests(m, by = "demand")

# belief
DF.surv2 %>% 
  group_by(demand) %>% 
  summarise(m.bel = mean(bel,
                         na.rm = T))
lm(bel ~ demand,
   data = DF.surv2) %>% 
  anova()

lmer(happy ~ trial + block.num + bel + 
            (trial : bel) +
            (1 | sub),
          data = DF.surv2) %>% 
  anova()

# motivation
## need to recode motivation for the nil hypothesis condition
DF.surv2 <- DF.surv2 %>% 
  rowwise() %>% 
  mutate(mot = if_else(demand == "nil",
                       mot * (-1),
                       mot))

lmer(happy ~ trial + block.num + mot + 
            (trial : mot) +
            (1 | sub),
          data = DF.surv2) %>% 
  anova()

# interactions
m <- lmer(happy ~ trial + block.num + demand + 
            (trial : demand) + 
            (trial : demand : mot) +
            (1 | sub),
          data = DF.surv2)

anova(m)

m <- lmer(happy ~ trial + block.num + demand + 
            (trial : demand) + 
            (trial : demand : bel) +
            (1 | sub),
          data = DF.surv2)

anova(m)

m <- lmer(happy ~ trial + block.num + demand + 
            (trial : demand) + 
            (trial : demand : opp) +
            (1 | sub),
          data = DF.surv2)

anova(m)

# new simpler belief and motivation analyses


```


Need to save these two columns:
12_p_hap
12_z_hap
