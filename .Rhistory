even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE))
even_odd <- full_join(even, odd)
r = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
(2 * r)/(1 + r)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
even <- DF.surv |>
sample_frac(.5, replace = FALSE)
odd <- anti_join(DF.surv, even)
even <- even |>
group_by(vig) |>
summarise(mot_even = mean(mot, na.rm = TRUE),
bel_even = mean(bel, na.rm = TRUE))
odd <- odd |>
group_by(vig) |>
summarise(mot_odd = mean(mot, na.rm=TRUE),
bel_odd = mean(bel, na.rm = TRUE))
even_odd <- full_join(even, odd)
r_mot = cor.test(even_odd$mot_even, even_odd$mot_odd)$estimate
r_bel = cor.test(even_odd$bel_even, even_odd$bel_odd)$estimate
(2 * r_mot)/(1 + r_mot)
(2 * r_bel)/(1 + r_bel)
DF.surv$ss
length(unique(DF.surv$ss))
hist(even$mot_even)
hist(even$bel_even)
hist(even$mot_even)
sd(even$mot_even)
sd(even$bel_even)
hist(even$mot_even)
# Chunk 1: setup
# load writing and data processing packages
library("papaja")
library("tidyverse")
library("readxl")
library("cowplot")
# load meta-analyses packages
library("metafor")
library("weightr")
library("PublicationBias")
# load mixed-effect regression packages
library("lme4")
library("lmerTest")
library("emmeans")
# identify paper references
r_refs("r-references.bib")
# turn scientific notation off
options(scipen = 999)
# set seed to year of lead author's favorite [unfinished] album, SMiLE
set.seed(1967)
# set theme
theme_set(theme_classic())
# Chunk 3: framework
knitr::include_graphics("images/metaware_framework.png")
# Chunk 4: literature search
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_EsData_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation =
if_else(condition = grepl("dissertation", link),
true = 1,
false = 0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# Chunk 5: final.df
# open clean effect size data
DF.es <-
read_csv(file = "data/metaware_meta_clean.csv")
# identify total number of studies (denoted by id.study column)
num.s <- DF.es$id.study %>%
unique() %>%
length()
# identify total number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
# for the known outlier (id = 18), give an example of the largest effect size
outlier.es <- DF.es %>%
filter(id.study == 18) %>%
summarise(max.es = min(es)) %>% #  using min because largest value is neg
round(2)
# Chunk 6: clean.env.1
# remove outlier and re-initialize id factors
DF.es <- DF.es %>%
filter(id.study != 18) %>%
mutate(id.study = factor(id.study),
id.es = factor(id.es))
# clean environment
rm(DF.s, r.pi, r.unp, num.s, num.p, outlier.es)
# Chunk 7: corr.sens
# examine how assumed repeated measures correlation impacts general pattern of results
# get list of sensitivity dataframes
sens.df.list <- list.files(path = "./data/r_sensitivity")
# (1) open dataframe, (2) compute intercept-only model, (3) extract overall es
sens.res <-
sapply(X = sens.df.list,
FUN = function(i){
# open data
df <- read.csv(paste0("data/r_sensitivity/",
i)
)
# fit model
m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# return overall es as a number
m$b %>%
as.numeric() %>%
return()
}
)
# compute range of es values
sens.range <- max(sens.res) - min(sens.res)
# delete vestigial
rm(sens.df.list, sens.res)
# Chunk 8: mult.eff
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id.study) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(condition = n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as percentage
as.numeric() %>%
round(digits = 2) * 100
# Chunk 9: clean.env.2
# delete vestigial
rm(mult.eff.per, sens.range)
# Chunk 10: overall
# estimate overall effect size
overall <-
rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# estimate standard deviation of effect size distribution (i.e., Tau)
# to do so, combine both sources of estimated variability in the model
tau <- sqrt(overall$sigma2[1] + overall$sigma2[2])
# estimate proportion of hypothesis-consistent and inconsistent responding
# -0.10 < d > 0.10 is the arbitrary threshold for saying it's neither consistent or inconsistent
h.c <- pnorm(q = .10,
mean = overall$b,
sd = tau,
lower.tail = F) %>%
round(digits = 2) * 100
h.i <- pnorm(q = (-.10),
mean = overall$b,
sd = tau,
lower.tail = T) %>%
round(digits = 2) * 100
# estimate lower and upper bound of effect size distribution
dist <- rnorm(n = 1000000,
mean = overall$b,
sd = tau)
dist.min <- dist %>%
min() %>%
round(digits = 2)
dist.max <- dist %>%
max() %>%
round(digits = 2)
rm(dist)
# Chunk 12: forest
# create a temporary dataset containing effect sizes and 95% CI's
tmp <- DF.es %>%
rowwise() %>%
mutate(se = sqrt(es.var),
ub = es + (se * 1.96),
ub = round(ub, 2),
lb = es - (se * 1.96),
lb = round(lb, 2),
es = round(es, 2)) %>%
ungroup() %>%
arrange(es, id.study)
# create a forest plot w/ distribution overlay
ggplot(data= tmp,
aes(y = rev(1: nrow(tmp)) * 0.007692308,
x = es,
xmin = lb,
xmax = ub)) +
#hypothesis inconsistent effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "#F8766D",
alpha = .25,
xlim = c(-2, -.10)) +
# negligible effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "grey80",
alpha = .25,
xlim = c(-.10, .10)) +
# hypothesis consistent effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "#00998a",
alpha = .25,
xlim = c(.10, 2)) +
# create dotted line at d = 0
geom_vline(xintercept = 0,
color = "black",
linetype = "dotted",
alpha = .5,
size =.5)  +
# add points and error bars
geom_point(shape = "diamond",
size = 1,
alpha = .8,
color = "dark grey") +
geom_errorbarh(height = .005,
size = .1,
alpha = .8,
color = "dark grey") +
# add citation label
geom_text(aes(label = citation),
x = -2.7,
hjust = 0,
size = 1) +
# add CI label
geom_text(aes(label = paste0(es,
" [", lb, ", ", ub, "]")),
x = 3.9,
size = 1,
hjust = 1) +
labs(x = expression(paste("Cohen's ", italic("d"))),
y = "density") +
# increase plotting area
scale_x_continuous(limits = c(-2.7, 4),
breaks = seq(from = -2, to = 3, by = 1),
expand = c(.01, .01)) +
scale_y_continuous(expand = c(.005, 0))
# Chunk 13: mod
# create moderator analysis function
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t")
sub.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year")
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
# test ref.type moderator in scenarios where there is a control comparison (i.e., ref.r == single)
mod.r[["ref.type"]] <-
ModAnalysis(m = "ref.type",
df = DF.es[DF.es$ref.r == "single", ])
# add motivation, opportunity, belief, and prediction moderators
## Note: comparisons with nil-demand conditions are excluded
mod.r.2 <-
sapply(X = c("mot", "opp", "bel", "pre"),
simplify = F,
FUN = ModAnalysis,
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz"))
## combine results
mod.r = c(mod.r, mod.r.2)
# delete vestigial
rm(mod.r.2)
data.frame(s = NA)
data.frame(s = NULL)
DF.es$student %>% unique
mod.r$student$mod
mod.r$student$mod %>% View()
mod.r$student$mod.[["s.nlevels.f"]]
mod.r$student$mod[["s.nlevels.f"]]
mod.r$student$mod[["s.nlevels.f"]][[1]]
mod.r$student$mod[["QM"]]
mod.r$student$mod[["QM"]]
mod.r$student$mod[["QM"]] %>% round(2)
mod.r$student$mod %>% View()
mod.r$student$mod
mod.r$student$mod[["QMp"]]
cbind(`Moderator (bolded) and level` = "Student Status",
s = mod.r$student$mod[["s.nlevels.f"]][[1]],
k = mod.r$student$mod[["s.nlevels.f"]][[2]],
d = "--",
B1 = "--",
`F` = mod.r$student$mod[["QM"]] %>% round(2),
`95% CI` = "--",
p = mod.r$student$mod[["QM"]] %>% round(2))
DF <- fetch_survey(surveyID = 'SV_1YQ3FmlbEHp1RIO',
force_request = T,
label = F,
convert = F)
# fix known issues
DF <- DF %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1")
## --------------------------------------------------------------------------------------
# clear environment
rm(list = ls())
# install (if necessary) and load packages
# function written by stevenworthington
Ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, 'Package'])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# vector of necessary packages
packages <- c('tidyverse', 'ggplot2',
'qualtRics', 'googlesheets4')
# using vector of packages, call ipak function
Ipak(packages)
# delete vestigial
rm(packages, Ipak)
## --------------------------------------------------------------------------------------
# Dangs API credential at UCSD
qualtrics_api_credentials(
api_key = 'urh7PtWEEOkAzrbjmYQC2FoipCvCT4n8ZIByL5rH',
base_url = 'iad1.qualtrics.com',
install = TRUE,
overwrite = TRUE)
readRenviron("~/.Renviron")
## --------------------------------------------------------------------------------------
# fetch survey
DF <- fetch_survey(surveyID = 'SV_1YQ3FmlbEHp1RIO',
force_request = T,
label = F,
convert = F)
# fix known issues
DF <- DF %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1")
source("~/GlobalGratitudeProject/code/GlobalGratitude_updates.R", echo=TRUE)
DF %>% group_by(lab) %>% summarise(n = n())
DF %>% filter(is.na(lab)) %>% View()
DF %>% filter(is.na(lab)) %>% write.csv("tmp.csv", row.names = F)
getwd()
