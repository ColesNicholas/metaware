# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
# delete vestigial
rm(in.s, on.s, v.s, p.s,
m.s1, m.s2,
m.sens, m.sens.student, m.sens.online, m.sens.pay)
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- corrected_meta(yi = DF.es$es,
vi = DF.es$es.var,
eta = 49,
clustervar = DF.es$id.study,
model = "robust",
favor.positive = T)
# 2a. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 2b. cluster robust three-level precision-effect test
########################
pe.3l.r <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es) %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
pe.3l.r = pe.3l.r,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
pub.r$rho_0.5$pe.3l
pub.r$rho_0.5$pe.3l.r
# import data
DF.surv2 <-
read_csv(file = "data/metaware_SurvData_raw.csv")
# remove rows containing unnecessary variable details
DF.surv2 <- DF.surv2[-(1 : 2), ]
# hand recode gender
## list as unknown if they did not answer (or said they'd prefer not to answer)
DF.surv2[is.na(DF.surv2$indiv_gend_var), ]$indiv_gend_var = "unknown"
DF.surv2[DF.surv2$indiv_gend_var == "7", ]$indiv_gend_var = "unknown"
## recode rest
DF.surv2[DF.surv2$indiv_gend_var == "1", ]$indiv_gend_var = "female"
DF.surv2[DF.surv2$indiv_gend_var == "2", ]$indiv_gend_var = "male"
DF.surv2[DF.surv2$indiv_gend_var == "3", ]$indiv_gend_var = "trans_female"
DF.surv2[DF.surv2$indiv_gend_var == "4", ]$indiv_gend_var = "trans_male"
DF.surv2[DF.surv2$indiv_gend_var == "5", ]$indiv_gend_var = "gender_nonconforming"
# hand recode ethnicity
DF.surv2[is.na(DF.surv2$ethnicity), ]$ethnicity = "unknown"
DF.surv2[DF.surv2$ethnicity == "1", ]$ethnicity = "white_caucasian"
DF.surv2[DF.surv2$ethnicity == "2", ]$ethnicity = "black_african_american"
DF.surv2[DF.surv2$ethnicity == "3", ]$ethnicity = "american_indian"
DF.surv2[DF.surv2$ethnicity == "4", ]$ethnicity = "asian"
DF.surv2[DF.surv2$ethnicity == "5", ]$ethnicity = "native_pacific_islander"
DF.surv2[DF.surv2$ethnicity == "6", ]$ethnicity = "native_pacific_islander"
DF.surv2[DF.surv2$ethnicity == "6" |
DF.surv2$ethnicity == "1,6" |
DF.surv2$ethnicity == "1,2" |
DF.surv2$ethnicity == "1,4" |
DF.surv2$ethnicity == "2,6" |
DF.surv2$ethnicity == "7" |
DF.surv2$ethnicity == "1,3", ]$ethnicity = "other"
# process data
DF.surv2 <- DF.surv2 %>%
# identify relevant variables
select(
# block 1 happy pose emotion reports
hap1_bl1_hap : hap1_bl1_enj,
# block 1 neutral pose emotion reports
neu1_bl1_hap : neu1_bl1_enj,
# block 2 happy pose emotion reports
hap2_bl2_hap : hap2_bl2_enj,
# block 2 neutral pose emotion reports
neu2_bl2_hap : neu2_bl2_enj,
# motivation, prediction, belief, and opportunity scores
mot : opp, mot_gen,
# manipulation check items (awareness and attention checks)
hap1_bl1_att, hap2_bl2_att, neu1_bl1_att, neu2_bl2_att,
awr,
# condition and individual difference items
demand,
indiv_gend_var, indiv_agee_var, ethnicity,
# relevant vignette data
`46_awr` : `46_opp`,
`47_awr` : `47_opp`) %>%
# rename vignette variables
rename(pos_awr = `46_awr`,
pos_mot = `46_mot`,
pos_pre = `46_pre`,
pos_bel = `46_bel`,
pos_opp = `46_opp`,
nil_awr = `47_awr`,
nil_mot = `47_mot`,
nil_pre = `47_pre`,
nil_bel = `47_bel`,
nil_opp = `47_opp`) %>%
# add subid variable
mutate(sub = factor(1 : nrow(.))) %>%
# identify whether attention checks were all passed
mutate(att.chk =
if_else(condition =
hap1_bl1_att == "5" &
neu1_bl1_att == "5" &
hap2_bl2_att == "5" &
neu2_bl2_att == "5",
true = 1,
false = 0)
) %>%
# identify whether participants correctly identified the hypothesis
mutate(manip.chk =
if_else(condition =
demand == "pos" & awr == 1,
true = 1,
false =
if_else(condition =
demand == "nil" & awr == 2,
true = 1,
false = 0))) %>%
# create separate rows for each trial
# 1. Gather emotion reports into a single column
gather(key = "dv",
value = "value",
hap1_bl1_hap : neu2_bl2_enj) %>%
# 2. Create separate variables that identify the trial and outcome using "_..._ naming convention separator
separate(col = "dv",
into = c("trial", "outcome"),
sep = "_..._") %>%
# 3. Spread outcomes into individual rows
pivot_wider(names_from = "outcome",
values_from = "value") %>%
# fix variable types
mutate_at(.vars = c("mot", "pre", "bel", "opp",
"mot_gen", "indiv_agee_var",
"hap", "sat", "enj",
"pos_awr", "pos_mot",
"pos_pre", "pos_bel",
"pos_opp",
"nil_awr", "nil_mot",
"nil_pre", "nil_bel",
"nil_opp"),
.funs = as.numeric) %>%
mutate_at(.vars = c("demand", "indiv_gend_var",
"ethnicity", "sub"),
.funs = as.factor) %>%
# Calculate self-reported happiness scores
rowwise() %>%
mutate(happy = mean(c(hap, sat, enj))) %>%
ungroup() %>%
# identify block number
mutate(block.num = if_else(condition = trial == "hap1" |
trial == "neu1",
true = 1,
false = 2),
block.num = factor(block.num)) %>%
# create new trial variable that remove redundant information about block
mutate(trial = substr(x = trial,
start = 1,
stop = 3),
trial = factor(trial)) %>%
# organize dataframe
arrange(sub, block.num, trial) %>%
select(sub, demand, trial, block.num, happy,
att.chk, manip.chk,
mot : mot_gen,
indiv_gend_var : ethnicity) %>%
# recode (flip) motivation for the nil hypothesis condition
rowwise() %>%
mutate(mot = if_else(demand == "nil",
mot * (-1),
mot)) %>%
ungroup()
# center motivation, opportunity, and belief scores
DF.surv2$mot.c = scale(DF.surv2$mot,
scale = F) %>% as.numeric()
DF.surv2$opp.c = scale(DF.surv2$opp,
scale = F) %>% as.numeric()
DF.surv2$bel.c = scale(DF.surv2$bel,
scale = F) %>% as.numeric()
# Chunk 1: setup and load packages
# load libraries
library("tidyverse")
library("readxl")
library("performance")
library("lme4")
d <- read.csv("data/metaware_replication_clean.csv")
View(d)
d %>% names
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
View(d)
d$trial %>% unique
d %>%
filter(tiral == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy),
sd.happy = sd(happy))
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy),
sd.happy = sd(happy))
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
?pivot_wider
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy)
View(d)
d$1
d$`1`
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy) %>%
pivot_wider(names_from = trial,
values_from = c(`1`, `2`))
)
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy
)
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy) %>%
pivot_wider(names_from = trial,
values_from = c(`1`, `2`))
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy)
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
pivot_wider(names_from = block.num,
values_from = happy) %>%
pivot_wider(names_from = trial,
values_from = c(`1`, `2`))
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
# restructure data
pivot_wider(names_from = block.num,
values_from = happy) %>%
pivot_wider(names_from = trial,
values_from = c(`1`, `2`)) %>%
# average across blocks
rowwise() %>%
mutate(hap = mean(c(`1_hap`, `2_hap`)),
neu = mean(c(`1_neu`, `2_neu`))
)
View(d)
d <- read.csv("data/metaware_replication_clean.csv") %>%
select(sub : happy)
# examine difference score
d %>%
filter(trial == 'hap') %>%
group_by(demand) %>%
summarise(m.happy = mean(happy,
na.rm = T),
sd.happy = sd(happy,
na.rm = T))
# examine difference in difference
d <- d %>%
# restructure data
pivot_wider(names_from = block.num,
values_from = happy) %>%
pivot_wider(names_from = trial,
values_from = c(`1`, `2`)) %>%
# average across blocks
rowwise() %>%
mutate(hap = mean(c(`1_hap`, `2_hap`)),
neu = mean(c(`1_neu`, `2_neu`))
) %>%
# calculate difference score
mutate(dif = hap - neu) %>%
ungroup()
View(d)
d %>% names
d %>%
group_by(demand) %>%
summarise(m.dif = mean(dif, na.rm = T),
sd.dif = sd(dif, na.rm = T))
