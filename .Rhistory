# identify block number
mutate(block.num = if_else(condition = trial == "hap1" |
trial == "neu1",
true = 1,
false = 2),
block.num = factor(block.num)) %>%
# create new trial variable that remove redundant information about block
mutate(trial = substr(x = trial,
start = 1,
stop = 3),
trial = factor(trial)) %>%
# organize dataframe
arrange(sub, block.num, trial) %>%
select(sub, demand, trial, block.num, happy,
att.chk, manip.chk,
mot : mot_gen,
indiv_gend_var : ethnicity) %>%
# recode (flip) motivation for the nil hypothesis condition
rowwise() %>%
mutate(mot = if_else(demand == "nil",
mot * (-1),
mot)) %>%
ungroup()
# center motivation, opportunity, and belief scores
DF.surv2$mot.c = scale(DF.surv2$mot,
scale = F) %>% as.numeric()
DF.surv2$opp.c = scale(DF.surv2$opp,
scale = F) %>% as.numeric()
DF.surv2$bel.c = scale(DF.surv2$bel,
scale = F) %>% as.numeric()
# Chunk 26
if(!exists("sens")){
write.csv(DF,
"data/metaware_data_clean.csv",
row.names = F)
}
# Chunk 27
write.csv(surv.sum,
"data/metaware_vignette_clean.csv",
row.names = F)
# Chunk 28
write.csv(DF.surv2,
"data/metaware_replication_clean.csv",
row.names = F)
# Chunk 1
title             : "A quantitative review of demand characteristics and their underlying mechanisms"
shorttitle        : "Demand characteristics quantitative review"
author:
- name          : "Nicholas A. Coles"
affiliation   : "1"
corresponding : yes
address       : "Cordura Hall, 210 Panama St, Stanford, CA 94305"
email         : "ncoles@stanford.edu"
- name          : "Michael C. Frank"
affiliation   : "2"
affiliation:
- id            : "1"
institution   : "Center for the Study of Language and Information, Stanford University"
- id            : "2"
institution   : "Department of Psychology, Stanford University"
authornote: |
This work was supported by the John Templeton Foundation (grant # 62295). The funder had no role in the preparation of the manuscript or decision to publish. We thank Morgan H. Wyatt for his assistance on the meta-analysis and Anjie Cao for reviewing project code.
abstract: |
Demand characteristics are a fundamental methodological concern in experimental psychology. Yet, little is known about the direction, magnitude, consistency, and mechanisms underlying their effects. We conducted a meta-analysis of 195 effect sizes from 40 studies that provided strict experimental tests of demand effects by manipulating the hypothesis communicated to participants. Demand characteristics tended to produce small increases in hypothesis-consistent responding (*d* = 0.22, 95% CI [0.11, 0.33]). However, these effects were extremely heterogeneous (between-study $\tau$ = 0.30; within-study $\sigma$ = 0.20), with the estimated distribution of true effects ranging from *d* = 1.90 (a large increase in hypothesis-consistent responding) to *d* = -1.46 (a large increase in hypothesis-*in*consistent responding). Contra prior frameworks, we did not find evidence that demand effects were driven participants’ motivation or opportunity to adjust their responses. We did, however, find robust evidence that such effects are driven by participants’ beliefs, as in placebo effects. Similar findings emerged in a direct replication of a study included in the meta-analysis. Taken together, results challenge conventional distinctions between demand characteristics and placebo effects. Furthermore, they underscore the importance of controlling for both response bias and placebo effects when estimating causal relationships.
keywords          : "demand characteristics, placebo, mindsets, research methods, meta-analysis"
bibliography      : "r-references.bib"
floatsintext      : yes
linenumbers       : no
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
classoption       : "man"
output            : papaja::apa6_docx
editor_options:
chunk_output_type: console
# Chunk 2: setup
# load writing and data processing packages
library("papaja")
library("tidyverse")
library("readxl")
library("cowplot")
# load meta-analyses packages
library("metafor")
library("weightr")
library("PublicationBias")
# load mixed-effect regression packages
library("lme4")
library("lmerTest")
library("emmeans")
# identify paper references
r_refs("r-references.bib")
# turn scientific notation off
options(scipen = 999)
# set theme
theme_set(theme_classic())
# Chunk 3: framework
knitr::include_graphics("images/metaware_framework.png")
# Chunk 4: literature search
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_EsData_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation =
if_else(condition = grepl("dissertation", link),
true = 1,
false = 0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# Chunk 5: final.df
# open clean effect size data
DF.es <-
read_csv(file = "data/metaware_data_clean.csv")
# identify total number of studies (denoted by id.study column)
num.s <- DF.es$id.study %>%
unique() %>%
length()
# identify total number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
# for the known outlier (id = 18), give an example of the largest effect size
outlier.es <- DF.es %>%
filter(id.study == 18) %>%
summarise(max.es = min(es)) %>% #  using min because largest value is neg
round(2)
# Chunk 6: clean.env.1
# remove outlier and re-initialize id factors
DF.es <- DF.es %>%
filter(id.study != 18) %>%
mutate(id.study = factor(id.study),
id.es = factor(id.es))
# clean environment
rm(DF.s, r.pi, r.unp, num.s, num.p, outlier.es)
# Chunk 7: corr.sens
# examine how assumed repeated measures correlation impacts general pattern of results
# get list of sensitivity dataframes
sens.df.list <- list.files(path = "./data/r_sensitivity")
# (1) open dataframe, (2) compute intercept-only model, (3) extract overall es
sens.res <-
sapply(X = sens.df.list,
FUN = function(i){
# open data
df <- read.csv(paste0("data/r_sensitivity/",
i)
)
# fit model
m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# return overall es as a number
m$b %>%
as.numeric() %>%
return()
}
)
# compute range of es values
sens.range <- max(sens.res) - min(sens.res)
# delete vestigial
rm(sens.df.list, sens.res)
# Chunk 8: mult.eff
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id.study) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(condition = n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as percentage
as.numeric() %>%
round(digits = 2) * 100
# Chunk 9: clean.env.2
# delete vestigial
rm(mult.eff.per, vig.n, survey.n, sens.range)
# Chunk 10: overall
# estimate overall effect size
overall <-
rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# estimate standard deviation of effect size distribution (i.e., Tau)
# to do so, combine both sources of estimated variability in the model
tau <- sqrt(overall$sigma2[1] + overall$sigma2[2])
# estimate proportion of hypothesis-consistent and inconsistent responding
# -0.10 < d > 0.10 is the arbitrary threshold for saying it's neither consistent or inconsistent
h.c <- pnorm(q = .10,
mean = overall$b,
sd = tau,
lower.tail = F) %>%
round(digits = 2) * 100
h.i <- pnorm(q = (-.10),
mean = overall$b,
sd = tau,
lower.tail = T) %>%
round(digits = 2) * 100
# estimate lower and upper bound of effect size distribution
dist.min <- rnorm(n = 1000000,
mean = overall$b,
sd = tau) %>%
min() %>%
round(digits = 2)
dist.max <- rnorm(n = 1000000,
mean = overall$b,
sd = tau) %>%
max() %>%
round(digits = 2)
# Chunk 11: forest
# create a temporary dataset containing effect sizes and 95% CI's
tmp <- DF.es %>%
rowwise() %>%
mutate(se = sqrt(es.var),
ub = es + (se * 1.96),
ub = round(ub, 2),
lb = es - (se * 1.96),
lb = round(lb, 2),
es = round(es, 2)) %>%
ungroup() %>%
arrange(es, id.study)
# create a forest plot w/ distribution overlay
ggplot(data= tmp,
aes(y = rev(1: nrow(tmp)) * 0.007692308,
x = es,
xmin = lb,
xmax = ub)) +
#hypothesis inconsistent effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "#F8766D",
alpha = .25,
xlim = c(-2, -.10)) +
# negligible effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "grey80",
alpha = .25,
xlim = c(-.10, .10)) +
# hypothesis consistent effects
## area
geom_area(stat = "function",
fun = dnorm,
args = list(mean = overall$b,
sd = tau),
fill = "#00998a",
alpha = .25,
xlim = c(.10, 2)) +
# create dotted line at d = 0
geom_vline(xintercept = 0,
color = "black",
linetype = "dotted",
alpha = .5,
size =.5)  +
# add points and error bars
geom_point(shape = "diamond",
size = 1,
alpha = .8,
color = "dark grey") +
geom_errorbarh(height = .005,
size = .1,
alpha = .8,
color = "dark grey") +
# add citation label
geom_text(aes(label = citation),
x = -2.7,
hjust = 0,
size = 1) +
# add CI label
geom_text(aes(label = paste0(es,
" [", lb, ", ", ub, "]")),
x = 3.9,
size = 1,
hjust = 1) +
labs(x = "Cohen's d",
y = "density") +
# increase plotting area
scale_x_continuous(limits = c(-2.7, 4),
breaks = seq(from = -2, to = 3, by = 1),
expand = c(.01, .01)) +
scale_y_continuous(expand = c(.005, 0))
# Chunk 12: mod
# create moderator analysis function
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t")
sub.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year")
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
# test ref.type moderator in scenarios where there is a control comparison (i.e., ref.r == single)
mod.r[["ref.type"]] <-
ModAnalysis(m = "ref.type",
df = DF.es[DF.es$ref.r == "single", ])
# add motivation, opportunity, belief, and prediction moderators
## Note: comparisons with nil-demand conditions are excluded
mod.r.2 <-
sapply(X = c("mot", "opp", "bel", "pre"),
simplify = F,
FUN = ModAnalysis,
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz"))
## combine results
mod.r = c(mod.r, mod.r.2)
# delete vestigial
rm(mod.r.2)
# Chunk 13: modforest
## list of moderators
mod.list <- c("student", "paid", "online", "ref.type", "design")
## function for extraction
mod.df <- map_df(mod.list, function(x) {
tibble(mod = x,
level = str_replace(rownames(mod.r[[x]]$sub$beta), mod, ""),
beta = mod.r[[x]]$sub$beta %>%
as.numeric() %>%
round(2),
lb = mod.r[[x]]$sub$ci.lb %>%
round(2),
ub = mod.r[[x]]$sub$ci.ub %>%
round(2))
})
## manually update some labels
mod.df <- mod.df %>%
mutate(level = recode_factor(.x = level,
nvc = "negative",
cvp = "positive",
cvz = "nil"),
mod = recode_factor(.x = mod,
ref.type = "type of demand"))
## reorder factors
mod.df$level <- fct_reorder(mod.df$level,
mod.df$beta,
.desc = TRUE)
## Create forest plot with effect size distribution superimposed
ggplot(mod.df,
aes(x = level,
y = beta)) +
# dotted line at d = 0
geom_hline(yintercept = 0,
linetype = "dotted",
alpha = .5,
size =.5) +
# estimates and CI
geom_pointrange(aes(ymin = lb,
ymax = ub),
alpha = .8,
color = "dark grey") +
# update labels
xlab("") +
ylab("Estimated subgroup mean (Cohen's standardized d)") +
# clean up aesthetics
coord_flip() +
facet_grid(mod ~ . , scales = "free_y") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = .5,  hjust=1))
# delete vestigial
rm(mod.df)
# Chunk 14: robust.chk
# calculate percentage of online effect sizes that had students vs. non-students
in.s <- DF.es[DF.es$online == "no", ]$student %>%
table() %>%
prop.table() %>%
as.data.frame() %>%
.[3, 2] %>%
round(2) * 100
on.s <- DF.es[DF.es$online == "yes", ]$student %>%
table() %>%
prop.table() %>%
as.data.frame() %>%
.[2, 2] %>%
round(2) * 100
# calculate percentage of paid effect sizes with students vs. non-students
v.s <- DF.es[DF.es$paid == "no", ]$student %>%
table() %>%
prop.table() %>%
as.data.frame() %>%
.[3, 2] %>%
round(2) * 100
p.s <- DF.es[DF.es$paid == "yes", ]$student %>%
table() %>%
prop.table() %>%
as.data.frame() %>%
.[2, 2] %>%
round(2) * 100
# fit more complex model
## set Type 3 SS
options(contrasts = c('contr.sum',
'contr.poly'))
m.sens <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online,
test= "t")
m.sens.student <- anova(m.sens, btt = c(2, 3))
m.sens.online <- anova(m.sens, btt = c(5))
m.sens.pay <- anova(m.sens, btt = c(4))
# Chunk 15: predplot
# set R back to default contrasts
options(contrasts = c("contr.treatment", "contr.poly"))
# change reference levels for:
## In-person study, no payment, students, positive demand
DF.es$student <- factor(DF.es$student,
levels = c("yes", "mix", "no"))
## fit model
m.s1 <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online + ref.type,
test = "t")
# change reference levels for:
## Online study, payment, non-students, positive demand
DF.es$online <- factor(DF.es$online,
levels = c("yes", "no"))
DF.es$paid <- factor(DF.es$paid,
levels = c("yes", "no"))
DF.es$student <- factor(DF.es$student,
levels = c("no", "mix", "yes"))
## fit model
m.s2 <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online + ref.type,
test = "t")
# manually add output from the models that estimated effects in two common research scenarios
pred_df <-
bind_rows(tibble(level = "in-person\nstudents\nno payment",
mod = "custom",
beta = m.s1$beta[1] %>%
as.numeric %>%
round(2),
lb = m.s1$ci.lb[1] %>%
as.numeric %>%
round(2),
ub = m.s1$ci.ub[1] %>%
as.numeric %>%
round(2)),
tibble(level = "online\nnon-students\npayment",
mod = "custom",
beta = m.s2$beta[1] %>%
as.numeric %>%
round(2),
lb = m.s2$ci.lb[1] %>%
as.numeric %>%
round(2),
ub = m.s2$ci.ub[1] %>%
as.numeric %>%
round(2)
))
# plot
ggplot(pred_df, aes(x = level, y = beta)) +
# line at d = 0
geom_hline(yintercept = 0,
lty = 2,
alpha = .5,
size =.5) +
# point estimate and 95% CI
geom_pointrange(aes(ymin = lb, ymax = ub),
alpha = .8,
color = "dark grey") +
# aes
xlab("") +
coord_flip() +
ylab("Estimated overall effect (Cohen's standardized d)") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = .5,  hjust=1))
