ub = m.s1$ci.ub[1] %>%
as.numeric %>%
round(2)),
tibble(level = "online\nnon-students\npayment",
mod = "custom",
beta = m.s2$beta[1] %>%
as.numeric %>%
round(2),
lb = m.s2$ci.lb[1] %>%
as.numeric %>%
round(2),
ub = m.s2$ci.ub[1] %>%
as.numeric %>%
round(2)
))
# plot
ggplot(pred_df, aes(x = level, y = beta)) +
# line at d = 0
geom_hline(yintercept = 0,
lty = 2,
alpha = .5,
size =.5) +
# point estimate and 95% CI
geom_pointrange(aes(ymin = lb, ymax = ub),
alpha = .8,
color = "dark grey") +
# aes
xlab("") +
coord_flip() +
ylab(expression(paste("Estimated overall effect (Cohen's ", italic("d"), ")"))) +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = .5,  hjust=1))
# Chunk 16: pub.bias
# delete vestigial
rm(in.s, on.s, v.s, p.s,
m.s1, m.s2,
m.sens, m.sens.student, m.sens.online, m.sens.pay)
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- corrected_meta(yi = DF.es$es,
vi = DF.es$es.var,
eta = 49,
clustervar = DF.es$id.study,
model = "robust",
favor.positive = T)
# 2. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
# Chunk 17: funnel
##########
# Funnel plot with non-aggregated dependencies
##########
# create a temporary dataset with standard error (se) values
tmp <- DF.es %>%
rowwise() %>%
mutate(se = sqrt(es.var)) %>%
ungroup()
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(DF.es))
ll95 = overall$b[1] - (1.96 * se.seq)
ul95 = overall$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = overall$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
# plot
a <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
scale_y_reverse(expand = c(.01, 0)) +
scale_x_continuous(limits = c(-1.5, 2.1),
expand = c(.01, .01)) +
geom_vline(xintercept = overall$b[1],
linetype = "dotted") +
labs(x = expression(paste("Cohen's ", italic("d"))),
y = "Standard error")
# delete vestigial
rm(tmp, ll95, ul95, se.seq, t.coord)
##########
# Funnel plot with aggregated dependencies
##########
# create a temporary dataset with standard error (se) values
tmp <- pub.r$rho_0.5$DF.agg %>%
rowwise() %>%
mutate(es = yi,
se = sqrt(vi)) %>%
ungroup()
# calculate overall effect size
tmp.meta <- rma.uni(yi = yi,
vi = vi,
data = tmp,
method = "REML")
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(tmp))
ll95 = tmp.meta$b[1] - (1.96 * se.seq)
ul95 = tmp.meta$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = tmp.meta$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
b <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
scale_y_reverse(expand = c(.01, 0)) +
scale_x_continuous(limits = c(-1.5, 2.1),
expand = c(.01, .01)) +
geom_vline(xintercept = tmp.meta$b[1],
linetype = "dotted") +
labs(x = expression(paste("Cohen's ", italic("d"))),
y = "")
# delete vestigial
rm(tmp, ll95, ul95, se.seq, t.coord, tmp.meta)
##########
# Plot funnels next to each other plot with aggregated dependencies
##########
plot_grid(a, b,
labels = c("A", "B"))
rm(a, b)
# Chunk 18: vig.desc
# identify total number of vignettes
vig.n <- read.csv(file = "admin/vig/metaware_VigCombined.csv") %>%
nrow()
# Chunk 19: vig
knitr::include_graphics("images/metaware_vigs.png")
# Chunk 20: survey.dem
# describe participant demographics
survey.DF <-
# open survey
read.csv("data/metaware_replication_clean.csv") %>%
# get one observation per participant
distinct(sub,
.keep_all = T)
# get participant demographics
survey.n <- nrow(survey.DF)
survey.gend <-
survey.DF$indiv_gend_var %>%
table() %>%
prop.table() %>%
round(2) * 100
survey.eth <-
survey.DF$ethnicity %>%
table() %>%
prop.table() %>%
round(2) * 100
survey.age.m <- mean(survey.DF$indiv_agee_var,
na.rm = T) %>%
round(2)
survey.age.sd <- sd(survey.DF$indiv_agee_var,
na.rm = T) %>%
round(2)
# put demographics into table
survey.dem = list(n = survey.n,
gend = survey.gend,
ethnicity = survey.eth,
age.m = survey.age.m,
age.sd = survey.age.sd)
# remove vestigial
rm(survey.DF, survey.n, survey.gend,
survey.eth, survey.age.m, survey.age.sd)
# Chunk 21: mods
knitr::include_graphics("images/metaware_mods.png")
# Chunk 22: modfig
#################
# motivation plot
#################
# get predicted (for the regression line) and actual values into a single dataset
mot.df <- predict(mod.r$mot$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$mot$mod$yi)
# plot
m <- ggplot(data = mot.df,
aes(x = X.mot,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = expression(paste("Cohen's ", italic("d"))),
x = "motivation ratings")
rm(mot.df)
#################
# opportunity plot
#################
# get predicted and actual values into a single dataset
opp.df <- predict(mod.r$opp$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$opp$mod$yi)
# plot
o <- ggplot(data = opp.df,
aes(x = X.opp,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "",
x = "opportunity ratings")
rm(opp.df)
#################
# belief  plot
#################
# get predicted and actual values into a single dataset
bel.df <- predict(mod.r$bel$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$bel$mod$yi)
# plot
b <- ggplot(data = bel.df,
aes(x = X.bel,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = expression(paste("Cohen's ", italic("d"))),
x = "expectancy ratings")
rm(bel.df)
#################
# prediction plot
#################
# get predicted and actual values into a single dataset
pre.df <- predict(mod.r$pre$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$pre$mod$yi)
# plot
p <- ggplot(data = pre.df,
aes(x = X.pre,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "",
x = "prediction ratings")
rm(pre.df)
#################
# merge plots
#################
plot_grid(m, o, b, p,
labels = c("A", "B", "C", "D"))
rm(m, o, b, p, survey.dem)
# Chunk 23
# evaluate whether the difference in significance is significant
# prep data
dif.in.sig.df <- DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz") %>%
pivot_longer(cols = c('mot', 'bel'),
names_to = "mech",
values_to = "mech.value") %>%
mutate(mech = factor(mech))
# fit model
dif.in.sig.df.m <- rma.mv(yi = es,
V = es.var,
data = dif.in.sig.df,
random = ~ 1 | id.study / id.es,
mods = ~ mech.value * mech,
test= "t")
dif.in.sig.df.m
dif.in.sig.df.m$zval
# calculate a pseudo-R2
## see this page for a discussion of the method:
## https://stackoverflow.com/questions/22356450/getting-r-squared-from-a-mixed-effects-multilevel-model-in-metafor
## pairwise delete observations where we don't have information for moderator analyses
## this is to ensure that the two models we are comparing have the same observations
DF.cmplt <- DF.es %>%
filter(!is.na(student),
!is.na(paid),
!is.na(online),
!is.na(ref.type),
!is.na(bel),
!is.na(mot),
!is.na(opp))
## fit intercept-only model
m.int <- rma.mv(yi = es,
V = es.var,
data = DF.cmplt,
random = ~ 1 | id.study / id.es,
test = "t")
# fit study 1 moderator model and calculate r2
m.s1 <- rma.mv(yi = es,
V = es.var,
data = DF.cmplt,
random = ~ 1 | id.study / id.es,
mods = ~ student + online + ref.type + design + paid,
test = "t")
s1.r2 <- (sum(m.int$sigma2) - sum(m.s1$sigma2)) / sum(m.int$sigma2)
# fit study 2 moderator model and calculate r2
m.s2 <- rma.mv(yi = es,
V = es.var,
data = DF.cmplt,
random = ~ 1 | id.study / id.es,
mods = ~ bel + mot + opp,
test = "t")
s2.r2 <- (sum(m.int$sigma2) - sum(m.s2$sigma2)) / sum(m.int$sigma2)
# fit full moderator model and calculate r2
m.full <- rma.mv(yi = es,
V = es.var,
data = DF.cmplt,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online + ref.type +
bel + mot + opp,
test = "t")
full.r2 <- (sum(m.int$sigma2) - sum(m.full$sigma2)) / sum(m.int$sigma2)
# compile into list
r2 <- list(s1.r2 = s1.r2,
s2.r2 = s2.r2,
full.r2 = full.r2)
rm(s1.r2, s2.r2, full.r2)
rm(DF.cmplt, m.int, m.s1, m.s2, m.full)
r2$full.r2
# note: this code is set to not evaluate.
# for computational reproducibility purposes, the code exports package version info to a text file
# this will help others see which package versions were used when the code was written
writeLines(text = sessionInfo() %>%
capture.output(),
con = "sessionInfo.txt")
# Chunk 1: setup
# load writing and data processing packages
library("papaja")
library("tidyverse")
library("readxl")
library("cowplot")
# load meta-analyses packages
library("metafor")
library("weightr")
library("PublicationBias")
# load mixed-effect regression packages
library("lme4")
library("lmerTest")
library("emmeans")
# identify paper references
r_refs("r-references.bib")
# turn scientific notation off
options(scipen = 999)
# set seed to year of Nicholas' favorite [unfinished] album, SMiLE
set.seed(1967)
# set theme
theme_set(theme_classic())
# note: this code is set to not evaluate.
# for computational reproducibility purposes, the code exports package version info to a text file
# this will help others see which package versions were used when the code was written
writeLines(text = sessionInfo() %>%
capture.output(),
con = "sessionInfo.txt")
