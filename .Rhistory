p = mod.r$paid$sub$pval[[1]] %>% as.numeric %>% apa_p()
),
################
# Publication status
################
cbind(
`Moderator (bolded) and level` = "Publication status",
s = mod.r$published$mod$n,
k = mod.r$published$mod$k,
g =  "--",
`95% CI` = "--",
`F` = mod.r$published$mod$QM %>% round(2),
p = mod.r$published$mod$QMp %>% as.numeric %>% apa_p()
),
## published
cbind(
`Moderator (bolded) and level` = "     published",
s = DF.es %>%
filter(published == 'yes') %>%
reframe(n.study = unique(id.study)) %>%
nrow(),
k = DF.es %>%
filter(published == 'yes') %>%
nrow(),
g =  mod.r$published$sub$b[[2]] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$published$sub$ci.lb[[2]] %>% round(2),
", ",
mod.r$published$sub$ci.ub[[2]] %>% round(2),
"]"
),
`F` = mod.r$published$sub$zval[[2]] ^ 2 %>%
round(2),
p = mod.r$published$sub$pval[[2]] %>% as.numeric %>% apa_p()
),
## unpublished
cbind(
`Moderator (bolded) and level` = "     unpublished",
s = DF.es %>%
filter(published == 'no') %>%
reframe(n.study = unique(id.study)) %>%
nrow(),
k = DF.es %>%
filter(published == 'no') %>%
nrow(),
g =  mod.r$published$sub$b[[1]] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$published$sub$ci.lb[[1]] %>% round(2),
", ",
mod.r$published$sub$ci.ub[[1]] %>% round(2),
"]"
),
`F` = mod.r$published$sub$zval[[1]] ^ 2 %>%
round(2),
p = mod.r$published$sub$pval[[1]] %>% as.numeric %>% apa_p()
)
)
apa_table(
feature.mod.table,
caption = "Study feature moderator and subgroup analyses",
note = "s = number of studies; k = number of effect size estimates; g = Hedge's g; 95% CI corresponds to the estimated value of Hedge's g; F-values represent the test of moderation in bolded rows -- and tests of the model-dervied overall effect size in non-bolded rows; The number of studies listed for a moderator analysis is not necessarily the sum of the number of studies listed for the individual levels of the moderators because many studies yielded effect sizes for multiple levels.")
# Chunk 18: vig.rel.full
vig.rel <- readRDS("output/vig.survfull.rel.rds")
vig.desc <- read.csv("output/surv.sum.csv")
vig.rel <- readRDS("output/vig.survfull.rel.rds")
# Chunk 19
rbind(
# predicted demand effects
cbind(
`Moderator (bolded) and level` = "predicted demand effects",
s = mod.r$pre$mod$n,
k = mod.r$pre$mod$k,
B1 = mod.r$pre$mod$b[2] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$pre$mod$ci.lb[[2]] %>% round(2),
", ",
mod.r$pre$mod$ci.ub[[2]] %>% round(2),
"]"
),
`F` = mod.r$pre$mod$QM %>% round(2),
p = mod.r$pre$mod$QMp %>% apa_p()
),
# motivation to adjust responses
cbind(
`Moderator (bolded) and level` = "motivation to adjust responses",
s = mod.r$mot$mod$n,
k = mod.r$mot$mod$k,
B1 = mod.r$mot$mod$b[2] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$mot$mod$ci.lb[[2]] %>% round(2),
", ",
mod.r$mot$mod$ci.ub[[2]] %>% round(2),
"]"
),
`F` = mod.r$mot$mod$QM %>% round(2),
p = mod.r$mot$mod$QMp %>% apa_p()
),
# opportunity to adjust responses
cbind(
`Moderator (bolded) and level` = "opportunity to adjust responses",
s = mod.r$opp$mod$n,
k = mod.r$opp$mod$k,
B1 = mod.r$opp$mod$b[2] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$opp$mod$ci.lb[[2]] %>% round(2),
", ",
mod.r$opp$mod$ci.ub[[2]] %>% round(2),
"]"
),
`F` = mod.r$opp$mod$QM%>% round(2),
p = mod.r$opp$mod$QMp %>% apa_p()
),
# belief in communicated hypothesis
cbind(
`Moderator (bolded) and level` = "belief in communicated hypothesis",
s = mod.r$bel$mod$n,
k = mod.r$bel$mod$k,
B1 = mod.r$bel$mod$b[2] %>% round(2),
`95% CI` =
paste0(
"[",
mod.r$bel$mod$ci.lb[[2]] %>% round(2),
", ",
mod.r$bel$mod$ci.ub[[2]] %>% round(2),
"]"
),
`F` = mod.r$bel$mod$QM %>% round(2),
p = mod.r$bel$mod$QMp %>% apa_p()
)
) %>%
apa_table(caption = "Participant rating moderator analyses",
note = "s = number of studies; k = number of effect size estimates; B1 = estimated linear relationship between participant ratings and observed Hedge's g scores; 95% CI corresponds to the estimated value of B1.")
# Chunk 20: pub.bias
# delete vestigial
rm(in.s, on.s, v.s, p.s,
m.s1, m.s2,
m.sens, m.sens.student, m.sens.online, m.sens.pay)
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- pubbias_meta(yi = DF.es$es,
vi = DF.es$es.var,
cluster = DF.es$id.study,
selection_ratio = 10000000,
model_type = "robust",
favor_positive = T)
# you can run the code below to see how nonsensicle it is to look at disfavor bias
# pubbias_meta(yi = DF.es$es,
#              vi = DF.es$es.var,
#              cluster = DF.es$id.study,
#              selection_ratio = 10000000,
#              model_type = "robust",
#              favor_positive = F)
# 2a. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 2b. cluster robust three-level precision-effect test
########################
pe.3l.r <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es) %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# temp code: aggregated precision-effect test
########################
rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg %>% filter(id.study != 30,
id.study != 55),
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
pe.3l.r = pe.3l.r,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
# Chunk 21: funnel
##########
# Funnel plot with non-aggregated dependencies
##########
# create a temporary dataset with standard error (se) values
tmp <- DF.es %>%
rowwise() %>%
mutate(se = sqrt(es.var)) %>%
ungroup()
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(DF.es))
ll95 = overall$b[1] - (1.96 * se.seq)
ul95 = overall$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = overall$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
# plot
a <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# scale_y_reverse(expand = c(.01, 0)) +
scale_y_continuous(expand = c(.01, 0)) +
scale_x_continuous(limits = c(-1.5, 2.1),
expand = c(.01, .01)) +
geom_vline(xintercept = overall$b[1],
linetype = "dotted") +
labs(x = expression(paste("Hedge's ", italic("g"))),
y = "Standard error")
# delete vestigial
rm(tmp, ll95, ul95, se.seq, t.coord)
##########
# Funnel plot with aggregated dependencies
##########
# create a temporary dataset with standard error (se) values
tmp <- pub.r$rho_0.5$DF.agg %>%
rowwise() %>%
mutate(es = yi,
se = sqrt(vi)) %>%
ungroup()
# calculate overall effect size
tmp.meta <- rma.uni(yi = yi,
vi = vi,
data = tmp,
method = "REML")
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(tmp))
ll95 = tmp.meta$b[1] - (1.96 * se.seq)
ul95 = tmp.meta$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = tmp.meta$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
b <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
#scale_y_reverse(expand = c(.01, 0)) +
scale_y_continuous(expand = c(.01, 0)) +
scale_x_continuous(limits = c(-1.5, 2.1),
expand = c(.01, .01)) +
geom_vline(xintercept = tmp.meta$b[1],
linetype = "dotted") +
labs(x = expression(paste("Hedge's ", italic("g"))),
y = "")
# delete vestigial
rm(tmp, ll95, ul95, se.seq, t.coord, tmp.meta)
##########
# Plot funnels next to each other plot with aggregated dependencies
##########
plot_grid(a, b,
labels = c("A", "B"))
rm(a, b)
DF.es %>% names
lmer(att ~ student + paid + online + (1 |id.study / id.es),
data = DF.es)
lmer(att ~ student + paid + online + (1 | id.study) + (1 | id.es),
data = DF.es)
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es)
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es)
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
summary()
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
att
mot <-
lmer(mot ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
mot
opp <-
lmer(opp ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
opp
bel <-
lmer(bel ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
bel
yi = es,
rm(att, mot, opp, bel)
lmer(bel ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
lmer(opp ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
options(contrasts = c('contr.sum', 'contr.poly'))
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
att
mot <-
lmer(mot ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
mot
opp <-
lmer(opp ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
opp
bel <-
lmer(bel ~ student + paid + online + (1 | id.study),
data = DF.es) %>%
anova()
bel
att
mot
mot
opp
bel
att %>% anova()
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es)
att %>% anova()
att %>% BIC
att <-
lmer(att ~ student + paid + online + (1 | id.study),
data = DF.es)
att
DF.es %>% names
# create moderator analysis function
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t") %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
sub.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t") %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year", "att",
# exploratory quality control measures
'report', 'external', 'internal')
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year", "att",
# exploratory quality control measures
'report', 'internal')
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
mod.r$report$mod
mod.r$internal$mod
