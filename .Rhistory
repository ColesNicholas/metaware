rm(list = ls())
# load packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# call package function
packages <- c('metafor', 'tidyverse',
'readxl', 'robumeta')
ipak(packages)
rm(packages, ipak)
# turn scientific notation off
options(scipen = 999)
# Chunk 2
# import data
DF.screen <-
read_xlsx(path = "metaware_data.xlsx",
sheet = "records.screening",
na = c("N/A")) %>%
select(year)
hist(DF.screen$year,
breaks = seq(from = 1960,
to = 2022,
by = 2))
rm(DF.screen)
DF <- read_xlsx(path = "metaware_data.xlsx",
sheet = "coding",
na = c("NA"))
DF %>% filter(es.calc == "p") %>% View()
DF$direction %>% unique()
DF$direction %>% table()
DF %>% filter(es.calc == "p") %>% View()
# Chunk 1: setup and load packages
# clean environment
rm(list = ls())
# load packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# call package function
packages <- c('metafor', 'tidyverse',
'readxl', 'robumeta')
ipak(packages)
rm(packages, ipak)
# turn scientific notation off
options(scipen = 999)
# Chunk 2
# import data
DF.screen <-
read_xlsx(path = "metaware_data.xlsx",
sheet = "records.screening",
na = c("N/A")) %>%
select(year)
hist(DF.screen$year,
breaks = seq(from = 1960,
to = 2022,
by = 2))
rm(DF.screen)
# Chunk 3: open/clean data
# import data
DF <- read_xlsx(path = "metaware_data.xlsx",
sheet = "coding",
na = c("NA"))
# delete unnecessary variables
DF <- DF %>%
# remove reference columns
select(-ends_with("ref")) %>%
# remove variables we won't include in any analyses
select(-c(prop.woman : online, note))
# temporarily delete p-value caess
# DF <- DF %>%
#   filter(es.calc != "pval")
# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
# effect size by year
DF$year %>% hist()
# record by year
tmp <- DF %>%
distinct(id,
.keep_all = T)
tmp$year %>%
hist(breaks = seq(from = 1960,
to = 2022,
by = 2))
# Chunk 4: define function EsBetwMean
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1,
n.2, m.2, sd.2){
sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
((n.2 - 1) * (sd.2^2))) /
(n.1 + n.2 - 2));
es <- (m.1 - m.2) / sd.within;
return(es)
}
# Chunk 5: define function EsBetwTval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
es <- tval * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 6: define function EsBetwFval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
es <- sqrt((fval * (n.1 + n.2)) /
(n.1 * n.2));
return(es)
}
# Chunk 7
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval, pval.df, direction){
# calculate the inverse of the cumulative distribution function of t
t.inv <- qt(p = (pval / 2),
df = (n.1 + n.2 - 2),
lower.tail = FALSE);
es <- t.inv * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 8: define function EsVarBetw
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){
es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
((es^2) / (2 * (n.1 + n.2)));
return(es.var)
}
# Chunk 1: setup and load packages
# clean environment
rm(list = ls())
# load packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# call package function
packages <- c('metafor', 'tidyverse',
'readxl', 'robumeta')
ipak(packages)
rm(packages, ipak)
# turn scientific notation off
options(scipen = 999)
# Chunk 2
# import data
DF.screen <-
read_xlsx(path = "metaware_data.xlsx",
sheet = "records.screening",
na = c("N/A")) %>%
select(year)
hist(DF.screen$year,
breaks = seq(from = 1960,
to = 2022,
by = 2))
rm(DF.screen)
# Chunk 3: open/clean data
# import data
DF <- read_xlsx(path = "metaware_data.xlsx",
sheet = "coding",
na = c("NA"))
# delete unnecessary variables
DF <- DF %>%
# remove reference columns
select(-ends_with("ref")) %>%
# remove variables we won't include in any analyses
select(-c(prop.woman : online, note))
# temporarily delete p-value caess
# DF <- DF %>%
#   filter(es.calc != "pval")
# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
# effect size by year
DF$year %>% hist()
# record by year
tmp <- DF %>%
distinct(id,
.keep_all = T)
tmp$year %>%
hist(breaks = seq(from = 1960,
to = 2022,
by = 2))
# Chunk 4: define function EsBetwMean
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1,
n.2, m.2, sd.2){
sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
((n.2 - 1) * (sd.2^2))) /
(n.1 + n.2 - 2));
es <- (m.1 - m.2) / sd.within;
return(es)
}
# Chunk 5: define function EsBetwTval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
es <- tval * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 6: define function EsBetwFval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
es <- sqrt((fval * (n.1 + n.2)) /
(n.1 * n.2));
return(es)
}
# Chunk 7
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval){
# calculate the inverse of the cumulative distribution function of t
t.inv <- qt(p = (pval / 2),
df = (n.1 + n.2 - 2),
lower.tail = FALSE);
es <- t.inv * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 8: define function EsVarBetw
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){
es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
((es^2) / (2 * (n.1 + n.2)));
return(es.var)
}
# Chunk 1: setup and load packages
# clean environment
rm(list = ls())
# load packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# call package function
packages <- c('metafor', 'tidyverse',
'readxl', 'robumeta')
ipak(packages)
rm(packages, ipak)
# turn scientific notation off
options(scipen = 999)
# Chunk 2
# import data
DF.screen <-
read_xlsx(path = "metaware_data.xlsx",
sheet = "records.screening",
na = c("N/A")) %>%
select(year)
hist(DF.screen$year,
breaks = seq(from = 1960,
to = 2022,
by = 2))
rm(DF.screen)
# Chunk 3: open/clean data
# import data
DF <- read_xlsx(path = "metaware_data.xlsx",
sheet = "coding",
na = c("NA"))
# delete unnecessary variables
DF <- DF %>%
# remove reference columns
select(-ends_with("ref")) %>%
# remove variables we won't include in any analyses
select(-c(prop.woman : online, note))
# temporarily delete p-value caess
# DF <- DF %>%
#   filter(es.calc != "pval")
# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
# effect size by year
DF$year %>% hist()
# record by year
tmp <- DF %>%
distinct(id,
.keep_all = T)
tmp$year %>%
hist(breaks = seq(from = 1960,
to = 2022,
by = 2))
# Chunk 4: define function EsBetwMean
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1,
n.2, m.2, sd.2){
sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
((n.2 - 1) * (sd.2^2))) /
(n.1 + n.2 - 2));
es <- (m.1 - m.2) / sd.within;
return(es)
}
# Chunk 5: define function EsBetwTval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
es <- tval * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 6: define function EsBetwFval
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval){
es <- sqrt((fval * (n.1 + n.2)) /
(n.1 * n.2));
return(es)
}
# Chunk 7
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval){
# calculate the inverse of the cumulative distribution function of t
t.inv <- qt(p = (pval / 2),
df = (n.1 + n.2 - 2),
lower.tail = FALSE);
es <- t.inv * sqrt((n.1 + n.2) /
(n.1 * n.2));
return(es)
}
# Chunk 8: define function EsVarBetw
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){
es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
((es^2) / (2 * (n.1 + n.2)));
return(es.var)
}
# Chunk 9: b: call functions to calculate d
for (i in 1:nrow(DF)) {
if (DF$design[i] == "between"){
# call EsBetwMean on cases with between-subject designs and *means*
if (DF$es.calc[i] == "m_sd") {
DF$es[i] <- EsBetwMean(n.1 = DF$n.1[i],
m.1 = DF$m.1[i],
sd.1 = DF$sd.1[i],
n.2 = DF$n.2[i],
m.2 = DF$m.2[i],
sd.2 = DF$sd.2[i])
}
# call EsBetwTval on cases with between-subject designs and *t-values*
if (DF$es.calc[i] == "t") {
DF$es[i] <- EsBetwTval(n.1 = DF$n.1[i],
n.2 = DF$n.2[i],
tval = DF$tval[i])
}
# call EsBetwFval on cases with between-subject designs and *F-values*
if (DF$es.calc[i] == "f") {
DF$es[i] <- EsBetwFval(n.1 = DF$n.1[i],
n.2 = DF$n.2[i],
fval = DF$fval[i])
}
# call EsBetwenPval on cases with between-subject designs and *p-values*
if (DF$es.calc[i] == "p") {
DF$es[i] <- EsBetwPval(n.1 = DF$n.1[i],
n.2 = DF$n.2[i],
pval = DF$pval[i])
}
# call EsVarBetw on cases with between subject designs
DF$es.var[i] <- EsVarBetw(n.1 = DF$n.1[i],
n.2 = DF$n.2[i],
es = DF$es[i])
}
}
DF$r %>% unique()
DF$es.calc %>% unique()
tmp <- DF %>% filter(es.calc == "or")
View(tmp)
# Chunk 1: setup and load packages
# clean environment
rm(list = ls())
# load packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# call package function
packages <- c('metafor', 'tidyverse',
'readxl', 'robumeta')
ipak(packages)
rm(packages, ipak)
# turn scientific notation off
options(scipen = 999)
# Chunk 2
# import data
DF.screen <-
read_xlsx(path = "metaware_data.xlsx",
sheet = "records.screening",
na = c("N/A")) %>%
select(year)
hist(DF.screen$year,
breaks = seq(from = 1960,
to = 2022,
by = 2))
rm(DF.screen)
# Chunk 3: open/clean data
# import data
DF <- read_xlsx(path = "metaware_data.xlsx",
sheet = "coding",
na = c("NA"))
# delete unnecessary variables
DF <- DF %>%
# remove reference columns
select(-ends_with("ref")) %>%
# remove variables we won't include in any analyses
select(-c(prop.woman : online, note))
# temporarily delete p-value caess
# DF <- DF %>%
#   filter(es.calc != "pval")
# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the
# Cohen's d functions (defined later) to work
DF$es <- NA
DF$es.var <- NA
# effect size by year
DF$year %>% hist()
# record by year
tmp <- DF %>%
distinct(id,
.keep_all = T)
tmp$year %>%
hist(breaks = seq(from = 1960,
to = 2022,
by = 2))
tmp <- DF %>%
filter(es.calc == "or")
?ln
tmp <- tmp %>%
mutate(or = (count.1 * (n.2 - count.2)) /
((n.1 - count.1) * count.2)
)
View(tmp)
tmp %>% names()
tmp <- DF %>%
filter(es.calc == "or") %>%
select(es.calc, n.1, n.2, count.1, count.2)
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
# focus on or
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
# add test row
tmp <- rbind(tmp,
cbind(name = "test",
es.calc = "or",
n.1 = 100,
n.2 = 100,
count.1 = 5,
count.2 = 10))
# compute OR and lnOR
tmp <- tmp %>%
mutate(or = (count.1 * (n.2 - count.2)) /
((n.1 - count.1) * count.2)
)
# focus on OR
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
# add test row
tmp <- rbind(tmp,
cbind(name = "test",
es.calc = "or",
n.1 = 100,
n.2 = 100,
count.1 = 5,
count.2 = 10))
tmp %>% summary()
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
summary(tmp)
# focus on OR
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
# add test row
tmp <- rbind(tmp,
cbind(name = "test",
es.calc = "or",
n.1 = as.numeric(100),
n.2 = as.numeric(100),
count.1 = as.numeric(5),
count.2 = as.numeric(10))
)
# compute OR and lnOR
tmp <- tmp %>%
mutate(or = (count.1 * (n.2 - count.2)) /
((n.1 - count.1) * count.2)
)
View(tmp)
summary(tmp)
tmp <- DF %>%
filter(es.calc == "or") %>%
select(name, es.calc, n.1, n.2, count.1, count.2)
# add test row
tmp2 <- cbind(name = "test",
es.calc = "or",
n.1 = as.numeric(100),
n.2 = as.numeric(100),
count.1 = as.numeric(5),
count.2 = as.numeric(10))
tmp2 %>% summary()
