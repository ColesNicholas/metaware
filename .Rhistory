", ",
mod.r$ref.type.full$sub$ci.ub[[2]] %>% round(2),
"]"
),
p = mod.r$ref.type.full$sub$pval[[2]]
),
## nvc
cbind(
`Moderator (bolded) and level` = "     negative vs. control",
s = DF.es[DF.es$ref.type == 'nvc', ]$id.study %>%
unique() %>%
length(),
k = DF.es[DF.es$design == 'nvc', ]$id.es %>%
unique() %>%
length(),
g =  mod.r$ref.type.full$sub$b[[3]] %>% round(2),
B1 = "--",
`F` = mod.r$ref.type.full$sub$zval[[3]] ^ 2 %>%
round(2),
`95% CI` =
paste0(
"[",
mod.r$ref.type.full$sub$ci.lb[[3]] %>% round(2),
", ",
mod.r$ref.type.full$sub$ci.ub[[3]] %>% round(2),
"]"
),
p = mod.r$ref.type.full$sub$pval[[3]]
),
## pvz
cbind(
`Moderator (bolded) and level` = "     positive vs. nil",
s = DF.es[DF.es$ref.type == 'pvz', ]$id.study %>%
unique() %>%
length(),
k = DF.es[DF.es$design == 'pvz', ]$id.es %>%
unique() %>%
length(),
g =  mod.r$ref.type.full$sub$b[[5]] %>% round(2),
B1 = "--",
`F` = mod.r$ref.type.full$sub$zval[[5]] ^ 2 %>%
round(2),
`95% CI` =
paste0(
"[",
mod.r$ref.type.full$sub$ci.lb[[5]] %>% round(2),
", ",
mod.r$ref.type.full$sub$ci.ub[[5]] %>% round(2),
"]"
),
p = mod.r$ref.type.full$sub$pval[[5]]
),
## pvz
cbind(
`Moderator (bolded) and level` = "     positive vs. negative",
s = DF.es[DF.es$ref.type == 'pvn', ]$id.study %>%
unique() %>%
length(),
k = DF.es[DF.es$design == 'pvn', ]$id.es %>%
unique() %>%
length(),
g =  mod.r$ref.type.full$sub$b[[4]] %>% round(2),
B1 = "--",
`F` = mod.r$ref.type.full$sub$zval[[4]] ^ 2 %>%
round(2),
`95% CI` =
paste0(
"[",
mod.r$ref.type.full$sub$ci.lb[[4]] %>% round(2),
", ",
mod.r$ref.type.full$sub$ci.ub[[4]] %>% round(2),
"]"
),
p = mod.r$ref.type.full$sub$pval[[4]]
),
################
# Publication status
################
cbind(
`Moderator (bolded) and level` = "Publication status",
s = mod.r$published$mod$s.nlevels.f[[1]],
k = mod.r$published$mod$s.nlevels.f[[2]],
g =  "--",
B1 = "--",
`F` = mod.r$published$mod$QM %>% round(2),
`95% CI` = "--",
p = mod.r$published$mod$QMp
),
## published
cbind(
`Moderator (bolded) and level` = "     published",
s = DF.es[DF.es$publisheg = = 'yes', ]$id.study %>%
unique() %>%
length(),
k = DF.es[DF.es$publisheg = = 'yes', ]$id.es %>%
unique() %>%
length(),
g =  mod.r$published$sub$b[[2]] %>% round(2),
B1 = "--",
`F` = mod.r$published$sub$zval[[2]] ^ 2 %>%
round(2),
`95% CI` =
paste0(
"[",
mod.r$published$sub$ci.lb[[2]] %>% round(2),
", ",
mod.r$published$sub$ci.ub[[2]] %>% round(2),
"]"
),
p = mod.r$published$sub$pval[[2]]
),
## unpublished
cbind(
`Moderator (bolded) and level` = "     unpublished",
s = DF.es[DF.es$publisheg = = 'no', ]$id.study %>%
unique() %>%
length(),
k = DF.es[DF.es$publisheg = = 'no', ]$id.es %>%
unique() %>%
length(),
g =  mod.r$published$sub$b[[1]] %>% round(2),
B1 = "--",
`F` = mod.r$published$sub$zval[[1]] ^ 2 %>%
round(2),
`95% CI` =
paste0(
"[",
mod.r$published$sub$ci.lb[[1]] %>% round(2),
", ",
mod.r$published$sub$ci.ub[[1]] %>% round(2),
"]"
),
p = mod.r$published$sub$pval[[1]]
)
) %>%
apa_table()
# Chunk 15: modforest
## list of moderators
mod.list <- c("student", "paid", "online", "ref.type", "design")
## function for extraction
mod.df <- map_df(mod.list, function(x) {
tibble(mod = x,
level = str_replace(rownames(mod.r[[x]]$sub$beta), mod, ""),
beta = mod.r[[x]]$sub$beta %>%
as.numeric() %>%
round(2),
lb = mod.r[[x]]$sub$ci.lb %>%
round(2),
ub = mod.r[[x]]$sub$ci.ub %>%
round(2))
})
## manually update some labels
mod.df <- mod.df %>%
mutate(level = recode_factor(.x = level,
nvc = "negative",
cvp = "positive",
cvz = "nil"),
mod = recode_factor(.x = mod,
ref.type = "demand"))
## reorder factors
mod.df$level <- fct_reorder(mod.df$level,
mod.df$beta,
.desc = TRUE)
## Create forest plot with effect size distribution superimposed
ggplot(mod.df,
aes(x = level,
y = beta)) +
# dotted line at d = 0
geom_hline(yintercept = 0,
linetype = "dotted",
alpha = .5,
size =.5) +
# estimates and CI
geom_pointrange(aes(ymin = lb,
ymax = ub),
alpha = .8,
color = "dark grey") +
# update labels
xlab("") +
ylab(expression(paste("Estimated subgroup mean (Hedge's ", italic("g"), ")"))) +
# clean up aesthetics
coord_flip() +
facet_grid(mod ~ . , scales = "free_y") +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = .5,  hjust=1))
# delete vestigial
rm(mod.df)
# Chunk 16: predplot
# set R back to default contrasts
options(contrasts = c("contr.treatment", "contr.poly"))
# change reference levels for:
## In-person study, no payment, students, positive demand
DF.es$student <- factor(DF.es$student,
levels = c("yes", "mix", "no"))
## fit model
m.s1 <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online + ref.type,
test = "t")
# change reference levels for:
## Online study, payment, non-students, positive demand
DF.es$online <- factor(DF.es$online,
levels = c("yes", "no"))
DF.es$paid <- factor(DF.es$paid,
levels = c("yes", "no"))
DF.es$student <- factor(DF.es$student,
levels = c("no", "mix", "yes"))
## fit model
m.s2 <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = ~ student + paid + online + ref.type,
test = "t")
# manually add output from the models that estimated effects in two common research scenarios
pred_df <-
bind_rows(tibble(level = "in-person\nstudents\nno payment",
mod = "custom",
beta = m.s1$beta[1] %>%
as.numeric %>%
round(2),
lb = m.s1$ci.lb[1] %>%
as.numeric %>%
round(2),
ub = m.s1$ci.ub[1] %>%
as.numeric %>%
round(2)),
tibble(level = "online\nnon-students\npayment",
mod = "custom",
beta = m.s2$beta[1] %>%
as.numeric %>%
round(2),
lb = m.s2$ci.lb[1] %>%
as.numeric %>%
round(2),
ub = m.s2$ci.ub[1] %>%
as.numeric %>%
round(2)
))
# plot
ggplot(pred_df, aes(x = level, y = beta)) +
# line at d = 0
geom_hline(yintercept = 0,
lty = 2,
alpha = .5,
size =.5) +
# point estimate and 95% CI
geom_pointrange(aes(ymin = lb, ymax = ub),
alpha = .8,
color = "dark grey") +
# aes
xlab("") +
coord_flip() +
ylab(expression(paste("Estimated overall effect (Hedge's ", italic("g"), ")"))) +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, vjust = .5,  hjust=1))
# Chunk 17: pub.bias
# delete vestigial
rm(in.s, on.s, v.s, p.s,
m.s1, m.s2,
m.sens, m.sens.student, m.sens.online, m.sens.pay)
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- corrected_meta(yi = DF.es$es,
vi = DF.es$es.var,
eta = 49,
clustervar = DF.es$id.study,
model = "robust",
favor.positive = T)
# 2a. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 2b. cluster robust three-level precision-effect test
########################
pe.3l.r <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es) %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
# delete vestigial
rm(in.s, on.s, v.s, p.s,
m.s1, m.s2,
m.sens, m.sens.student, m.sens.online, m.sens.pay)
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- corrected_meta(yi = DF.es$es,
vi = DF.es$es.var,
eta = 49,
clustervar = DF.es$id.study,
model = "robust",
favor.positive = T)
# 2a. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 2b. cluster robust three-level precision-effect test
########################
pe.3l.r <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es) %>%
robust(x = .,
cluster = id.study,
clubSandwich = T)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") %>%
metafor::funnel(hlines = "lightgray",
xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
funnel.plot <- recordPlot()
# clear R environment
plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
pe.3l.r = pe.3l.r,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pe.a"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
pub.r$rho_0.5$pe.3l
pub.r$rho_0.5$pe.3l.r
