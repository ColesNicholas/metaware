sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation = if_else(grepl("dissertation", link),
1,
0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
rm(DF.s, r.pi, r.unp)
DF.es <-
#open data
read_csv(path = "data/metaware_data_clean.csv")
?read.csv
DF.es <-
# open data
read_csv(file = "data/metaware_data_clean.csv")
DF.es <-
# open data
read_csv(file = "data/metaware.data_clean.csv")
DF.es$id %>% unique() %>% length()
DF.es$id %>% unique() %>% length()
DF.es$name %>% unique()
DF.es$name %>% unique()
DF.es$name %>% unique() %>% arrange() %>% View()
DF.es$name %>% unique() %>% View()
.
DF.es$name %>% unique() %>% View()
DF.es$name %>% unique()
# load necessary packages
library("papaja")
library("tidyverse")
library("readxl")
# identify refs
r_refs("r-references.bib")
?read.csv
vig.n <- read.csv(file = "vig/metaware.vig.csv")
vig.n <- read.csv(file = "vig/metaware.vig.csv") %>%
nrow()
# load necessary packages
library("papaja")
library("tidyverse")
library("readxl")
# identify refs
r_refs("r-references.bib")
knitr::include_graphics("images/metaware_framework.png")
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_data_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation = if_else(grepl("dissertation", link),
1,
0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# open effect size data
DF.es <-
read_csv(file = "data/metaware.data_clean.csv")
# specify number of studies (denoted by id column)
num.s <- DF.es$id %>%
unique() %>%
length()
# specify number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
rm(DF.s, r.pi, r.unp, num.s, num.p)
# identify total number of vignettes
vig.n <- read.csv(file = "vig/metaware_VigCombined.csv") %>%
nrow()
knitr::include_graphics("images/metaware_vigs.png")
knitr::include_graphics("images/metaware_mods.png")
DF.es %>%
group_by(name) %>%
count()
DF.es %>%
group_by(name) %>%
count()
DF.es %>%
group_by(id) %>%
count()
?if_else
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
mean(.$dep)
?mean
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
select(dep) %>%
mean()
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
summarise(mult.eff = mean(dep))
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep))
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
as.numeric()
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() * 100 %>%
round(2)
?round
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() * 100 %>%
round(digits = 2)
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2)
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2) %>%
. * 100
DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2) * 100
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2) * 100
overall <-
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
library(metafor)
overall <-
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
overall
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
DF.es$es.id <- 1 : nrow(DF.es)
overall <- rma.mv(yi = es,
V = es.var,
data = DF,
random = ~ 1 | id / es.id)
overall <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id / es.id)
overall
# clean environment
rm(list = ls())
library("tidyverse")
library("readxl")
# Chunk 1: setup
# load necessary packages
library("papaja")
library("tidyverse")
library("readxl")
# identify refs
r_refs("r-references.bib")
# Chunk 2: framework
knitr::include_graphics("images/metaware_framework.png")
# Chunk 3: literature search
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_data_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation = if_else(grepl("dissertation", link),
1,
0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# Chunk 4: final.df
# open effect size data
DF.es <-
read_csv(file = "data/metaware.data_clean.csv")
# specify number of studies (denoted by id column)
num.s <- DF.es$id %>%
unique() %>%
length()
# specify number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
# Chunk 5: clean.env.1
rm(DF.s, r.pi, r.unp, num.s, num.p)
# Chunk 6: vig.desc
# identify total number of vignettes
vig.n <- read.csv(file = "vig/metaware_VigCombined.csv") %>%
nrow()
# Chunk 7: vig
knitr::include_graphics("images/metaware_vigs.png")
# Chunk 8: mods
knitr::include_graphics("images/metaware_mods.png")
# Chunk 9
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2) * 100
overall <-
robu(formula = es ~ 1,
data = DF,
studynum = id,
var.eff.size = es.var,
modelweights = "HIER",
small = FALSE)
library("robumeta")
# estimate overall effect size
overall <-
robu(formula = es ~ 1,
data = DF,
studynum = id,
var.eff.size = es.var,
modelweights = "HIER",
small = FALSE)
overall <-
robu(formula = es ~ 1,
data = DF.es,
studynum = id,
var.eff.size = es.var,
modelweights = "HIER",
small = FALSE)
overall
View(overall)
print(overall)
install.packages("robumeta")
install.packages("robumeta")
install.packages("robumeta")
install.packages("robumeta")
# Chunk 1: setup
# load necessary packages
library("papaja")
library("tidyverse")
library("readxl")
library("robumeta")
# identify refs
r_refs("r-references.bib")
# Chunk 2: framework
knitr::include_graphics("images/metaware_framework.png")
# Chunk 3: literature search
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_data_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation = if_else(grepl("dissertation", link),
1,
0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# Chunk 4: final.df
# open effect size data
DF.es <-
read_csv(file = "data/metaware.data_clean.csv")
# specify number of studies (denoted by id column)
num.s <- DF.es$id %>%
unique() %>%
length()
# specify number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
# Chunk 5: clean.env.1
rm(DF.s, r.pi, r.unp, num.s, num.p)
# Chunk 6: vig.desc
# identify total number of vignettes
vig.n <- read.csv(file = "vig/metaware_VigCombined.csv") %>%
nrow()
# Chunk 7: vig
knitr::include_graphics("images/metaware_vigs.png")
# Chunk 8: mods
knitr::include_graphics("images/metaware_mods.png")
# Chunk 9
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as numeric and turn into percentage
as.numeric() %>%
round(digits = 2) * 100
# estimate overall effect size
overall <-
robu(formula = es ~ 1,
data = DF.es,
studynum = id,
var.eff.size = es.var,
modelweights = "HIER",
small = FALSE)
View(overall)
?robu
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
library('metafor')
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
tmp <- rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
View(tmp)
overall <-
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML") %>%
robust(cluster = DF.es$id)
overall
View(overall)
overall$b
overall.es <-
overall$b %>%
as.numeric %>%
round(2)
overall.es
overall$ci.lb
overall.lb <-
overall$ci.lb %>%
round(2)
overall
overall.lb
overall.ub
overall$ci.ub
overall
View(overall)
overall.t <-
overall$zval %>%  #  says t in output
round(2)
overall.t
overall[["pval"]]
overall
overall$tau2
overall$tau
overall$se.tau2
overall$tau.2 %>% sqrt
overall$tau.2
overall$tau2 %>% sqrt
overall$tau2 %>% sqrt
overall$I2
rnorm(1000, overall$b, sqrt(overall$tau2)) %>% plot()
rnorm(1000, overall$b, sqrt(overall$tau2)) %>% hist()
