mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year")
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
# test ref.type moderator in scenarios where there is a control comparison (i.e., ref.r == single)
mod.r[["ref.type"]] <-
ModAnalysis(m = "ref.type",
df = DF.es[DF.es$ref.r == "single", ])
# add motivation, opportunity, belief, and prediction moderators
## Note: comparisons with nil-demand conditions are excluded
mod.r.2 <-
sapply(X = c("mot", "opp", "bel", "pre"),
simplify = F,
FUN = ModAnalysis,
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz"))
## combine results
mod.r = c(mod.r, mod.r.2)
# delete vestigial
rm(ModAnalysis, mod.r.2)
# Chunk 15: mod.fig
#################
# motivation plot
#################
# get predicted and actual values into a single dataset
mot.df <- predict(mod.r$mot$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$mot$mod$yi)
# plot
m <- ggplot(data = mot.df,
aes(x = X.mot,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "Cohen's d",
x = "motivation ratings")
rm(mot.df)
#################
# opportunity plot
#################
# get predicted and actual values into a single dataset
opp.df <- predict(mod.r$opp$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$opp$mod$yi)
# plot
o <- ggplot(data = opp.df,
aes(x = X.opp,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "",
x = "opportunity ratings")
rm(opp.df)
#################
# belief plot
#################
# get predicted and actual values into a single dataset
bel.df <- predict(mod.r$bel$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$bel$mod$yi)
# plot
b <- ggplot(data = bel.df,
aes(x = X.bel,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "Cohen's d",
x = "belief ratings")
rm(bel.df)
#################
# prediction plot
#################
# get predicted and actual values into a single dataset
pre.df <- predict(mod.r$pre$mod,
addx = T) %>%
as.data.frame() %>%
cbind(.,
yi = mod.r$pre$mod$yi)
# plot
p <- ggplot(data = pre.df,
aes(x = X.pre,
y = yi)) +
# jittered raw data
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
# model derived prediction line
geom_line(aes(y = pred)) +
# model derived CI
geom_ribbon(aes(ymin = ci.lb,
ymax = ci.ub),
alpha = .10,
fill = "#3366FF") +
# adjust labels
labs(y = "",
x = "prediction ratings")
rm(pre.df)
#################
# merge plots
#################
plot_grid(m, o, b, p,
labels = c("A", "B", "C", "D"))
rm(m, o, b, p)
# Chunk 16: pub.bias
##########################
# Define publication bias analysis that
# 1. Mathur and VanderWeele 2020 sensitivity analyses
# 2. Fits three-level precision-effect test
# 3a. Aggregates dependent effect sizes (with given rho value)
# 3b. Aggregated precision-effect test
# 3b. Fits Vevea and Hedges (1995) Weight-Function Model w/ aggregated effects
# 4a. Fit funnel plot
# 4b. Fit funnel plot w/ aggregated dependencies
# 5. Organizes results into list
##########################
PubBias = function(rho.val = .5){
# 1. sensitivity analyses
########################
sens <- corrected_meta(yi = DF.es$es,
vi = DF.es$es.var,
eta = 49,
clustervar = DF.es$id.study,
model = "robust",
favor.positive = T)
# 2. three-level precision-effect test
########################
pe.3l <- rma.mv(yi = es,
V = es.var,
mods = ~ sqrt(es.var),
data = DF.es,
random = ~ 1 | id.study / id.es)
# 3a. aggregate dependent effect sizes
########################
DF.agg <- DF.es %>%
# convert to an 'escalc' object so function can run
escalc(yi = es,
vi = es.var,
data = DF.es,
measure = "SMD") %>%
# delete vestigial: es is now yi; es.var is now vi
select(-c(es, es.var)) %>%
# aggregate dependencies
aggregate(x = .,
cluster = id.study,
rho = rho.val)
# 3b. aggregated precision-effect test
########################
pe.a <- rma.uni(yi = yi,
vi = vi,
mods = ~ sqrt(vi),
data = DF.agg,
method = "REML")
# 3c. Weight-function model
########################
weight.funct <- weightfunct(effect = DF.agg$yi,
v = DF.agg$vi,
mods = NULL,
weights= NULL,
fe = FALSE,
table = TRUE,
pval = NULL)
# 4a. funnel plot
########################
#par(mfrow=c(1,2))
rma.uni(yi = es,
vi = es.var,
data = DF.es,
method = "REML")# %>%
# metafor::funnel(hlines = "lightgray",
# xlab = "Cohen's standardized d")
# 4b. funnel plot w/ aggregated dependencies
########################
funnel.plot <- rma.uni(yi = yi,
vi = vi,
data = DF.agg,
method = "REML") #%>%
#metafor::funnel(hlines = "lightgray",
#               xlab = "Cohen's standardized d (aggregated)")
# save funnel plot as object
#funnel.plot <- recordPlot()
# clear R environment
#plot.new()
# 5. Organize results in list
########################
list(sens = sens,
pe.3l = pe.3l,
DF.agg = DF.agg,
pe.a = pe.a,
weight.funct = weight.funct,
funnel = funnel.plot) %>%
return()
}
# for range of rho values, run publication bias analyses
rho.l = seq(from = .1,
to = .9,
by = .2)
pub.r <- lapply(X = rho.l,
FUN = PubBias)
names(pub.r) = paste0("rho_", rho.l) #  name list
# delete vestigial
rm(rho.l, PubBias)
# look at sensitivity analyses
## general story: often, but not always, find evidence of reverse publication bias (preference for negative effects)
# lapply(pub.r, function(x){x[["pet"]]})
# lapply(pub.r, function(x){x[["peese"]]})
# lapply(pub.r, function(x){x[["weight.funct"]]})
# lapply(pub.r, function(x){x[["funnel"]]})
# plot funnels
# overall %>%
#   metafor::funnel(x = .,
#                   hlines = "lightgray",
#                   xlab = "Cohen's standardized d")
#
# pub.r$rho_0.5$pe.3l$b[2]
#
# pub.r$rho_0.5$weight.funct %>% View()
# Chunk 18: funnel2
##########non-aggregated
# create temp dataset with se values
tmp <- DF.es %>%
rowwise() %>%
mutate(se = sqrt(es.var)) %>%
ungroup()
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(DF.es))
ll95 = overall$b[1] - (1.96 * se.seq)
ul95 = overall$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = overall$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
# plot
a <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
scale_y_reverse() +
geom_vline(xintercept = overall$b[1],
linetype = "dotted") +
labs(x = "Cohen's d",
y = "Standard error")
##########aggregated
tmp <- pub.r$rho_0.5$DF.agg %>%
rowwise() %>%
mutate(es = yi,
se = sqrt(vi)) %>%
ungroup()
# create temporary sequence of ses
se.seq = seq(0, max(tmp$se),
length.out = nrow(tmp))
ll95 = overall$b[1] - (1.96 * se.seq)
ul95 = overall$b[1] + (1.96 * se.seq)
# create coordinates for polygon
t.coord <- rbind(cbind(x = pub.r$rho_0.5$funnel$b[1],
y = 0),
cbind(x = min(ll95),
y = max(tmp$se)),
cbind(x = max(ul95),
y = max(tmp$se))
) %>%
as.data.frame()
# plot
b <- ggplot(data = tmp,
aes(x = es,
y = se)) +
geom_polygon(data = t.coord,
aes(x = x,
y = y),
fill = "#3366FF",
alpha = .1) +
geom_jitter(alpha = .8,
fill = "dark grey",
color = "dark grey") +
scale_y_reverse() +
geom_vline(xintercept = pub.r$rho_0.5$funnel$b[1],
linetype = "dotted") +
labs(x = "Cohen's d",
y = "Standard error")
plot_grid(a, b,
labels = c("A", "B"))
DF.es %>%
filter(name == "Demand effects in survey experiments: An empirical assessment") %>%  View
DF.es$bel %>% hist()
DF.es %>%
filter(name == "Demand effects in survey experiments: An empirical assessment") %>%
summarise(m.bel = mean(bel))
View(DF.es)
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
View() summarise(m.bel = mean(bel))
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
View() summarise(m.bel = mean(bel))
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
View()
DF.es %>%
filter(id.study == 11 | id.study == 12 | id.study == 13) %>%
summarise(m.bel = mean(bel))
DF.es %>%
filter(name == "Demand effects in survey experiments: An empirical assessment") %>%
summarise(m.bel = mean(bel))
DF.es$year %>% hist()
tmp <- DF.es %>%
filter(year > 2010)
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2020)
)
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t")
sub.m <- rma.mv(yi = es,
V = es.var,
data = df,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2020)
)
mod.r[["pre"]][["modern"]]
mod.r[["pre"]][["modern"]]
tmp <- DF.es %>%
filter(year > 2010)
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2010)
)
mod.r[["pre"]][["modern"]]
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["pre"]][["modern"]]
mod.r[["mot"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["opp"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["bel"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["pre"]][["modern"]]
mod.r[["mot"]][["modern"]]
mod.r[["pre"]][["modern"]][["mod"]]
mod.r[["mot"]][["modern"]][["mod"]]
mod.r[["mot"]][["modern"]] <-
ModAnalysis(m = "mot",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["mot"]][["modern"]][["mod"]]
mod.r[["opp"]][["modern"]][["mod"]]
mod.r[["opp"]][["modern"]][["mod"]]
mod.r[["bel"]][["modern"]] <-
ModAnalysis(m = "bel",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["bel"]][["modern"]][["mod"]]
# pre
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2010)
)
mod.r[["pre"]][["modern"]][["mod"]]
mod.r[["mot"]][["modern"]] <-
ModAnalysis(m = "mot",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2010)
)
mod.r[["mot"]][["modern"]][["mod"]]
mod.r[["opp"]][["modern"]] <-
ModAnalysis(m = "opp",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2010)
)
mod.r[["opp"]][["modern"]][["mod"]]
mod.r[["bel"]][["modern"]] <-
ModAnalysis(m = "bel",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2010)
)
mod.r[["bel"]][["modern"]][["mod"]]
# pre
mod.r[["pre"]][["modern"]] <-
ModAnalysis(m = "pre",
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz" &
year > 2012)
)
mod.r[["pre"]][["modern"]][["mod"]]
rm(tmp)
View(mod.r)
mod.r[["pre"]][["mod"]]
