as.numeric)
DF.surv <- DF.surv %>%
# identify whether the demand condition was pos, neg, or nil
mutate(dem = substr(x = vig,
start = 4,
stop = 4))
## set att.chk to 0 (false) by default
DF.surv$att.chk = 0
## set att.chk to 1 when hypothesis is correctly identified
DF.surv[DF.surv$dem == "p" &
!is.na(DF.surv$awr) &
DF.surv$awr == 1, ]$att.chk = 1
DF.surv[DF.surv$dem == "n" &
!is.na(DF.surv$awr) &
DF.surv$awr == 2, ]$att.chk = 1
DF.surv[DF.surv$dem == "z" &
!is.na(DF.surv$awr) &
DF.surv$awr == 3, ]$att.chk = 1
## if participants did not specify a  hypothesis, set att.chk to NA
DF.surv[is.na(DF.surv$awr), ]$att.chk = NA
DF.surv %>%
summarise(m = mean(att.chk,
na.rm = T))
DF.surv %>%
group_by(dem) %>%
summarise(m = mean(att.chk,
na.rm = T))
DF.surv %>%
group_by(vig) %>%
filter(!is.na(att.chk)) %>%
summarise(n = n(),
m = mean(att.chk)) %>%
arrange(m)
DF.surv %>%
group_by(vig) %>%
filter(is.na(att.chk))
# split by vignette
DF.surv %>%
group_by(vig) %>%
filter(!is.na(att.chk)) %>%
summarise(n = n(),
m = mean(att.chk)) %>%
arrange(m) %>%
View()
DF.surv <- DF.surv %>%
filter(att.chk == 1)
surv.sum <- DF.surv %>%
group_by(vig) %>%
summarise(m.mot = mean(mot, na.rm = T),
m.opp = mean(opp, na.rm = T),
m.bel = mean(bel, na.rm = T),
m.pre = mean(pre, na.rm = T)
) %>%
ungroup()
rm(DF.surv)
# connect summary data to ES dataframe
DF <- DF %>%
# rename vig.1 to vig to enable join
rename(vig = vig.1) %>%
# connect summary data to vig.1
left_join(x = .,
y = surv.sum,
by = "vig") %>%
# rename vig.1 summary columns
rename(v1.mot = m.mot,
v1.opp = m.opp,
v1.bel = m.bel,
v1.pre = m.pre) %>%
# rename vig.2 to vig to prep for join
rename(vig.1 = vig,
vig = vig.2) %>%
# connect summary data to vig.2
left_join(x = .,
y = surv.sum,
by = "vig") %>%
# rename vig.2 summary columns
rename(v2.mot = m.mot,
v2.opp = m.opp,
v2.bel = m.bel,
v2.pre = m.pre) %>%
# sum motivation, opportunity, belief, and prediction scores
rowwise() %>%
mutate(mot = sum(c(v1.mot, v2.mot),
na.rm = T),
opp = sum(c(v1.opp, v2.opp),
na.rm = T),
bel = sum(c(v1.bel, v2.bel),
na.rm = T),
pre = sum(c(v1.pre, v2.pre),
na.rm = T)) %>%
ungroup()
rm(surv.sum)
# tmp code: if  no vignette ratings exist, leave mot to pre blank
DF[is.na(DF$v1.mot), ]$mot = NA
DF[is.na(DF$v1.mot), ]$opp = NA
DF[is.na(DF$v1.mot), ]$bel = NA
DF[is.na(DF$v1.mot), ]$pre = NA
# arrange variables
DF <- DF %>%
select(id.study, id.es,
name : ref.r,
es, es.var,
mot : pre)
# import data
DF.surv2 <-
read_csv(file = "data/metaware_SurvData_raw.csv")
# remove rows containing unnecessary variable details
DF.surv2 <- DF.surv2[-(1 : 2), ]
# process data
DF.surv2 <- DF.surv2 %>%
# identify relevant variables
select(
# block 1 happy pose emotion reports
hap1_bl1_hap : hap1_bl1_enj,
# block 1 neutral pose emotion reports
neu1_bl1_hap : neu1_bl1_enj,
# block 2 happy pose emotion reports
hap2_bl2_hap : hap2_bl2_enj,
# block 2 neutral pose emotion reports
neu2_bl2_hap : neu2_bl2_enj,
# motivation, prediction, belief, and opportunity scores
mot : opp, mot_gen,
# manipulation check items (awareness and attention checks)
hap1_bl1_att, hap2_bl2_att, neu1_bl1_att, neu2_bl2_att,
awr,
# condition and individual difference items
demand,
indiv_gend_var, indiv_agee_var, ethnicity,
# relevant vignette data
`46_awr` : `46_opp`,
`47_awr` : `47_opp`) %>%
# rename vignette variables
rename(pos_awr = `46_awr`,
pos_mot = `46_mot`,
pos_pre = `46_pre`,
pos_bel = `46_bel`,
pos_opp = `46_opp`,
nil_awr = `47_awr`,
nil_mot = `47_mot`,
nil_pre = `47_pre`,
nil_bel = `47_bel`,
nil_opp = `47_opp`) %>%
# add subid variable
mutate(sub = factor(1 : nrow(.))) %>%
# identify whether attention checks were all passed
mutate(att.chk =
if_else(condition =
hap1_bl1_att == "5" &
neu1_bl1_att == "5" &
hap2_bl2_att == "5" &
neu2_bl2_att == "5",
true = 1,
false = 1)
) %>%
# create separate rows for each trial
# 1. Gather emotion reports into a single column
gather(key = "dv",
value = "value",
hap1_bl1_hap : neu2_bl2_enj) %>%
# 2. Create separate variables that identify the trial and outcome using "_..._ naming convention separator
separate(col = "dv",
into = c("trial", "outcome"),
sep = "_..._") %>%
# 3. Spread outcomes into individual rows
pivot_wider(names_from = "outcome",
values_from = "value") %>%
# fix variable types
mutate_at(.vars = c("mot", "pre", "bel", "opp",
"mot_gen", "indiv_agee_var",
"hap", "sat", "enj",
"pos_awr", "pos_mot",
"pos_pre", "pos_bel",
"pos_opp",
"nil_awr", "nil_mot",
"nil_pre", "nil_bel",
"nil_opp"),
.funs = as.numeric) %>%
mutate_at(.vars = c("demand", "indiv_gend_var",
"ethnicity", "sub"),
.funs = as.factor) %>%
# Calculate self-reported happiness scores
rowwise() %>%
mutate(happy = mean(c(hap, sat, enj))) %>%
ungroup() %>%
# identify block number
mutate(block.num = if_else(condition = trial == "hap1" |
trial == "neu1",
true = 1,
false = 2),
block.num = factor(block.num)) %>%
# create new trial variable that remove redundant information about block
mutate(trial = substr(x = trial,
start = 1,
stop = 3),
trial = factor(trial)) %>%
# organize dataframe
arrange(sub, block.num, trial) %>%
select(sub, demand, trial, block.num, happy,
att.chk, awr,
mot : mot_gen,
indiv_gend_var : ethnicity,
pos_awr : nil_opp)
if(!exists("sens")){
write.csv(DF,
"data/metaware_data_clean.csv",
row.names = F)
}
write.csv(DF.surv2,
"data/metaware_survey2_clean.csv",
row.names = F)
library(lme4)
library(lmerTest)
library(emmeans)
# test facial feedback by demand interaction
m <- lmer(happy ~ trial * block.num * demand +
(1 | sub),
data = DF.surv2)
anova(m)
emmeans(m,
pairwise ~ trial)
joint_tests(m, by = "demand")
m <- lmer(happy ~ trial + block.num + demand +
(trial : demand) +
(trial : demand : mot) +
(1 | sub),
data = DF.surv2)
summary(m)
anova(m)
m <- lmer(happy ~ trial + block.num + demand +
(trial : demand) +
(trial : demand : bel) +
(1 | sub),
data = DF.surv2)
anova(m)
anova(m)
DF.pos <- DF.surv2 %>%
filter(demand == "pos")
DF.nil <- DF.surv2 %>%
filter(demand == "nil")
cor(DF.pos$pos_mot, DF.pos$mot,
use = "pairwise.complete.obs")
rm(DF.pos, DF.nil)
DF.surv2$mot %>% mean()
DF.surv2$mot %>% mean(na.rm = T)
DF.surv2$mot %>% hist()
DF.surv2$bel %>% hist()
# Chunk 1: setup
# load packages writing and data processing packages
library("papaja")
library("tidyverse")
library("readxl")
# load meta-analyses packages
library("metafor")
library("weightr")
library("PublicationBias")
# identify refs
r_refs("r-references.bib")
# Chunk 2: framework
knitr::include_graphics("images/metaware_framework.png")
# Chunk 3: literature search
# open and process literature search data
DF.s <-
# open data
read_xlsx(path = "data/metaware_EsData_raw.xlsx",
sheet = "records.screening") %>%
# identify unpublished dissertations by identifying links that contain the word 'dissertation'
mutate(dissertation =
if_else(condition = grepl("dissertation", link),
true = 1,
false = 0)
)
# calculate number of records from PsycInfo by removing all records with no known database (i.e., ones that were personally found)
r.pi <- DF.s %>%
filter(!is.na(Database)) %>%
nrow()
# calculate number of unpublished records (i.e., dissertations)
r.unp <- DF.s %>%
filter(dissertation == 1) %>%
nrow()
# Chunk 4: final.df
# open clean effect size data
DF.es <-
read_csv(file = "data/metaware_data_clean.csv")
# identify total number of studies (denoted by id.study column)
num.s <- DF.es$id.study %>%
unique() %>%
length()
# identify total number of papers (denoted by name column)
num.p <- DF.es$name %>%
unique() %>%
length()
# for the known outlier (id = 18), give an example of the largest effect size
outlier.es <- DF.es %>%
filter(id.study == 18) %>%
summarise(max.es = min(es)) %>% #  using min because largest value is neg
round(2)
# Chunk 5: clean.env.1
# remove outlier and re-initialize id factors
DF.es <- DF.es %>%
filter(id.study != 18) %>%
mutate(id.study = factor(id.study),
id.es = factor(id.es))
# clean environment
rm(DF.s, r.pi, r.unp, num.s, num.p, outlier.es)
# Chunk 6: corr.sens
# examine how assumed repeated measures correlation impacts general pattern of results
# get list of sensitivity dataframes
sens.df.list <- list.files(path = "./data/r_sensitivity")
# (1) open dataframe, (2) compute intercept-only model, (3) extract overall es
sens.res <-
sapply(X = sens.df.list,
FUN = function(i){
# open data
df <- read.csv(paste0("data/r_sensitivity/",
i)
)
# fit model
m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# return overall es as a number
m$b %>%
as.numeric() %>%
return()
}
)
# compute range of es values
sens.range <- max(sens.res) - min(sens.res)
# delete vestigial
rm(sens.df.list, sens.res)
# Chunk 7: mult.eff
# calculate percentage of studies with multiple effect sizes
mult.eff.per <- DF.es %>%
# identify number of effect sizes for each study (id)
group_by(id.study) %>%
count() %>%
# code whether each study has more than one effect size
mutate(dep = if_else(condition = n > 1,
true = 1,
false = 0)
) %>%
# calculate proportion of studies with more than one effect size
ungroup() %>%
summarise(mult.eff = mean(dep)) %>%
# export as percentage
as.numeric() %>%
round(digits = 2) * 100
# Chunk 8: vig.desc
# identify total number of vignettes
vig.n <- read.csv(file = "vig/metaware_VigCombined.csv") %>%
nrow()
# Chunk 9: vig
knitr::include_graphics("images/metaware_vigs.png")
# Chunk 10: survey.n
# identify number of participants who completed the survey
survey.n <- read.csv("data/metaware_SurvData_raw.csv") %>%
nrow()
# Chunk 11: mods
knitr::include_graphics("images/metaware_mods.png")
# Chunk 12: clean.env.2
# delete vestigial
rm(mult.eff.per, vig.n, survey.n, sens.range)
# Chunk 13: overall
# estimate overall effect size
overall <-
rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es)
# overall <-
#   rma.uni(yi = es,
#           vi = es.var,
#           data = DF.es,
#           method = "REML") %>%
#   robust(cluster = DF.es$id)
# create moderator analysis function
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t")
sub.m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year")
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
# test ref.type moderator in scenarios where there is a control comparison (i.e., ref.r == single)
mod.r[["ref.type"]] <-
ModAnalysis(m = "ref.type",
df = DF.es[DF.es$ref.r == "single", ])
# add motivation, opportunity, belief, and prediction moderators
## TMP: visualize data
tmp <- DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz")
plot(tmp$es, tmp$mot)
plot(tmp$es, tmp$opp)
plot(tmp$es, tmp$bel)
plot(tmp$es, tmp$pre)
cor(tmp$es, tmp$mot,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$opp,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$bel,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$pre,
use = "pairwise.complete.obs")
# Note: comparisons with nil-demand conditions are excluded
mod.r.2 <-
sapply(X = c("mot", "opp", "bel", "pre"),
simplify = F,
FUN = ModAnalysis,
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz"))
# delete vestigial
rm(mod.l, ModAnalysis)
View(mod.r.2)
mod.r.2[["mot"]][["mod"]]
mod.r.2[["opp"]][["mod"]]
mod.r.2[["bel"]][["mod"]]
DF.es$mot %>% hist()
tmp <- DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz")
plot(tmp$es, tmp$mot)
# create moderator analysis function
ModAnalysis = function(m, df = DF.es) {
# set dataset
df <- df
# moderator analysis
mod.m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ ", m)),
test= "t")
sub.m <- rma.mv(yi = es,
V = es.var,
data = DF.es,
random = ~ 1 | id.study / id.es,
mods = as.formula(paste0("~ 0 + ", m)),
test= "t")
# return results as list
return(list(mod = mod.m,
sub = sub.m))
}
# conduct moderator and subgroup analyses for moderators assessed with full dataset
mod.l <- c("student", "paid", "online",
"design", "ref.r", "published",
"year")
mod.r <-
sapply(X = mod.l,
simplify = F,
FUN = ModAnalysis)
rm(mod.l)
# test ref.type moderator in scenarios where there is a control comparison (i.e., ref.r == single)
mod.r[["ref.type"]] <-
ModAnalysis(m = "ref.type",
df = DF.es[DF.es$ref.r == "single", ])
# add motivation, opportunity, belief, and prediction moderators
## TMP: visualize data
tmp <- DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz")
plot(tmp$es, tmp$mot)
plot(tmp$es, tmp$opp)
plot(tmp$es, tmp$bel)
plot(tmp$es, tmp$pre)
cor(tmp$es, tmp$mot,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$opp,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$bel,
use = "pairwise.complete.obs")
cor(tmp$es, tmp$pre,
use = "pairwise.complete.obs")
# Note: comparisons with nil-demand conditions are excluded
mod.r.2 <-
sapply(X = c("mot", "opp", "bel", "pre"),
simplify = F,
FUN = ModAnalysis,
df = DF.es %>%
filter(ref.type != "cvz" &
ref.type != "pvz"))
# delete vestigial
rm(mod.l, ModAnalysis)
plot(tmp$es, tmp$opp)
plot(tmp$es, tmp$bel)
plot(tmp$es, tmp$pre)
View(mod.r.2)
mod.r.2[["pre"]][["mod"]]
