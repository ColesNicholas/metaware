---
title: Data analysis for "A meta-analysis of the effects of demand characteristics in non-clinical research"
author: "Nicholas A. Coles and Morgan Wyatt"
---
The code was written in `r R.version$version.string` using R Markdown (http://rmarkdown.rstudio.com/).

# Section 1: Data Prep
```{r setup and load packages, include = FALSE}
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    
    sapply(pkg, require, character.only = TRUE)
}

# call package function
packages <- c('metafor', 'tidyverse', 'readxl')
ipak(packages)
rm(packages, ipak)

# turn scientific notation off
options(scipen = 999)
```

## Open and clean data
```{r open/clean data, message = FALSE, warning = FALSE}
# import data
BTX.DF <- read_xlsx(path = "BtxDepress_screening_coding.xlsx",
                    sheet = "coding.final",
                    na = c("F.D.", "N/A"))
 
# delete unnecessary variables
  # create list of unnecessary variables
  del.var.list <- names(BTX.DF) %in% 
    c("article.doi", "coded.by", "study", "ref", "ref_1",
      "ref_2", "ref_3", "ref_4", "ref_5", "ref_6",
      "ref_7", "ref_8", "ref_9", "ref_10", "ref_11",
      "ref_12", "refs", "refs1", "reg.num", "injection site",
      "bot.type")

  # remove unnecessary variables from dataframe
  BTX.DF <- BTX.DF[!del.var.list]
  rm(del.var.list)
  
# delete non-depression records 
# dataframe contains other measures of affect unrelated to our current interest in depression
BTX.DF <- subset(BTX.DF, depressed == "yes")

# convert study-level statistics into continous variables
BTX.DF$b.treat.n <- as.numeric(BTX.DF$b.treat.n) 
BTX.DF$b.treat.m <- as.numeric(BTX.DF$b.treat.m)
BTX.DF$b.treat.sd <- as.numeric(BTX.DF$b.treat.sd)
BTX.DF$b.compa.n <- as.numeric(BTX.DF$b.compa.n)
BTX.DF$b.compa.m <- as.numeric(BTX.DF$b.compa.m)
BTX.DF$b.compa.sd <- as.numeric(BTX.DF$b.compa.sd)
BTX.DF$pval <- as.numeric(BTX.DF$pval)
BTX.DF$pval.df <- as.numeric(BTX.DF$pval.df)
BTX.DF$w.n <- as.numeric(BTX.DF$w.n)
BTX.DF$w.pre.m <- as.numeric(BTX.DF$w.pre.m)
BTX.DF$w.pre.sd <- as.numeric(BTX.DF$w.pre.sd)
BTX.DF$w.post.m <- as.numeric(BTX.DF$w.post.m)
BTX.DF$w.post.sd <- as.numeric(BTX.DF$w.post.sd)
BTX.DF$w.diff.m <- as.numeric(BTX.DF$w.diff.m)
BTX.DF$w.diff.sd <- as.numeric(BTX.DF$w.diff.sd)

# create blank columns for effect size and effect size variance
# Note: these pre-exisiting columns are necessary for the 
# Cohen's d functions (defined later) to work
BTX.DF$es <- NA
BTX.DF$es.var <- NA
```


## Examine selective reporting and COI's
Create an empty list to save output in
```{r coi list}
coi.compl <- list()
```

### In overall database
When constructing the database of reported findings on the effects of BTX on depression, rows for all outcomes were created, even if these outcomes were not actually reported in the paper (e.g., if it was clear that the authors collected data for an outcome at week 2, but did not report it). These rows provide insight into the extent of selecting reporting in this literature. The next batch of code calculates the proportion of incomplete records

When constructing the database, it was noted that many studies had conflicts of interest. This next batch also calculates the extent of conflict of interest in this literature.

Afterwards, all the summary data are placed in a list.
```{r coi complete}
# First, calculate proprtion of complete records and conflicts of interest in *entire dataset*
  # proportion of complete records
  compl <- mean(BTX.DF$complete)
  
  # proportion of records with conflicts of interest
  coi <- mean(BTX.DF$coi)
  
# put summary of overall selective reporting and coi in list called oval (overall)
oval <- list(compl = compl,
             coi = coi)

# nest oval list into the coi.compl list
coi.compl <- list(oval = oval)

# delete vestigial
rm(compl, coi, oval)
```

#### Print summary
```{r coi complete results}
paste0("The proportion of complete records is: ", 
       round(x = coi.compl$oval$compl,
             digits = 2))
```

### Remove incomplete records
```{r remove incompletes}
BTX.DF <- subset(BTX.DF, complete == 1)
```

#### Examine COI in analyzable portion of the dataset
Now that we have limited the dataframe to complete records, we will examine conflicts of interest in the analyzable portion of the dataset
```{r coi in analyzed data}
# examine description of conflicts of interest
coi <- mean(BTX.DF$coi) # conflict of interest
patent <- mean(BTX.DF$patent) #  with investigators who held relevant patents
agn.f <- mean(BTX.DF$allerg.fund) # funded by Allergan
agn.c <- mean(as.numeric
                (BTX.DF$allerg.consult)) # with investigators who consulted for Allergan

# put conflict of interest descriptives in the coi.compl list
coi.compl$anlyz <- list(coi = coi,
                        patent = patent,
                        agn.f = agn.f,
                        agn.c = agn.c)

# delete vestigial
rm(coi, patent, agn.f, agn.c)
```

##### Print summary
```{r coi in analyzed data results}
with(coi.compl$anlyz, {
     list(paste0("Prop of observations with a coi: ", 
                 round(x = coi,
                       digits = 2)),
          paste0("Prop of observations from an author with a patent: ",
                 round(x = patent,
                       digits = 2)),
          paste0("Prop of observations from a study funded by Allergan: ",
                 round(x = agn.f,
                       digits = 2)),
          paste0("Prop of observations from an author who consulted for Allergan: ",
                 round(x = agn.c,
                       digits = 2))
          )
     })
```

# Calculate Cohen's *d* and variance
## For between-subjects data
### Functions for calculating *d* 
#### When *M*'s and *SD*'s are provided
```{r define function EsBetwMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1, 
                       n.2, m.2, sd.2){
    sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
                       ((n.2 - 1) * (sd.2^2))) /
                        (n.1 + n.2 - 2));
    
    es <- (m.1 - m.2) / sd.within;
    return(es)
}
```

#### When *p*-values are provided
```{r define function EsBetwPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval, pval.df){
  # calculate the inverse of the cumulative distribution function of t
  t.inv <- qt(p = (pval / 2), 
              df = pval.df,
              lower.tail = FALSE);
  
  es <- t.inv * sqrt((n.1 + n.2) /
                     (n.1 * n.2));
  
  return(es)
}
```

### Function for calculating variance of *d*
```{r define function EsVarBetw}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){       
   es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
             ((es^2) / (2 * (n.1 + n.2)));
   return(es.var)
}
```

### Call functions to calculate d and variance of *d*
```{r b: call functions to calculate d}
EsBetw <- function(){
  # call EsBetwMean on cases with between-subject designs and *means*
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "between" &  
        BTX.DF$es.calc[i] == "mean") {
      BTX.DF$es[i] <<- EsBetwMean (n.1 = BTX.DF$b.treat.n[i],
                                   m.1 = BTX.DF$b.treat.m[i],
                                   sd.1 = BTX.DF$b.treat.sd[i],
                                   n.2 = BTX.DF$b.compa.n[i],
                                   m.2 = BTX.DF$b.compa.m[i],
                                   sd.2 = BTX.DF$b.compa.sd[i])
    }
  }
  
  # call EsBetwPval on cases with between-subject designs and *p-values*
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "between" & 
        BTX.DF$es.calc[i] == "pval") {
      BTX.DF$es[i] <<- EsBetwPval (n.1 = BTX.DF$b.treat.n[i],
                                   n.2 = BTX.DF$b.compa.n[i],
                                   pval = BTX.DF$pval[i],
                                   pval.df = BTX.DF$pval.df[i])
    }
  }
  
  # call EsVarBetw on cases with between subject designs
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "between") {
      BTX.DF$es.var[i] <<- EsVarBetw (n.1 = BTX.DF$b.treat.n[i],
                                      n.2 = BTX.DF$b.compa.n[i],
                                      es = BTX.DF$es[i])
    }
  }
}

EsBetw()
```

## For within-subjects data
### Assumed pre-post correlation
```{r assumed correlation}
# define assumed correlation (sensitivity analyses performed later)
corr <- .50
```

### Functions for calculating d
#### When *M*_diff's and *SD*_diff's are provided
```{r EsWitnMeanDiff}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnMeanDiff <- function(m.diff, sd.diff, corr){
  es <- (m.diff / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

#### When *M*'s and *SD*'s are provided 
```{r EsWitnMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
# formula for imputing sd.diff:
# http://handbook.cochrane.org/chapter_16/16_4_6_1_mean_differences.htm
EsWitnMean <- function(m.1, sd.1, m.2, sd.2, corr){
  sd.diff <- sqrt((sd.1^2) + (sd.2^2) -
                  (2 * corr * sd.1 * sd.2));
        
  es <- ((m.1 - m.2) / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

#### When *p*-values are provided
```{r EsWitnPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnPval <- function(n, pval, pval.df, corr){
  # calculate the inverse of the cumulative distribution function of t
  tinv <- qt(p = (pval / 2), 
             df = pval.df,
             lower.tail = FALSE);
  
  es <- tinv * sqrt((2 * (1 - corr)) / n);
  return(es)
}
```

### Function for calculating variance of *d*
```{r EsVarWitn}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsVarWitn <- function(n, es){
  es.var <- ((1 / n) + 
             ((es^2) / (2 * n))) *
            2 * (1 - corr);
  return(es.var)
}
```

### Call functions to calculate *d* and variance of *d*
```{r w: call functions to calculate d}
# create a function that calls the functions to calculate d and variance of d
EsWitn <- function(){
  # call EsWitnMean on cases with within-subject designs and *mean_differences*
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "within" & 
        BTX.DF$es.calc[i] == "mean_diff") {
      BTX.DF$es[i] <<- EsWitnMeanDiff (m.diff = BTX.DF$w.diff.m[i],
                                       sd.diff = BTX.DF$w.diff.sd[i],
                                       corr = corr)
    }
  }
  
  # call EsWitnMean on cases with within-subject designs and *means*
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "within" & 
        BTX.DF$es.calc[i] == "mean") {
      BTX.DF$es[i] <<- EsWitnMean (m.1 = BTX.DF$w.pre.m[i],
                                   sd.1 = BTX.DF$w.pre.sd[i],
                                   m.2 = BTX.DF$w.post.m[i],
                                   sd.2 = BTX.DF$w.post.sd[i],
                                   corr = corr)
    }
  }
  
  # call EsWitnPval on cases with within-subject designs and *p-values*
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "within" & 
        BTX.DF$es.calc[i] == "pval") {
      BTX.DF$es[i] <<- EsWitnPval (n = BTX.DF$w.n[i],
                                   pval = BTX.DF$pval[i],
                                   pval.df = BTX.DF$pval.df[i],
                                   corr = corr)
    }
  }
  
  # call EsVarWitn on cases with within subject designs
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$within.between[i] == "within") {
      BTX.DF$es.var[i] <<- EsVarWitn (n = BTX.DF$w.n[i],
                                      es = BTX.DF$es[i])
    }
  }
}

# call EsWitn function
EsWitn()
```

## Specify direction
All hypothesis consistent effects are coded in the positive direction so that a positive value denotes a decrease in depression.

This direction of the effect was coded for in the raw database, and this code ensures that all effects are in the correct direction.
```{r specify es direction}
EsDir <- function(){
  # rename es column to denote that its direction has not yet been specified
  colnames(BTX.DF) [colnames(BTX.DF) == "es"] <<- "es.nodir"
  
  # create a new, blank effect size column
  BTX.DF$es <<- 0
  
  # make *all* the effect sizes positive
  for (i in 1:nrow(BTX.DF)) {
    BTX.DF$es[i] <<- abs(BTX.DF$es.nodir[i])
  }
  
  # make *negative* effect sizes negative
  for (i in 1:nrow(BTX.DF)) {
    if (BTX.DF$direction[i] == "negative") {
      BTX.DF$es[i] <<- BTX.DF$es[i] * (-1)
        }
  }
  
  # delete es.nodir
  BTX.DF <<- subset(BTX.DF, select = -c(es.nodir))
}

# call EsDir function
EsDir()
```

# Define data analysis function
This function will:

1. aggregate dependent effect sizes
2. Create an intercept-only meta-regression model
3. (unless user specifies otherwise) Examine bias
    + 3.1. Trim-and-fill
    + 3.2. PET-PEESE
    + 3.3. Weight-function model
4. Create summary plot
    + 4.1. Funnel plot
    + 4.2. Forest plot
    + 4.3. (unless user specifies no bias tests) Add summary of bias analyses
5. Save results to a list

The user must specify:

* the dataframe to perform the analyses on
* what to name the list of results
  
By default, the function:

* specifies the correlation among dependent measures to .70 
* Conducts publication bias tests
```{r define AnalyzeData}
AnalyzeData <- function(df, 
                        agg.cor = .70, 
                        bias.test = TRUE, 
                        list.name){
  # 1. Aggregate dependent effect sizes
  BTX.AGG.DF <- agg(id = record_id,
                    es = es,
                    var = es.var,
                    method = "BHHR",
                    cor = agg.cor, 
                    data = df)
  
    # add article.citation column to aggregated dataframe
    BTX.AGG.DF$names <- pull( unique( df[,"article.citation"]))
  
  # 2. Create an intercept-only meta-regression model
  re.mr <- rma.uni(yi = es,
                   vi = var,
                   slab = names,
                   data = BTX.AGG.DF,
                   method = "REML")
  
  # 3. Examine bias (if specified to do so)
    # if bias.tests NOT requested, output NA's
    trim <- NA
    pet <- NA
    peese <- NA
    weight.fun <- NA
    weight.adj.es <- NA
    weight.adj.p <- NA
    
    # if bias.tests requested:
    # conduct trim-and-fill, PET-PEESE, and weight-function analyses
    if (bias.test == TRUE){
      # 3.1. Duval and Tweedie trim and fill method
      trim <- trimfill(x = re.mr)
      
      # 3.2. PET-PEESE
      ## first compute standard error of es
      BTX.AGG.DF$se <- sqrt(BTX.AGG.DF$var)
          
        ### create models
          pet <-   lm(BTX.AGG.DF$es ~ BTX.AGG.DF$se, 
                      weights = 1 / BTX.AGG.DF$var)
          peese <- lm(BTX.AGG.DF$es ~ BTX.AGG.DF$var, 
                      weights = 1 / BTX.AGG.DF$var)
            
      # 3.3. Weight-function modeling
      weight.fun <- weightfunct(effect = BTX.AGG.DF$es,
                                v = BTX.AGG.DF$var)
      
        # [manually] extract relevant output from model
        # I.e., adjusted overall effect estimate and std error
        weight.adj.es <- weight.fun[[2]]$par[2]
        weight.adj.se <- sqrt(abs(diag(solve(weight.fun[[2]]$hessian))))[2]
        weight.adj.p <- pnorm(q = abs(weight.adj.es / weight.adj.se),
                              lower.tail = FALSE) * 2
      }
  
  # 4. Create summary plot
  # adjust plotting region so two plots can be simultaneously displayed
  par(mfrow = c(1, 2))
  
    # 4.1. Forest plot
    forest(x = re.mr, 
           xlab = "Standardized Mean Difference",
           cex = 1,
           cex.lab = 1,
           cex.axis = 1, 
           order = "prec")
    
      # add column headers
      par(font = 2) # bold font
      
        # primary outcome header placement
        if (deparse(substitute(df)) == "BTX.DF.1"){
          text(-1.25, 5.5, "Authors and Year",
               cex = .75)
          text(3.6, 5.5, "Effect [95% CI]",
               cex = .75)
        }
      
        # secondary outcome header placement
        if (deparse(substitute(df)) == "BTX.DF.2"){
          text(-1.25, 5.5, "Authors and Year",
               cex = .75)
          text(5.7, 5.5, "Effect [95% CI]",
               cex = .75)
        }
      
        # overall outcome header placement
        if (deparse(substitute(df)) == "BTX.DF"){
          text(-2, 8.8, "Authors and Year",
               cex = .75)
          text(6, 8.8, "Effect [95% CI]",
               cex = .75)
        }
      
      par(font = 1) #unbold font
  
    # 4.2. Funnel plot
    funnel(x = re.mr, 
           yaxis = "sei",
           xlab = "Standardized Mean Difference",
           back = "lightgray",
           hlines = "lightgray")
    
    # 4.3. If bias.tests requested
    # Add bias.test results to plot
    if (bias.test == TRUE){
      mtext(paste0("trim-and-fill: ", 
                   formatC(round(x = as.numeric(trim$b), 
                                 digits = 2), 
                           format = 'f', 
                           digits = 2),
                   stars.pval(trim$pval),
                   
                   "   ",
                   "PET: ",
                   formatC(round(x = summary(pet)$coefficients[1, 1], 
                                 digits = 2), 
                           format = 'f', 
                           digits = 2),
                   stars.pval(summary(pet)$coefficients[1, 4]),
                   
                   "   ",
                   "PEESE: ",
                   formatC(round(x = summary(peese)$coefficients[1, 1],
                                 digits = 2), 
                           format = 'f', 
                           digits = 2),
                   stars.pval(summary(peese)$coefficients[1, 4]),
                   
                   "   ",
                   "weight-function: ",
                   formatC(round(x = weight.adj.es, 
                                 digits = 2), 
                           format = 'f', 
                           digits = 2),
                   stars.pval(weight.adj.p)
                   ), 
      side = 3)
      }
  
  # save plot
  summary.plot <- recordPlot()

  # reset plotting region
  par(mfrow =c(1, 1)) 
  
  # 5. Write results to list
  assign(x= list.name,
         value = list(re.mr = re.mr,
                      trim = trim,
                      pet = summary(pet), 
                      peese = summary(peese),
                      weight.fun = list(model = weight.fun,
                                        adj.es = weight.adj.es,
                                        adj.p = weight.adj.p),
                      summary.plot = summary.plot),
         envir = .GlobalEnv)
}
```

# Primary outcome of interest: Week 6 BTX vs. Placebo Between-subject comparison
```{r AnalyzeData_out1, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
# subset data
BTX.DF.1 <- subset(BTX.DF, week == "6" &
                           placebo == 1 &
                           within.between == "between")

# call AnalyzeData function
AnalyzeData(df = BTX.DF.1,
            list.name = "outcome1.results")
```

## Print summary
```{r print outcome1 results, fig.width = 14, fig.height = 3, fig.asp = .62}
outcome1.results$summary.plot
```

# Secondary outcome of interest: Baseline v. Week 6 within-subject comparison for BTX group
```{r AnalyzeData_out2, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
# subset data
BTX.DF.2 <- subset(BTX.DF, week == "6" &
                           within.between == "within")

# call AnalyzeData function
AnalyzeData(df = BTX.DF.2,
            list.name = "outcome2.results")
```

## Print summary
```{r print outcome 2 results, fig.width = 14, fig.height = 3, fig.asp = .62}
outcome2.results$summary.plot
```

# Overall effect size
```{r AnalyzeData_oval, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
# call AnalyzeData function
AnalyzeData(df = BTX.DF,
            list.name = "overall.results")
```

## Print summary
```{r print oval results,  fig.width = 14, fig.height = 3, fig.asp = .62}
overall.results$summary.plot
```

# Misc. outcomes of interest
Specify valid weeks
```{r misc weeks}
weeks <- c("2", "3", "4", "6", 
           "8", "12", "16")
```

Create dataframe to paste results in
```{r create misc.results DF}
misc.results <- data.frame()
```

Using nested for loops, for each week and each outcome type (between or within):

1. subset data
2. call AnalyzeData function
3. append the results to the misc.results dataframe
```{r AnalyzeData_misc.weeks, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
for (out.type in c("between", "within")){
  for (week in weeks){
    # 1. subset data by outcome type and week
    BTX.DF.TMP <- subset(BTX.DF, 
                         within.between == out.type & week == week)
    
    # 2. call AnalyzeData function
    AnalyzeData(df = BTX.DF.TMP,
                bias.test = FALSE,
                list.name = "misc")
    
    # 3. append results to dataframe
    misc.results <<- 
      rbind(misc.results,
            with(misc,
                 cbind(w.b. = out.type,
                       week = week,
                       beta = round(x = re.mr$beta[1],
                                    digits = 2),
                       se = round(x = re.mr$se,
                                  digits = 2),
                       ci.lb = round(x = re.mr$ci.lb,
                                     digits = 2),
                       ci.ub = round(x = re.mr$ci.ub,
                                     digits = 2),
                       pval = AbbrvPval(re.mr$pval)
                       )
                 )
            )
    }
  }

# delete vestigial
rm(misc, weeks, out.type, week, BTX.DF.TMP)
```

## Print summary
```{r print misc.weeks}
kable(misc.results) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

# Sensitivity analyses
Create a list to paste all sensitivity analyses in
```{r create sens.list}
sens <- list()
```

## Assumed correlation in Borenstein aggregation method
```{r aggcorr.sens setup}
# create a vector of assumed correlations to test
corr.list <- c(.50, .60, .70, .80, .90)

# create dataframe to paste results in
aggcorr.sens <- data.frame()
```

```{r aggcorr.sens, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
for (DF in c("BTX.DF", "BTX.DF.1", "BTX.DF.2")){
  for (cor in corr.list){
    # 1. call AnalyzeData function
    AnalyzeData(df = get(DF),
                agg.cor = cor,
                bias.test = TRUE,
                list.name = "agg.sens")
  
    # 2. append the results to the agg.corr dataframe
    aggcorr.sens <<- 
      rbind(aggcorr.sens,
            with(agg.sens,
                 cbind(outcome = DF,
                       agg.corr = cor,
                       beta = round(x = re.mr$beta[1],
                                    digits = 2),
                       ci.lb = round(x = re.mr$ci.lb,
                                     digits = 2),
                       ci.ub = round(x = re.mr$ci.ub,
                                     digits = 2),
                       pval = AbbrvPval(re.mr$pval),
                       pet.int = round(x = pet$coefficients[1,1],
                                       digits = 2),
                       pet.int.p = round(x = pet$coefficients[1,4],
                                         digits = 2),
                       pet.b1 = round(x = pet$coefficients[2,1],
                                      digits = 2),
                       pet.b1.p = round(x = pet$coefficients[2,4],
                                        digits = 2),
                       peese.int = round(x = peese$coefficients[1,1],
                                         digits = 2),
                       peese.int.p = round(x = peese$coefficients[1,4],
                                           digits = 2),
                       peese.b1 = round(x = peese$coefficients[2,1],
                                        digits = 2),
                       peese.b1.p = round(x = peese$coefficients[2,4],
                                          digits = 2),
                       weight.adj.es = round(x = weight.fun$adj.es,
                                             digits = 2),
                       weight.adj.p = round(x = weight.fun$adj.p,
                                            digits = 2)
                       )
                 )
            )
    }
  }

# update naming of outcome column in aggcorr.sens dataframe
aggcorr.sens$outcome <- as.character(aggcorr.sens$outcome)
aggcorr.sens$outcome[aggcorr.sens$outcome == "BTX.DF"] <- "overall"
aggcorr.sens$outcome[aggcorr.sens$outcome == "BTX.DF.1"] <- "primary"
aggcorr.sens$outcome[aggcorr.sens$outcome == "BTX.DF.2"] <- "secondary"

rm(agg.sens, cor, corr.list, DF)
```

### Print summary
```{r print aggcorr.sens results}
kable(aggcorr.sens) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(width = "100%", height = "400px")
```


### Put sensitivity results into sensitivity list
```{r put aggcorr.sens in list}
sens <- list(agg.corr = aggcorr.sens)
rm(aggcorr.sens)
```

## Leave one-out analyses
For each outcome, conduct a leave-one-out analysis and append the results to a dataframe
```{r leave one out analyses, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
l1o <-
  rbind(cbind(outcome = "overall",
              leave1out(overall.results$re.mr) %>%  # leave-one-out analysis
                as.data.frame() %>%  # convert to dataframe
                tibble::rownames_to_column()  # fix row naming convention
              ),
        
        cbind(outcome = "primary",
              leave1out(outcome1.results$re.mr) %>%
                as.data.frame() %>%
                tibble::rownames_to_column()
              ),
        
        cbind(outcome = "secondary",
              leave1out(outcome2.results$re.mr) %>% 
                as.data.frame() %>% 
                tibble::rownames_to_column()
              )
)


# clean up formatting of dataframe
## round numbers
l1o[ , -c(1, 2, 6)] <- l1o[ , -c(1, 2, 6)] %>%
  round(digits = 2)

## abbreviate p-values
l1o$pval <- AbbrvPval(l1o$pval)
```

### Print summary
```{r print leave one out analyses}
kable(l1o) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(width = "100%", height = "400px")
```

Put in sensitivity analyses list
```{r put l1o in list}
sens$l10 <- l1o
rm(l1o)
```

## Influential outliers
1. Identify influential outliers
  1.1. Create a standard intercept-only random-effects meta-regression model
  1.2. Using the base-R influence function, flag influential outliers in that model
  1.3. Append "significant outlier" identifier to the dataframe
2. Re-run meta-regression excluding significant outliers
  2.1. Using base-R subset function, exclude outliers
  2.2. re-run standard intercept-only random-effects meta-regression model
3. Save output from influence function and meta-regression model (excluding outliers) to a list
  
```{r outlier analyses, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
out.sens <- data.frame()

for (DF in c("BTX.DF", "BTX.DF.1", "BTX.DF.2")){
  # 1. Identify influential outliers
  ## 1.1. Create a tmp dataframe
  DF.TMP <- get(DF)
  
  ## 1.2. Create a standard intercept-only random-effects meta-regression model
  mr <- rma.uni (yi = es,
                 vi = es.var,
                 data = DF.TMP,
                 method = "REML")

  ## 1.3. Using the base-R influence function, flag influential outliers in that model
  outliers <- influence(mr)

  ## 1.4. Append "significant outlier" identifier to the dataframe
  DF.TMP$influence <- outliers$is.infl

  # 2. Re-run meta-regression excluding significant outliers
  ## 2.1. Using base-R subset function, exclude outliers
  DF.TMP <- subset(DF.TMP, influence == FALSE)

  ## 2.2. re-run standard intercept-only random-effects meta-regression model
  ## by calling AnalyzeData function with subsetted dataframe
  AnalyzeData(df = DF.TMP,
              list.name = "outlier.rmv")
  
  # 3. append the results to the out.sens dataframe
    out.sens <<- 
      rbind(out.sens,
            with(outlier.rmv,
                 cbind(outcome = DF,
                       outliers.removed = length(which(outliers$is.infl == TRUE)),
                       beta = round(x = re.mr$beta[1],
                                    digits = 2),
                       ci.lb = round(x = re.mr$ci.lb,
                                     digits = 2),
                       ci.ub = round(x = re.mr$ci.ub,
                                     digits = 2),
                       pval = AbbrvPval(re.mr$pval),
                       pet.int = round(x = pet$coefficients[1,1],
                                       digits = 2),
                       pet.int.p = round(x = pet$coefficients[1,4],
                                         digits = 2),
                       pet.b1 = round(x = pet$coefficients[2,1],
                                      digits = 2),
                       pet.b1.p = round(x = pet$coefficients[2,4],
                                        digits = 2),
                       peese.int = round(x = peese$coefficients[1,1],
                                         digits = 2),
                       peese.int.p = round(x = peese$coefficients[1,4],
                                           digits = 2),
                       peese.b1 = round(x = peese$coefficients[2,1],
                                        digits = 2),
                       peese.b1.p = round(x = peese$coefficients[2,4],
                                          digits = 2),
                       weight.adj.es = round(x = weight.fun$adj.es,
                                             digits = 2),
                       weight.adj.p = round(x = weight.fun$adj.p,
                                            digits = 2)
                       )
                 )
            )
}

# delete vestigial
rm(DF, DF.TMP, mr, outlier.rmv, outliers)
```

### Print summary
```{r print outlier analyses}
kable(out.sens) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

### Put sensitivity results into sensitivity list
```{r put outlier analyses in list}
sens$outlier <- out.sens

# delete vestigial
rm(out.sens)
```

## Alternative meta-analytic approaches
For each outcome:

1. create an intercept-only meta-regression without aggregated dependencies
2. create an intercept-only meta-regression using robust variance estimation
3. create an intercept-only meta-regression using three-level multi-level model
4. put results in a list

```{r creat alt.mr dataframe}
# create blank dataframe to paste results in
alt.mr <- data.frame()
```

```{r alternative meta-analytic approaches, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
for (DF in c("BTX.DF", "BTX.DF.1", "BTX.DF.2")){
  # get dataframe
  DF.TMP <- get(DF)
  
  # 1. run meta-regression without aggregated dependencies
  std.mr <- rma.uni(yi = es,
                    vi = es.var,
                    data = DF.TMP)
  
  # 2. create an intercept-only meta-regression using robust variance estimation
  rve.mr <- robu(formula = es ~ 1,
                 data = DF.TMP,
                 studynum = record_id,
                 var.eff.size = es.var,
                 modelweights = "CORR",
                 small = TRUE)
  
  # 3. create an intercept-only meta-regression using three-level multi-level model
    ## Create an effect size id column
    DF.TMP <- DF.TMP %>%
      group_by(record_id) %>%
      mutate(es.id = row_number())
    
    ## model
    mlm.mr <- rma.mv(y = es, V = es.var,
                     random = list(~ 1 | es.id, ~ 1 | record_id),
                     tdist = TRUE,
                     data = DF.TMP)

  # 4. Append results to alt.mr dataframe
    alt.mr <-
    rbind(alt.mr,
          cbind(outcome = DF,
                model = "random-effects meta, no aggregated dependencies",
                est = round(x = std.mr$b[1],
                            digits = 2),
                pval = AbbrvPval(std.mr$pval)),
          cbind(outcome = DF,
                model = "robust variance estimates",
                est = round(x = rve.mr$b.r[1],
                            digits = 2),
                pval = AbbrvPval(rve.mr$p)),
          cbind(outcome = DF,
                model = "mlm",
                est = round(x = mlm.mr$b[1],
                            digits = 2),
                pval = AbbrvPval(mlm.mr$pval))
          )
}

# delete vestigial
rm(std.mr, rve.mr, mlm.mr, DF, DF.TMP)
```

### Print summary
```{r print alt.mr results}
kable(alt.mr) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

### Put sensitivity results into sensitivity list
```{r put alt.mr results in a list}
sens$alt.mr <- alt.mr

# delete vestigial
rm(alt.mr)
```


## Pre-post correlation in within-subject designs
```{r set up wcorr.sens analyses}
# create a vector of assumed correlations to test
corr.list <- c(.30, .50, .70, .50)

# create dataframe to paste results in
wcorr.sens <- data.frame()
```

### Overall
```{r wcorr.sens_oval, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
for (c in corr.list){
  # specify assumed pre-post correlation
  corr <<- c
  
  # re-calculate within subject effect sizes
  EsWitn()
  
  # re-specify effect size direction
  EsDir()
  
  # run analyses
  AnalyzeData(df = BTX.DF,
              list.name = "results")
  
  # append results to the dataframe
  wcorr.sens <<- 
    rbind(wcorr.sens,
          with(results,
               cbind(outcome = "overall",
                     corr = c,
                     beta = round(x = re.mr$beta[1],
                                  digits = 2),
                     ci.lb = round(x = re.mr$ci.lb,
                                   digits = 2),
                     ci.ub = round(x = re.mr$ci.ub,
                                   digits = 2),
                     pval = AbbrvPval(re.mr$pval),
                     pet.int = round(x = pet$coefficients[1,1],
                                     digits = 2),
                     pet.int.p = AbbrvPval(pet$coefficients[1,4]),
                     pet.b1 = round(x = pet$coefficients[2,1],
                                    digits = 2),
                     pet.b1.p = AbbrvPval(pet$coefficients[2,4]),
                     peese.int = round(x = peese$coefficients[1,1],
                                       digits = 2),
                     peese.int.p = AbbrvPval(peese$coefficients[1,4]),
                     peese.b1 = round(x = peese$coefficients[2,1],
                                      digits = 2),
                     peese.b1.p = AbbrvPval(peese$coefficients[2,4])
                     )
               )
          )
  
  print(results$weight.fun)
}
rm(results)
```

### Primary outcome of interest
N/A

### Secondary outcome of interest
```{r wcorr.sens_2, message = FALSE, warning = FALSE, results = "hide", fig.show = "hide"}
for (c in corr.list){
  # specify assumed pre-post correlation
  corr <<- c
  
  # re-calculate within subject effect sizes
  EsWitn()
  
  # re-specify effect size direction
  EsDir()
  
  ## subset data
  BTX.DF.2 <<- subset(BTX.DF, week == "6" &
                             within.between == "within")
  
  # run analyses
  AnalyzeData(df = BTX.DF.2,
              list.name = "results")
  
  # append results to the dataframe
  wcorr.sens <<- 
    rbind(wcorr.sens,
          with(results,
               cbind(outcome = "secondary",
                     corr = c,
                     beta = round(x = re.mr$beta[1],
                                  digits = 2),
                     ci.lb = round(x = re.mr$ci.lb,
                                   digits = 2),
                     ci.ub = round(x = re.mr$ci.ub,
                                   digits = 2),
                     pval = AbbrvPval(re.mr$pval),
                     pet.int = round(x = pet$coefficients[1,1],
                                     digits = 2),
                     pet.int.p = AbbrvPval(pet$coefficients[1,4]),
                     pet.b1 = round(x = pet$coefficients[2,1],
                                    digits = 2),
                     pet.b1.p = AbbrvPval(pet$coefficients[2,4]),
                     peese.int = round(x = peese$coefficients[1,1],
                                       digits = 2),
                     peese.int.p = AbbrvPval(peese$coefficients[1,4]),
                     peese.b1 = round(x = peese$coefficients[2,1],
                                      digits = 2),
                     peese.b1.p = AbbrvPval(peese$coefficients[2,4])
                     )
               )
          )
  
  print(results$weight.fun)
}
rm(results, c, corr, corr.list)
```

### Print summary
```{r}
kable(wcorr.sens) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(width = "100%", height = "400px")
```

### Put sensitivity results into sensitivity list
```{r put wcorr.sens results in list}
sens$w.corr <- wcorr.sens
rm(wcorr.sens)
```
